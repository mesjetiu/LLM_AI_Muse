\chapter{Hacia un ejemplo de arte sonoro generado con ayuda de GPT-4}

Como consecuencia de las pruebas y experimentos realizados con la API y el Playground de OpenAI, se generaron decenas de archivos con código cuyo resultado sonoro fue juzgado de cierto interés, independientemente de su adecuación a los requerimentos pasados por el prompt. Estos bloques de código están escritos tanto en SuperCollider como en Tidal Cycles. En el primer caso responden a peticiones muy concretas de texturas, timbres o sucesiones sonoras, en el Playground; en el segundo, a sesiones de \textit{livecoding} compartidas, asistidas por la API en \textit{AlgorAI}.

Ninguna de las construcciones de código conseguidas responden a un plan de una pieza completa, sino, más bien, a texturas sonoras continuas o con pocas variaciones en el tiempo. Por esta razón, el planteamiento de composición de una pieza a partir de estos materiales ha sido organizado absolutamente por el compositor-investigador. En este caso, se ha optado por organizar los sonidos elegidos en la DAW (\textit{Digital Audio Workstation}) \textit{Ardour}. Los procesados y efectos aplicados han sido mínimos, con el fin de mantener la esencia de los sonidos generados por GPT-4, limitándose a filtrados, cortes y compensación dinámica entre elementos. La Figura \ref{fig:ardour} muestra la organización de los sonidos en la DAW.

\begin{figure}[H]
    \caption[Captura de pantalla de la DAW Ardour con los sonidos generados por GPT-4 organizados en pistas]{Captura de pantalla de la DAW Ardour con los sonidos generados por GPT-4 organizados por pistas en una composición de arte sonoro.}
    \centering
    \includegraphics[width=0.4\textwidth]{./figuras/ardour.png}
    \source{Elaboración propia}
    \label{fig:ardour}
\end{figure}

\section{Proceso y criterios de selección de material sonoro}

La selección de los fragmentos de código a utilizar en la composición se realizó en un momento distinto de la propia generación, hasta dos meses más tarde en algunos casos, sin atender a las intenciones primeras a la hora de dialogar con la API ni a su grado de adecuación a las peticiones. Se buscó, más bien, la variedad de texturas y timbres, así como la posibilidad de combinarlos entre sí en un discurso sonoro coherente y equilibrado. La búsqueda se realizó escuchando bloque por bloque y renderizando a archivos de audio una o varias versiones de los mismos, ya que en ocasiones el resultado sonoro dependía de factores externos al código como la posición o el movimiento del ratón en los ejes $X$ e $Y$. 

En el momento de la selección, se intentó encontrar una estructura base esquemática con la ayuda de GPT-4, pero siempre aparecían problemas asociados al entendimiento de los procesos en el tiempo por parte del LLM. Todas las soluciones eran extremadamente simples en el mejor de los casos, o bien lejos de lo que se pretendía, una composición temporal a partir de samples, en el peor y la mayoría de los casos. Por esta razón, se optó por la intervención humana absoluta en el proceso de composición, relegando el papel de GPT-4 a la generación de material sonoro.

\section{Interacción humano-LLM en el proceso de composición}

En este proceso compositivo, cabe preguntarse si la utilización de materiales sonoros generados por IA ha determinado en algún sentido la dirección y resultado final de la composición. En este caso, al menos en la apreciación subjetiva del compositor-investigador, la respuesta es negativa. La forma en la que se han combinado en el tiempo los diferentes materiales, su fraccionamiento, su duración, orden, etc., no estaba implícitos de ningún modo en los materiales sonoros, sino que responden a una decisión más o menos consciente y creativa del compositor. Otros materiales distintos hubieran dado lugar a otra pieza, aunque con un carácter y estilo similares. 

Sin embargo, no se puede considerar indiferente la utilización de materiales sonoros generados por IA en el proceso compositivo. En primer lugar, la utilización de estos materiales ha permitido al compositor-investigador explorar nuevas texturas y timbres que, de otro modo, no hubiera podido crear. El artista sonoro suele buscar sus materiales sonoros a modo de exploración, bien del mundo real, con micrófonos, bien del mundo electrónico o digital, experimentando con sintetizadores, secuenciadores y todo tipo de software de generación sonora. En este caso, la exporación realizada por medio de modelos de lenguaje en código de programación ha permitido al compositor-investigador dar con materiales que por sí mismo no hubiera podido crear, no por falta de conocimientos o habilidades, sino porque las posibilidades de combinación de elementos generadores es infinita, por una parte, y el creador humano tiende a repetir patrones y estructuras que le son familirares o que han resultado exitosas en el pasado, por otra.

En todo caso, es notable el ahorro de trabajo que ha supuesto el hecho de que el LLM haya generado los materiales sonoros. El tiempo necesario para ello se ha reducido con creces respecto a la creación de los mismos por parte del compositor. Podría objetarse que esto significa la pérdida del poder de control del artista sobre su obra, pero esto no es necesariamente cierto. La actitud del compositor humano frente al manejo del LLM por sus diferentes interfaces ha sido la de búsqueda y selección constante. Los archivos con código de los cuales se han elegido ciertos bloques para la composición puede que no lleguen a una tercera parte de todos los desechados en el proceso experimental. Los guardados como interesantes, a su vez, fueron el producto de varias iteraciones en el diálogo con el modelo. No se ha aprecidado diferencia significativa en la calidad de la composición derivada de que el origen de los materiales sea la IA o producto de otras técnicas de exploración sonora. En todo caso, al tratarse de música experimental, la búsqueda de materiales ajenos a la intención del compositor es una constante, y la utilización de modelos de lenguaje en código de programación sonora se presenta como una herramienta más en el proceso de exploración sonora.