\chapter{Estado de la cuestión}
\label{chap:estado_cuestion}

En la actualidad, la generación de música o, en un sentido ámplio, de sonido, constituye uno de los frentes de investigación activos y más prometedores en el campo de la IA. La generación música con modelos de \textit{Deep Learning} ha sido abordado históricamente desde dos grandes perspectivas en función de la naturaleza de los datos generados por los modelos: la generación de música simbólica y la generación de música con audio. La primera de ellas consiste en la creación de elementos musicales como notas, acordes, melodías, etc. en un formato simbólico, ya sea MIDI, OSC, MusicXML, ABC, Lilypond, o cualquier formato musical reducible a símbolos textuales. La segunda, en la creación de un flujo de audio directamente reproducible sin necesidad de síntesis sonora o utilización de bibliotecas de \textit{samples}. Encontramos investigaciones recientes en ambos campos, incluso en la combinación de ambos, donde se generan elementos simbólicos que son posteriormente convertidos a audio. La Figura \ref{fig:generacion_musica_estado_cuestion} muestra un esquema de las diferentes aproximaciones a la generación de música con IA, que pasamos a detallar a continuación.

\begin{figure}[H]
    \caption{Esquema de las diferentes aproximaciones a la generación de música con IA}
    \centering
    \includegraphics[width=0.7\textwidth]{./figuras/generacion_musica_estado_cuestion.png}
    \source{Elaboración propia}
    \label{fig:generacion_musica}
\end{figure}

\section{Modelos de IA generativa aplicados a la música}

La primera aproximación, la de la composición informática de música a través de elementos simbólicos, se remonta a los inicios de la computación, con pioneros como Lejaren Hiller y Leonard Isaacson, que en 1957 crearon \textit{Illiac Suite} \citep{arizaTwoPioneeringProjects2011,funkMusicalSuiteComposed2018}, la primera composición musical generada por ordenador. Desde entonces, la generación de música simbólica ha sido abordada desde diferentes perspectivas, como la generación de música aleatoria, la generación de música a partir de reglas, la generación de música a partir de modelos probabilísticos como las cadenas de Markov, música basada en mátemática fractal, estocástica, etc. \citep{hernandez-olivanSurveyArtificialIntelligence2022}. 

La generación de audio por medio de modelos de \textit{Deep Learning} es un campo de investigación más reciente debido en parte a su gran demanda computacional, que ha estado fuera del alcance de investigadores y empresas hasta la última década. Actualmente, modelos como \textit{MuseNet}  \citep{departmentofcomputersciencesrminstituteofscienceandtechnologychennaiindia.MusenetMusicGeneration2020a}, \textit{Jukebox} \citep{dhariwalJukeboxGenerativeModel2020}, \textit{Stable Audio} \cite{StableAudioFast}, o \textit{Suno} \citep{SunoAI}, entre otros, están consiguiendo diariamente inéditos avances en lo que se refiere a la generación de música en formato de audio de una alta calidad, y, al igual que está ocurriendo con modelos de generación de imagen o vídeo, se espera que en los próximos años se produzcan avances muy significativos en este campo. Sobre este campo de investigación existen numerosos y recientes estudios, como ...


\section{LLM como asistentes para la creación de música simbólica}
\label{sec:llm_asistentes_creacion_codigo_programacion}

La aproximación a la generación de música a través de elementos simbólicos en lugar de puro audio adquiere una renovada fuerza por la aparición de los grandes modelos de lenguaje, los cuales se basan en la arquitectura \textit{Transformer}, aparecida en 2017 \citep{vaswaniAttentionAllYou2017}, por lo que es un tema de investigación muy reciente y al que se le está prestando menos atención. El grueso de las investigaciones candentes en este momento se están centrando en la generación de audio, campo más prometedor desde el punto de vista comercial. No obstante, existen recientes investigaciones en este campo, como \textit{MuseCoco} \citep{luMuseCocoGeneratingSymbolic2023}, que propone un procedimiento en dos etapas desde el input de texto en lenguaje natural del usuario hasta la generación de música simbólica en forma de partitura. La Figura \ref{fig:musecoco} muestra el esquema de funcionamiento de este sistema. 

\begin{figure}[H]
    \caption[Esquema de funcionamiento en dos pasos de MuseCoco texto--música]{Esquema de funcionamiento en dos pasos de MuseCoco en la generación de música simbólica desde texto}
    \centering
    \includegraphics[width=0.9\textwidth]{./figuras/musecoco_two_steps.png}
    \source{\cite{luMuseCocoGeneratingSymbolic2023}}
    \label{fig:musecoco}
\end{figure}

Otro interesante trabajo sobre el uso de LLM para la generación musical es \textit{WavJourney} \citep{liuWavJourneyCompositionalAudio2023}, donde el papel del LLM es el de agente compositivo capaz de conectarse con otros modelos de generación de audio (voz, instrumentos, ruidos, música, etc.) para <<componer>> a partir del input o prompt del usuario. En este caso, el LLM juega un papel de mediador y planificador de la composición, además de generador de prompts para los diversos modelos implicados en la generación de audio. La Figura \ref{fig:wavjourney} muestra el esquema de funcionamiento de este sistema. Una aproximación similar en cuanto al uso de los LLM en la generación de audio lo encontramos en \cite{borsosAudioLMLanguageModeling2023}.

\begin{figure}[H]
    \caption[Esquema de funcionamiento de WavJourney]{Esquema de funcionamiento de WavJourney en la generación de audio desde texto}
    \centering
    \includegraphics[width=0.4\textwidth]{./figuras/WavJourney.png}
    \source{\cite{liuWavJourneyCompositionalAudio2023}}
    \label{fig:wavjourney}
\end{figure}

La generación de código de programación por LLM, independientemente de su finalidad artística o técnica, sí que es un campo muy estudiado en los últimos meses, y que ha dado lugar a la aparición de modelos como \textit{Github Copilot}, que ha sido capaz de generar código de programación de considerable calidad a partir de inputs o \textit{prompts} en lenguaje natural. \textit{Github Copilot} es un servicio que integra un modelo GPT-4 junto a un conjunto de aplicaciones de integración en entornos de desarrollo como Visual Studio Code, Atom, etc. Debido a su amplia aplicación en el campo de la programación, es un modelo que ha recibido una gran atención mediática, y que ha sido objeto de numerosos estudios y análisis, por lo que podemos considerarlo como el estado del arte en la generación de código de programación por LLM. Es por ello que los principales estudios sobre la interacción de LLM con humanos en el campo de la programación se han centrado en este servicio. De todos estos artículos podemos extraer conclusiones de interés.

Un estudio sobre el impacto en la productividad del uso de AI en tareas concretas de programación mostró que estas se realizaron un 55,8\% más rápido que sin su ayuda \citep{pengImpactAIDeveloper2023a}, aunque necesario señalar que en este estudio participaron investigadores de Microsoft, empresa que desarrolla \textit{Github Copilot}, con lo cual los resultados pueden estar sesgados. En esta línea, investigadores Montreal y Toronto, observaron que herramientas como \textit{Github Copilot} dan resultados muy comparables a los de programadores humanos, si bien su utilidad es mayor cuando lo utilizan programadores con experiencia, constituyendo cierto riesgo en manos de programadores noveles \citep{moradidakhelGitHubCopilotAI2023}. Otro interesante estudio sobre la fiabilidad de la generación de código de \textit{Github Copilot} \citep{mastropaoloRobustnessCodeGeneration2023}, halló que en casi la mitad de los casos, el código generado por dos descripciones en lenguaje natural semánticamente equivalentes, era diferente, y en más de una cuarta parte de los casos la corrección del código se vio comprometida, lo que pone en tela juicio la robustez del sistema.

\section{\textit{Prompting engineering}}

Se entiende por \textit{prompting} a la forma en la que se le pide a un modelo generativo una respuesta. En el caso de un LLM, que genere un texto \citep{LLMPromptingGuide}. El \textit{prompt} es el texto en lenguaje natural que el usuario presenta al LLM como input. El \textit{prompting} es un campo de investigación muy activo en la actualidad, y que ha dado lugar a numerosos estudios y publicaciones. El buen desempeño de los LLM en tareas de código de programación lleva a estudios como \cite{liStructuredChainofThoughtPrompting2023}, que propone un sistema de prompting que pide al LLM una reflexión explícita sobre la implementación a realizar, en una especie de pseudocódigo, que en un segundo paso será traducido al código final de programación. Este sistema de prompting se basa en la idea de que el LLM generará código de mayor calidad si se le permite <<pensar>> la respuesta antes de generarla. En este sentido, existen sobradas publicaciones que ponen de relieve la sensibilidad de los LLM a la forma en la que se le pide que procese la información (\textit{prompting}) y la correlación en la calidad de sus resultados \citep{zhouLeasttoMostPromptingEnables2023,weiChainofThoughtPromptingElicits2023,LLMPromptingGuide}.
 
\section{\textit{Retrieval-Augmented Generation} (RAG)}

Los modelos de lenguaje están prentrenados con grandes cantidades de texto de propósito general, lo que los hace capaces y hábiles en multiples campos sin necesidad de un entrenamiento específico (ver Figura \ref{fig:fundation_models_habilities}). Es posible, sin embargo, rentrenarlos con datos más concretos y precisos para una tarea específica (por ejemplo, con datos médicos, ingenieriles, con datos privados de una empresa, etc.). A este proceso se le conoce como \textit{fine-tuning} o <<ajuste fino>>. Sin embargo, el proceso de \textit{fine-tuning} de un LLM requiere de grandes cantidades de datos y tiempo de entrenamiento, algo que en este momento no está al alcance del usuario medio. Por ello, se están desarrollando técnicas que permitan a los usuarios aprovechar los modelos preentrenados para tareas específicas sin necesidad de \textit{fine-tuning}. Una de estas técnicas es \textit{Retrieval-Augmented Generation} (RAG) \citep{WhatRetrievalaugmentedGeneration2021}, que combina la recuperación de información con la generación de texto. Esta es una técnica que ofrece resultados muy notables en términos de eficacia y eficiencia frente al \textit{fine-tuning}. RAG consiste en pasar como contexto al LLM junto a la petición del usuario, una serie de fragmentos de texto que se corresponden semánticamente con la petición, y que se obtienen de una base de datos de documentos relacionados con la tarea a realizar. Esta base de datos puede ser de cualquier tipo, desde una base de datos de texto en lenguaje natural, hasta una base de datos de código de programación, pasando por una base de datos de partituras musicales, o una base de datos de audio, y representan la base de conocimiento extra (\textit{knowledge}) que el LLM manejará en sus interacciones con el usuario. Este sistema de \textit{prompting} está en la base actual de muchos productos relacionados con LLM, como Assistant o GPTs de OpenAI. La Figura \ref{fig:rag} muestra el esquema de funcionamiento de RAG. La base de datos del conocimiento del LLM es dividido en una primera fase en fragmentos más pequeños y analizados por el LLM para obtener una representación vectorial de cada uno de ellos. En una segunda fase, el LLM recibe el \textit{prompt} del usuario y lo analiza para obtener una representación vectorial. En una tercera fase, el LLM busca en la base de datos de fragmentos aquellos que tienen similitud vectoria (y, por ende, semántica) con el \textit{prompt} del usuario. En una cuarta fase, el LLM genera el texto de salida a partir del \textit{prompt} del usuario y de los fragmentos de texto recuperados de la base de datos. 

\begin{figure}
    \caption{Habilidades de los \textit{Foundation Models} de OpenAI.}
    \centering
    \includegraphics[width=0.8\textwidth]{./figuras/fundation_models_habilities.png}
    \source{\cite{GPT3RiseFoundation}}
    \label{fig:fundation_models_habilities}
\end{figure}

\begin{figure}[H]
    \caption[Esquema de funcionamiento de RAG]{Esquema de funcionamiento de RAG}
    \centering
    \includegraphics[width=0.9\textwidth]{./figuras/rag.png}
    \source{\cite{}}
    \label{fig:rag}
\end{figure}

Esta técnica, frente al \textit{fine-tuning}, ofrece una serie de ventajas, como la posibilidad de utilizar modelos preentrenados de propósito general, que son más eficientes y eficaces que los modelos entrenados para una tarea específica, y la posibilidad de utilizar bases de datos de conocimiento de gran tamaño, que son más fáciles de obtener que los grandes conjuntos de datos necesarios para el \textit{fine-tuning}. Además, la base de datos de conocimiento puede ser actualizada de forma independiente al modelo, lo que permite una mayor flexibilidad en el uso de los modelos. Por contra, el modelo no tiene conocimiento global de los contenidos de la base de datos, por lo que no puede realizar inferencias globales sobre ella, y la calidad de los resultados depende en gran medida de cómo se ha dividido su contenido en fragmentos y de la calidad de la representación vectorial de cada uno de ellos. Se ha probado un mayor rendimiento en técnicas combinadas de \textit{fine-tuning} para tareas específicas y RAG \citep{lewisRetrievalAugmentedGenerationKnowledgeIntensive2021}.


