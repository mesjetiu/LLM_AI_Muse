\chapter{Limitaciones y prospectiva}

% \defaultFontEpigraph{Is Bang-Bang Control All You Need?}{\cite{seydeBangBangControlAll2021}}

\defaultFontEpigraph{Is Bang-Bang Control All You Need?}{Seyde y cols. (2021)}


\section{Limitaciones}

Este trabajo se ha desarrollado bajo ciertas restricciones que son importantes considerar al momento de interpretar los resultados y conclusiones presentadas. A continuación, se detallan las principales limitaciones encontradas durante la investigación y que son inherentes a esta:

\begin{enumerate}
\item \textbf{Naturaleza cualitativa y exploratoria:} El enfoque de este estudio es principalmente cualitativo y exploratorio, lo que implica que no se han buscado resultados experimentales cuantificables. Esta aproximación, a pesar de ofrecer un panorama global del tema y de dibujar futuras líneas de investigación, limita a priori la capacidad de generalizar los hallazgos más allá de los casos estudiados.

\item \textbf{Unicidad del investigador y sesgos:} La investigación fue llevada a cabo por un único individuo en interacción creativa, lo cual puede introducir sesgos en la recopilación y análisis de datos, así como en la interpretación de los resultados. Además, dada la familiaridad del investigador con la programación y la música, es posible que existan sesgos en la selección de prompts y en la interpretación de los resultados, influyendo en la dirección y conclusiones del trabajo.

\item \textbf{Obsolescencia de herramientas de \gls{IA} analizadas:} Las herramientas y modelos de lenguaje empleados representan el estado del arte al comienzo de la realización del estudio. Sin embargo, el campo de la \gls{ia} avanza rápidamente, lo que podría resultar en que estas herramientas se vuelvan obsoletas, y con ellas, los resultados, en un corto periodo de tiempo.

\item \textbf{Uso de modelos de código cerrado:} La investigación se apoyó en modelos de lenguaje de código cerrado, en concreto, con los de OpenAI, que limita la transparencia y comprensión completa de los procesos internos que guían las generaciones musicales.

\item \textbf{Limitaciones computacionales:} No fue posible realizar ajustes finos (fine tuning) en los modelos de lenguaje debido a la falta de recursos computacionales necesarios, restringiendo la personalización de los modelos para necesidades específicas del estudio.

\item \textbf{Potencial sesgo del investigador:} 

\end{enumerate}

% Limitación inherente a la naturaleza cualitativa y exploratoria del propio trabajo. No se pueden esperar resultados experimentales.

% Limitación por la existencia de un único investigador, que puede llevar a sesgos en la interpretación de los resultados.

% Limitación por obsolescencia de las herramientas utilizadas. Los modelos de lenguaje utilizados son los más actuales a día de hoy, pero solo tienen que pasar unos meses para que queden obsoletos.

% La utilización de modelos de código cerrados, en lugar de open source, limita la comprensión de los procesos internos de los modelos de lenguaje.

% La imposibilidad de realizar fine tuning de los modelos de lenguaje utilizados por no tener los recursos computacionales necesarios.

% Entre otras cosas, comentar la posibilidad de sesgo de todo el trabajo, en cuanto que el investigador es conocedor del lenguaje de programación y de la música, y por tanto, puede que haya sesgos en la elección de los prompts, en la interpretación de los resultados, etc.


\section{Prospectiva}


% \item \textbf{Aplicaciones educativas y de asistente:} Se reconoce el valor de estas herramientas para la educación en los lenguajes musicales, ofreciendo una asistencia teórica y práctica de gran utilidad.

% Futuros trabajos con metodología cuantitativa, con métricas de calidad de código, de calidad de música, de originalidad, etc.

% Creación de datasets específicos para entrenar modelos de lenguaje en música y sonido.

% Creación de un buen sistema \gls{rag}, con documentos de código comentados y categorizados, para que el modelo pueda aprender de ellos.

% Trabajos futuros con más de dos lenguajes de programación.

% Investigar sistemas de agentes autónomos que puedan manejar los errores de código iterativamente

% Investigar la posibilidad de entrenamiento con fine tuning de los modelos de lenguaje como GPT-3 y GPT-4 en los lenguajes utilizados.

% Con el crecimiento de los LLM, investigar su capacidad de manejo de piezas extensas.

% En el futuro, la posibilidad e utilizar agentes es muy sugerente y prometedora, ya que auna la capacidad de manejo de códigos pequeños con el de su unidad y planificación general.


% En el futuro, investigar la posibilidad de tener LLM en local y open source, así como la posibilidad de entrenarlos con fine tuning.


% Prospectiva: explorar la multimodalidad en el campo audiovisual.

% Explorar más afondo la posibilidad de utilizar LLM en tiempo real, en el campo del live coding.



