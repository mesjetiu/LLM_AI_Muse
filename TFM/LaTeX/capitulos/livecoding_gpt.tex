\chapter{\emph{AI Muse}, herramienta en \emph{Python} para la interacción en vivo LLM en entornos de \emph{live coding}}
\todo{Sobre AI Muse, capítulo por hacer\dots}

% \defaultFontEpigraph{One Model Is All You Need}{\cite{grahamOneModelAll2022}}
\defaultFontEpigraph{One Model Is All You Need}{Graham y cols. (2022)}

Aquí se detalla la herramienta creada de live coding con la API y Tidal Cycles. Se describe el proceso de creación de la herramienta, así como su funcionamiento y las posibilidades que ofrece. También se exponen ejemplos.

\section{Descripción general de la herramienta}

Escrito en Python
Se comunica con la API de OpenAI
Es un entorno de Livecondig
Al guardar el archivo se realiza un intercambio con la API
Permite ejecutar código de SuperCollider y código de Tidal Cycles
Tiene un archivo de configuración en json, además de un conjunto de comandos para cambiar los parámetros en vivo

\section{¿Por qué en entorno de Livecoding?}

Es más dúctil e interactivo que el de la composición.
Explora la posibilidad de respuesta inmediata por API.
Explota el hecho de que los LLM actualmente trabajan mejor con bloques relativamente pequeños.
Los lenguajes de livecoding tienen mecanismos de seguridad que abstraen al usuario de largas comprobaciones de errores: o funciona o no funciona. Si no funciona, nada se cae. Este principio se aplica especialmente a Tidal Cycles, aunque SuperCollider también tiene estructuras adecuadas para livecoding (placeholders)
Inmediatez de la respuesta del modelo. Se iteran las respuestas buenas, las malas se pueden desechar sin más.

\section{Integración de la API de OpenAI}

Usar la API es conveniente para controlar todos los parámetros del modelo.
Actualmente tiene dos modalidades: Chat y Assistant.
Es lo suficientemente rápido como para interaccionar y escribir mucho más rápido que el usuario, por lo que se puede poner un tiempo mínimo entre respuestas.



\section{Lenguajes de programación musical disponibles}

\section{Archivo de configuración y comandos}

Explicar el archivo de configuración y los comandos de configuración en vivo. Hacer una tabla

\section{Flujo de trabajo}

\section{Hallazgos obtenidos con \emph{AI Muse}}

Se ha conseguido un alto nivel de "colaboración" e interacción con un modelo de lenguaje. La dimensión temporal no se decide de antemano, como en una composición, sino que se desarrolla a partir de modificaciones y aportaciones atómicas. En esto es fuerte GPT-4.

Es un buen banco de pruebas para la experimentación con modelos. 



\section{Ejemplos de uso}