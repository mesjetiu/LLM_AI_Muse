@misc{200BestFree,
  type = {página web},
  title = {The 200 {{Best Free VST Plugins Ever}}},
  url = {https://blog.landr.com/best-free-vst-plugins/}
}

@article{abeliukHistoriaEvoluacionInteligencia2021,
  title = {Historia y evoluación de la inteligencia artificial},
  author = {Abeliuk, Andrés and Gutiérrez, Claudio},
  date = {2021-08-03},
  journaltitle = {Revista Bits de Ciencia},
  number = {21},
  pages = {14--21},
  url = {https://revistasdex.uchile.cl/index.php/bits/index},
  urldate = {2023-10-30},
  issue = {21},
  langid = {spanish},
  file = {/home/carlos/Zotero/storage/3XUJEG4L/Abeliuk y Gutiérrez - 2021 - Historia y evoluación de la inteligencia artificia.pdf}
}

@inproceedings{abelSynchronizationOrganPipes2008,
  title = {Synchronization of Organ Pipes},
  author = {Abel, Markus},
  date = {2008-01-01},
  pages = {231--240},
  file = {/home/carlos/Zotero/storage/DAMGURJM/Abel - 2008 - Synchronization of organ pipes.pdf}
}

@software{AGIEdgerunnersLLMAgentsPapers2024,
  title = {{{AGI-Edgerunners}}/{{LLM-Agents-Papers}}},
  date = {2024-01-02T17:41:34Z},
  origdate = {2023-05-31T08:33:48Z},
  url = {https://github.com/AGI-Edgerunners/LLM-Agents-Papers},
  urldate = {2024-01-02},
  abstract = {A repo lists papers related to LLM based agent},
  organization = {{AGI-Edgerunners}},
  keywords = {agents,large-language-models,llm-agent,paper-list}
}

@article{alan1950a,
  title = {Computing Machinery and Intelligence},
  author = {Turing, Alan Mathison},
  date = {1950},
  journaltitle = {Mind; a quarterly review of psychology and philosophy},
  shortjournal = {Mind},
  volume = {49},
  pages = {433--460}
}

@article{alberdiEvolutionaryAnalysisAcoustics2021,
  title = {Evolutionary {{Analysis}} of the {{Acoustics}} of the {{Baroque Church}} of {{San Luis}} de Los {{Franceses}} ({{Seville}})},
  author = {Alberdi, Enedina and Galindo, Miguel and Leon-Rodriguez, Angel},
  date = {2021-02-04},
  journaltitle = {Applied Sciences},
  shortjournal = {Applied Sciences},
  volume = {11},
  pages = {1402},
  doi = {10.3390/app11041402},
  abstract = {In the 16th century the Society of Jesus built a large number of churches following the Tridentine model of a Latin cross and a single nave. However, the shift towards this model did not entail the abandonment of the central floor plan, especially in the 17th century. The acoustics of these spaces can present phenomena linked to focalizations which increase the sound pressure level. The church of San Luis de los Franceses, built by the Jesuits for their novitiate in Seville (Spain), is an example of a Baroque church with a central floor plan. Although the church has hosted different congregations since its inauguration it is currently desacralized and used for theatres and concerts. The acoustics of this church were studied by the authors through in situ measurements and virtual models. The main objective was to analyse the evolution and perception of its sound field from the 18th to 21st centuries, considering the different audience distributions and sound sources and the modifications in furniture and coatings. Analysis of the evolution of its sound field shows that the characteristics have remained stable, with a notable influence of the dome on the results for the different configurations studied.},
  file = {/home/carlos/Zotero/storage/XPL52EXB/Alberdi et al. - 2021 - Evolutionary Analysis of the Acoustics of the Baro.pdf}
}

@article{amiotDiscreteFourierTransform2009,
  title = {Discrete {{Fourier Transform}} and {{Bach}}’s {{Good Temperament}}},
  author = {Amiot, Emmanuel},
  date = {2009-07-01},
  journaltitle = {Music Theory Online},
  volume = {15},
  number = {2},
  url = {https://mtosmt.org/issues/mto.09.15.2/mto.09.15.2.amiot.html},
  urldate = {2023-05-31},
  langid = {english},
  file = {/home/carlos/Zotero/storage/8NZCLFPG/mto.09.15.2.amiot.html}
}

@online{AnalisisModosPropios,
  title = {Análisis de modos propios de recintos paralelepipédicos},
  url = {https://studylib.es/doc/6014937/análisis-de-modos-propios-de-recintos-paralelepipédicos},
  urldate = {2023-05-23},
  abstract = {Biblioteca en línea. Materiales de aprendizaje gratuitos.},
  langid = {spanish},
  organization = {{studylib.es}},
  file = {/home/carlos/Zotero/storage/SJL7SBZJ/análisis-de-modos-propios-de-recintos-paralelepipédicos.html}
}

@article{andoArchitecturalAcousticsBlending1998,
  title = {Architectural {{Acoustics}}: {{Blending Sound Sources}}, {{Sound Fields}}, and {{Listeners}}},
  shorttitle = {Architectural {{Acoustics}}},
  author = {Ando, Yoichi and Raichel, Daniel R.},
  date = {1998-12-01},
  journaltitle = {The Journal of the Acoustical Society of America},
  shortjournal = {The Journal of the Acoustical Society of America},
  volume = {104},
  number = {6},
  pages = {3151},
  issn = {0001-4966},
  doi = {10.1121/1.423953},
  url = {https://doi.org/10.1121/1.423953},
  urldate = {2023-05-23},
  file = {/home/carlos/Zotero/storage/ALA8DMZ7/Ando y Raichel - 1998 - Architectural Acoustics Blending Sound Sources, S.pdf;/home/carlos/Zotero/storage/9FQX7UGW/Architectural-Acoustics-Blending-Sound-Sources.html}
}

@inproceedings{angster25YearsApplied2019,
  title = {25 Years Applied Pipe Organ Research at {{Fraunhofer IBP}} in {{Stuttgart}}},
  author = {Angster, Judit and Rucz, Péter and Miklós, András},
  date = {2019-09-01},
  abstract = {Throughout the world, musical instruments are deeply rooted in cultural traditions. They are part of our cultural heritage, and their preservation and further development deserves our utmost attention. For many years, the Fraunhofer Institute for Building Physics IBP has been engaged in the research of European musical instruments, the pipe organ in particular. To preserve its sound, to give support in building instruments as well as to contribute to the further development by integrating modern technologies are the focus of the joint research with other research institutions and a multitude of European organ building enterprises. In 25 years, 9 common European and several other research projects were carried out. Some examples of the topics will be mentioned like development of 1) different kinds of new wind systems, methods and software for the design, 2) design methods, tools and software with applying computer simulations for flue and reed organ pipes, 3) innovative swell shutters, 4) design methods and comprehensive tools for matching the instrument on the acoustics of the room. The procedure of research, way of communication with instrument builders, the method of demonstration and dissemination of the research results will be discussed.},
  file = {/home/carlos/Zotero/storage/YLW5UPL7/Angster et al. - 2019 - 25 years applied pipe organ research at Fraunhofer.pdf}
}

@article{angsterAcousticsOrganPipes2017,
  title = {Acoustics of {{Organ Pipes}} and {{Future Trends}} in the {{Research}}},
  author = {Angster, Judit and Rucz, Péter and Miklós, András},
  date = {2017-03-14},
  journaltitle = {Acoustics Today},
  shortjournal = {Acoustics Today},
  volume = {13},
  pages = {12--20},
  abstract = {The pipe organ produces a majestic sound that differs from all other musical instruments. Due to its wide tonal range, its ability of imitating the sound of various instruments, and its grandiose size, the pipe organ is often called the “king of musical instruments”. The richness and variety of sound color (timbre) produced by a pipe organ is very unique because of the almost uncountable possibilities for mixing the sounds from different pipes. According to the art of sound generation, there are two kinds of pipes in the organ that are similar in function to other wind instruments: flue (labial) pipes and reed (lingual) pipes. Although this article focuses on sound excitation by flue pipes, the role of reed pipes is briefly mentioned. The article also shows how the connection between sound character and pipe shape and dimensions can be understood, and it also considers the trends in the research that focus on helping organ builders in their practical work.},
  file = {/home/carlos/Zotero/storage/AAV3I6NF/Angster et al. - 2017 - Acoustics of Organ Pipes and Future Trends in the .pdf}
}

@inproceedings{angsterInnovativeMethodsSound2015a,
  title = {Innovative Methods for the Sound Design of Organ Pipes ({{Ph}}.{{D}}. {{Thesis Booklet}})},
  author = {Angster, J.},
  date = {2015},
  url = {https://www.semanticscholar.org/paper/Innovative-methods-for-the-sound-design-of-organ-Angster/065cc00b396f3251202c173c302041ad010b6d12},
  urldate = {2023-05-23},
  abstract = {Despite the fact that organ building is quite an orthodox art with roots going back more than two thousand years, organ builders are still looking for improvements of the quality of their instruments. Pipe organ research aims at providing answers to the questions of the craftsmen by seeking the physical explanations of the phenomena observed, and thus supplementing the traditional craftsmanship with scientific background. The objective of this thesis is to contribute to organ research regarding two main aspects. On the one hand, solutions to particular design issues in organ building practice are sought. This task consists of investigating the acoustic behavior of specific pipe families, understanding their physics, predicting the impact of changing the geometry of the pipe, and finally, developing strategies that lead to the desired sound characteristics by optimal design. On the other hand, the dissertation introduces novel modeling and optimization methodology for examining and solving the aforementioned problems. The latter involves the establishment of oneand three-dimensional or hybrid acoustic models and computer simulations of fluid flow relying on state of the art techniques. Both aspects are approached making use of analytical and numerical methods and validating the attained results by comparing them to measured data.},
  file = {/home/carlos/Zotero/storage/V5DLSTAB/Angster - 2015 - Innovative methods for the sound design of organ p.pdf}
}

@article{arizaTwoPioneeringProjects2011,
  title = {Two {{Pioneering Projects}} from the {{Early History}} of {{Computer-Aided Algorithmic Composition}}},
  author = {Ariza, Christopher},
  date = {2011-09},
  journaltitle = {MIT Press},
  publisher = {{MIT Press}},
  issn = {0148-9267},
  url = {https://dspace.mit.edu/handle/1721.1/68626},
  urldate = {2023-12-26},
  abstract = {Lejaren Hiller's 1970 chapter, "Music Composed  with Computers: An Historical Survey" (Hiller  1970) contains numerous descriptions of projects  in the computer generation of musical structures.  By then, just over ten years after the publication  of Hiller's and Leonard Isaacson's seminal book  Experimental Music (Hiller and Isaacson 1959), a  startling number of experiments in generativemusic  with early computers had been completed. Hiller’s  early research, compositions, and publications  established him as a leader in the then-emerging  field of computer-aided algorithmic composition  (CAAC). Some researchers, likely inspired by Hiller  and Isaacson's 1956 Illiac Suite string quartet, even  duplicated their instrumentation: in an amusing  footnote, Hiller writes that "it is curious to note  how many computer pieces have been written for  string quartet . . . particularly since string-quartet  performers seem to be among the least receptive to  newer compositional ideas such as computermusic"  (Hiller 1970, p. 70).},
  langid = {american},
  annotation = {Accepted: 2012-01-20T20:32:35Z},
  file = {/home/carlos/Zotero/storage/MN9QB5LS/Ariza - 2011 - Two Pioneering Projects from the Early History of .pdf}
}

@misc{arturia,
  type = {página web},
  title = {Arturia Synthi {{V}}},
  url = {http://www.futuremusic-es.com/arturia-synthi-v-sinte-plugin}
}

@misc{ArturiaSynthi,
  type = {página web},
  title = {Arturia {{Synthi V}}},
  url = {http://www.futuremusic-es.com/arturia-synthi-v-sinte-plugin}
}

@online{arunbijiRAGVsFinetuning,
  title = {{{RAG}} vs {{Finetuning}} vs {{Prompt Engineering}}: {{A}} Pragmatic View on {{LLM}} Implementation},
  shorttitle = {{{RAG}} vs {{Finetuning}} vs {{Prompt Engineering}}},
  author = {Arun Biji, Mathew},
  url = {https://www.linkedin.com/pulse/rag-vs-finetuning-prompt-engineering-pragmatic-view-llm-mathew},
  urldate = {2024-01-21},
  abstract = {The first half of this article tries to give a brief introduction to challenges in practical implementation of LLMs, whereas the second half focuses on solution approaches for addressing these challenges and how they compare to each other. Please skip to the later section if you are already aware of},
  langid = {english},
  file = {/home/carlos/Zotero/storage/56G7M9X9/rag-vs-finetuning-prompt-engineering-pragmatic-view-llm-mathew.html}
}

@incollection{attenboroughSoundPropagationAtmosphere2007,
  title = {Sound {{Propagation}} in the {{Atmosphere}}},
  booktitle = {Springer {{Handbook}} of {{Acoustics}}},
  author = {Attenborough, Keith},
  editor = {Rossing, Thomas D.},
  date = {2007},
  series = {Springer {{Handbooks}}},
  pages = {113--147},
  publisher = {{Springer}},
  location = {{New York, NY}},
  doi = {10.1007/978-0-387-30425-0_4},
  url = {https://doi.org/10.1007/978-0-387-30425-0_4},
  urldate = {2023-05-23},
  abstract = {Propagation of sound close to the ground outdoors involves geometric spreading, air absorption, interaction with the ground, barriers, vegetation and refraction associated with wind and temperature gradients. After a brief survey of historical aspects of the study of outdoor sound and its applications, this chapter details the physical principles associated with various propagation effects, reviews data that demonstrate them and methods for predicting them. The discussion is concerned primarily with the relatively short ranges and spectra of interest when predicting and assessing community noise rather than the frequencies and long ranges of concern, for example, in infrasonic global monitoring or used for remote sensing of the atmosphere. Specific phenomena that are discussed include spreading losses, atmospheric absorption, diffraction by barriers and buildings, interaction of sound with the ground (ground waves, surface waves, ground impedance associated with porosity and roughness, and elasticity effects), propagation through shrubs and trees, wind and temperature gradient effects, shadow zones and incoherence due to atmospheric turbulence. The chapter concludes by suggesting a few areas that require further research.},
  isbn = {978-0-387-30425-0},
  langid = {english},
  keywords = {Flow Resistivity,Ground Effect,Shadow Zone,Sound Propagation,Traffic Noise}
}

@online{Audio,
  title = {Audio},
  url = {https://stability.ai/stable-audio},
  urldate = {2023-12-26},
  langid = {british},
  organization = {{Stability AI}},
  file = {/home/carlos/Zotero/storage/2ILU7GRZ/stable-audio.html}
}

@book{barbourTuningTemperamentHistorical2004,
  title = {Tuning and {{Temperament}}: {{A Historical Survey}}},
  shorttitle = {Tuning and {{Temperament}}},
  author = {Barbour, James Murray},
  date = {2004-01-01},
  publisher = {{Courier Corporation}},
  abstract = {The demands of tuning (attaining the perfect scale) and temperament (the compromises necessary for composing in every key) have challenged musicians from the earliest civilizations onward. This guide surveys these longstanding problems, devoting a chapter to each principal theory and offering a running account of the complete history of tuning and temperament. Organized chronologically, the book features a helpful glossary and numerous illustrative tables, and it requires minimal background in music theory. This new reissue is currently the only edition in print of a much-quoted classic. 9 figures. 180 tables.},
  isbn = {978-0-486-43406-3},
  langid = {english},
  pagetotal = {260},
  keywords = {Music / History \& Criticism,Music / Instruction \& Study / Theory}
}

@inproceedings{bassoAcusticaEspaciosNo2018,
  title = {Acústica de espacios no convencionales y música para sitios específicos},
  author = {Basso, Gustavo Jorge and Farina, María Andrea and Jaureguiberry, Luis Federico},
  date = {2018-11-22},
  url = {http://sedici.unlp.edu.ar/handle/10915/133345},
  urldate = {2023-05-23},
  abstract = {El uso de lugares no destinados originalmente para la representación de espectáculos musicales y sonoros se  ha convertido en práctica habitual en todo el mundo y se está extendiendo rápidamente en nuestro país. Se puede considerar que una obra fue pensada para "sitio específico" cuando las condiciones acústicas del lugar donde se interpreta determinan su identidad, es decir, devienen estructurales. En los casos de obras para sitios específicos, para obtener resultados musicales y sonoros apropiados es necesario una adecuada interacción entre el material musical, las fuentes y el campo acústico. El concepto de “instrumento musical ampliado” permite concebir las tres partes de este conjunto como un todo correlacionado e interdependiente. En este trabajo intentaremos abordar una definición para el concepto de “sitio específico” y se analizarán las características acústicas y musicales de varias obras de música sitiada representadas en la Argentina en lo que va del siglo XXI.},
  eventtitle = {XVI Congreso Argentino de Acústica (AdAA 2018) (Buenos Aires, 22 y 23 de noviembre de 2018)},
  isbn = {978-987-47051-0-5},
  langid = {spanish},
  file = {/home/carlos/Zotero/storage/P7GJAJSW/Basso et al. - 2018 - Acústica de espacios no convencionales y música pa.pdf}
}

@inproceedings{bassoSalasParaMusica2012,
  title = {Salas Para Música: Patrimonio Acústico-Musical de La Ciudad de {{La Plata}}},
  shorttitle = {Salas Para Música},
  booktitle = {{{VI Jornadas}} de {{Investigación}} En {{Disciplinas Artísticas}} y {{Proyectuales}} ({{La Plata}}, 2012)},
  author = {Basso, Gustavo Jorge and Farina, María Andrea and Cejas, Valeria Paola and Jaureguiberry, Luis Federico and Szelagowski, Martín Tomás and Pappadopoulos, Jorge Daniel},
  date = {2012}
}

@online{BeginnerGuideNeural,
  title = {A {{Beginner}}'s {{Guide}} to {{Neural Networks}} and {{Deep Learning}}},
  url = {http://wiki.pathmind.com/neural-network},
  urldate = {2023-12-21},
  abstract = {An introduction to deep artificial neural networks and deep learning.},
  langid = {english},
  organization = {{Pathmind}},
  file = {/home/carlos/Zotero/storage/QUNDLL5X/a_beginners_guide_to_neural_networks_and_deep_learning___pathmind.pdf;/home/carlos/Zotero/storage/A63S2JGX/neural-network.html}
}

@book{beranekConcertHallsOpera2012,
  title = {Concert {{Halls}} and {{Opera Houses}}: {{Music}}, {{Acoustics}}, and {{Architecture}}},
  shorttitle = {Concert {{Halls}} and {{Opera Houses}}},
  author = {Beranek, Leo},
  date = {2012-12-06},
  eprint = {_jLTBwAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {{Springer Science \& Business Media}},
  abstract = {he first question any lover of classical music usually asb an acoustician is, "Which are the best halls in the world?" The response-the three halls rated highest by world-praised conductors and music critics of the largest newspapers were built in 1870, 1888, and 1900-always prompts the next query: "Why are those so good while many halls built after 1950 seem to be mediocre or failures?" You will find answers to these questions in this book the result of a half-century's research into the very complex field of acoustics of halls for music. The dialog re-enacted above bears a close resemblance to another illustration that typically troubles music lovers. They frequently asl},
  isbn = {978-0-387-21636-2},
  langid = {english},
  pagetotal = {662},
  keywords = {Science / Acoustics \& Sound,Science / Physics / General,Science / Waves \& Wave Mechanics,Technology \& Engineering / Construction / General,{Technology \& Engineering / Construction / Heating, Ventilation \& Air Conditioning}}
}

@article{beranekSubjectiveRankOrderingsAcoustical2003,
  title = {Subjective {{Rank-Orderings}} and {{Acoustical Measurements}} for {{Fifty-Eight Concert Halls}}},
  author = {Beranek, Leo},
  date = {2003-05-01},
  journaltitle = {Acta Acustica united with Acustica},
  shortjournal = {Acta Acustica united with Acustica},
  volume = {89},
  pages = {494--508},
  abstract = {A rank-ordering of fifty-eight concert halls according to their acoustical quality is presented, based on interviews of conductors, music critics and well-traveled music aficionados. For a large percentage of these halls, objective measurements of the acoustical attributes are presented. These objective data are compared to the subjective rank orderings in a series of charts. The acoustical attributes considered are reverberation time RT, early decay time EDT, Binaural Quality Index BQI (proposed name for the quantity [1−IACCE3], where the measured quantity is the interaural cross-correlation coefficient, integrated over 0 to 80 ms and averaged for the three octave bands, 500, 1k and 2k Hz bands), initial-time-delay gap ITDG, bass ratio BR, strength factor G at mid-frequencies (average of 500 and 1k octave bands), strength factor G125 at 125 Hz, lateral fraction LFE (both the average of LFE in the 125, 250, 500 and 1k Hz bands and in the 500, 1k and 2k bands, where "E" indicates integration over 0 to 80 ms), surface diffusivity index (visual) SDI, and support factor ST1. The objective quantities that correlate best with the subjective rank orderings are BQI, EDTmid, G125, SDI and ITDG, in that order. The possible use of the characteristics "texture" and "late lateral strength factor" are discussed.},
  file = {/home/carlos/Zotero/storage/NPHATKG4/Beranek - 2003 - Subjective Rank-Orderings and Acoustical Measureme.pdf}
}

@online{bhavsarPromptEngineeringArithmetic2023,
  title = {Prompt {{Engineering}} for {{Arithmetic Reasoning Problems}}},
  author = {Bhavsar, Kaustubh},
  date = {2023-11-18T15:42:54},
  url = {https://towardsdatascience.com/prompt-engineering-for-arithmetic-reasoning-problems-28c8bcd5bf0e},
  urldate = {2024-01-05},
  abstract = {Explore various prompt engineering techniques for arithmetic reasoning problems, best practices, and rapid experimentations for…},
  langid = {english},
  organization = {{Medium}},
  file = {/home/carlos/Zotero/storage/JPHKF3VK/prompt-engineering-for-arithmetic-reasoning-problems-28c8bcd5bf0e.html}
}

@online{borsosAudioLMLanguageModeling2023,
  title = {{{AudioLM}}: A {{Language Modeling Approach}} to {{Audio Generation}}},
  shorttitle = {{{AudioLM}}},
  author = {Borsos, Zalán and Marinier, Raphaël and Vincent, Damien and Kharitonov, Eugene and Pietquin, Olivier and Sharifi, Matt and Roblek, Dominik and Teboul, Olivier and Grangier, David and Tagliasacchi, Marco and Zeghidour, Neil},
  date = {2023-07-25},
  eprint = {2209.03143},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/2209.03143},
  urldate = {2024-01-04},
  abstract = {We introduce AudioLM, a framework for highquality audio generation with long-term consistency. AudioLM maps the input audio to a sequence of discrete tokens and casts audio generation as a language modeling task in this representation space. We show how existing audio tokenizers provide different trade-offs between reconstruction quality and long-term structure, and we propose a hybrid tokenization scheme to achieve both objectives. Namely, we leverage the discretized activations of a masked language model pre-trained on audio to capture long-term structure and the discrete codes produced by a neural audio codec to achieve high-quality synthesis. By training on large corpora of raw audio waveforms, AudioLM learns to generate natural and coherent continuations given short prompts. When trained on speech, and without any transcript or annotation, AudioLM generates syntactically and semantically plausible speech continuations while also maintaining speaker identity and prosody for unseen speakers. Furthermore, we demonstrate how our approach extends beyond speech by generating coherent piano music continuations, despite being trained without any symbolic representation of music.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/home/carlos/Zotero/storage/QXGW8ZAJ/Borsos et al. - 2023 - AudioLM a Language Modeling Approach to Audio Generation.pdf}
}

@book{boulangerCsoundBookPerspectives2000,
  title = {The {{Csound Book}}. {{Perspectives}} in {{Software Synthesis}}, {{Sound Design}}, {{Signal Processing}}, and {{Programming}}},
  editor = {Boulanger, Richard},
  date = {2000},
  publisher = {{The MIT Press}},
  location = {{Massachusetts}}
}

@online{bowmanEightThingsKnow2023,
  title = {Eight {{Things}} to {{Know}} about {{Large Language Models}}},
  author = {Bowman, Samuel R.},
  date = {2023-04-02},
  eprint = {2304.00612},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2304.00612},
  url = {http://arxiv.org/abs/2304.00612},
  urldate = {2023-10-23},
  abstract = {The widespread public deployment of large language models (LLMs) in recent months has prompted a wave of new attention and engagement from advocates, policymakers, and scholars from many fields. This attention is a timely response to the many urgent questions that this technology raises, but it can sometimes miss important considerations. This paper surveys the evidence for eight potentially surprising such points: 1. LLMs predictably get more capable with increasing investment, even without targeted innovation. 2. Many important LLM behaviors emerge unpredictably as a byproduct of increasing investment. 3. LLMs often appear to learn and use representations of the outside world. 4. There are no reliable techniques for steering the behavior of LLMs. 5. Experts are not yet able to interpret the inner workings of LLMs. 6. Human performance on a task isn't an upper bound on LLM performance. 7. LLMs need not express the values of their creators nor the values encoded in web text. 8. Brief interactions with LLMs are often misleading.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/carlos/Zotero/storage/RDHLL7B3/Bowman - 2023 - Eight Things to Know about Large Language Models.pdf;/home/carlos/Zotero/storage/HETIVTEB/2304.html}
}

@incollection{breazealePhysicalAcoustics2007,
  title = {Physical {{Acoustics}}},
  booktitle = {Springer {{Handbook}} of {{Acoustics}}},
  author = {Breazeale, Mack and McPherson, Michael},
  editor = {Rossing, Thomas D.},
  date = {2007},
  series = {Springer {{Handbooks}}},
  pages = {207--238},
  publisher = {{Springer}},
  location = {{New York, NY}},
  doi = {10.1007/978-0-387-30425-0_6},
  url = {https://doi.org/10.1007/978-0-387-30425-0_6},
  urldate = {2023-05-23},
  abstract = {An overview of the fundamental concepts needed for an understanding of physical acoustics is provided. Basic derivations of the acoustic wave equation are presented for both fluids and solids. Fundamental wave concepts are discussed with an emphasis on the acoustic case. Discussions of different experiments and apparatus provide examples of how physical acoustics can be applied and of its diversity. Nonlinear acoustics is also described.},
  isbn = {978-0-387-30425-0},
  langid = {english},
  keywords = {Acoustic Wave,Physical Acoustics,Sound Pressure Level,Surface Acoustic Wave,Surface Wave}
}

@online{bretanUnitSelectionMethodology2016,
  title = {A {{Unit Selection Methodology}} for {{Music Generation Using Deep Neural Networks}}},
  author = {Bretan, Mason and Weinberg, Gil and Heck, Larry},
  date = {2016-12-12},
  eprint = {1612.03789},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1612.03789},
  url = {http://arxiv.org/abs/1612.03789},
  urldate = {2023-05-24},
  abstract = {Several methods exist for a computer to generate music based on data including Markov chains, recurrent neural networks, recombinancy, and grammars. We explore the use of unit selection and concatenation as a means of generating music using a procedure based on ranking, where, we consider a unit to be a variable length number of measures of music. We first examine whether a unit selection method, that is restricted to a finite size unit library, can be sufficient for encompassing a wide spectrum of music. We do this by developing a deep autoencoder that encodes a musical input and reconstructs the input by selecting from the library. We then describe a generative model that combines a deep structured semantic model (DSSM) with an LSTM to predict the next unit, where units consist of four, two, and one measures of music. We evaluate the generative model using objective metrics including mean rank and accuracy and with a subjective listening test in which expert musicians are asked to complete a forced-choiced ranking task. We compare our model to a note-level generative baseline that consists of a stacked LSTM trained to predict forward by one note.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Sound},
  file = {/home/carlos/Zotero/storage/EHW5C3CU/Bretan et al. - 2016 - A Unit Selection Methodology for Music Generation .pdf;/home/carlos/Zotero/storage/E2D7NJMW/1612.html}
}

@online{brownLanguageModelsAre2020,
  title = {Language {{Models}} Are {{Few-Shot Learners}}},
  author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  date = {2020-07-22},
  eprint = {2005.14165},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2005.14165},
  url = {http://arxiv.org/abs/2005.14165},
  urldate = {2023-06-29},
  abstract = {Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/home/carlos/Zotero/storage/4ZY5M7ZW/Brown et al. - 2020 - Language Models are Few-Shot Learners.pdf;/home/carlos/Zotero/storage/PSWS6S3E/2005.html}
}

@online{butlinConsciousnessArtificialIntelligence2023,
  title = {Consciousness in {{Artificial Intelligence}}: {{Insights}} from the {{Science}} of {{Consciousness}}},
  shorttitle = {Consciousness in {{Artificial Intelligence}}},
  author = {Butlin, Patrick and Long, Robert and Elmoznino, Eric and Bengio, Yoshua and Birch, Jonathan and Constant, Axel and Deane, George and Fleming, Stephen M. and Frith, Chris and Ji, Xu and Kanai, Ryota and Klein, Colin and Lindsay, Grace and Michel, Matthias and Mudrik, Liad and Peters, Megan A. K. and Schwitzgebel, Eric and Simon, Jonathan and VanRullen, Rufin},
  date = {2023-08-22},
  eprint = {2308.08708},
  eprinttype = {arxiv},
  eprintclass = {cs, q-bio},
  doi = {10.48550/arXiv.2308.08708},
  url = {http://arxiv.org/abs/2308.08708},
  urldate = {2023-09-27},
  abstract = {Whether current or near-term AI systems could be conscious is a topic of scientific interest and increasing public concern. This report argues for, and exemplifies, a rigorous and empirically grounded approach to AI consciousness: assessing existing AI systems in detail, in light of our best-supported neuroscientific theories of consciousness. We survey several prominent scientific theories of consciousness, including recurrent processing theory, global workspace theory, higher-order theories, predictive processing, and attention schema theory. From these theories we derive "indicator properties" of consciousness, elucidated in computational terms that allow us to assess AI systems for these properties. We use these indicator properties to assess several recent AI systems, and we discuss how future systems might implement them. Our analysis suggests that no current AI systems are conscious, but also suggests that there are no obvious technical barriers to building AI systems which satisfy these indicators.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Computer Science - Machine Learning,Quantitative Biology - Neurons and Cognition},
  file = {/home/carlos/Zotero/storage/3YM2L8NV/Butlin et al. - 2023 - Consciousness in Artificial Intelligence Insights.pdf}
}

@online{caiStructuredPruningAll2022,
  title = {Structured {{Pruning}} Is {{All You Need}} for {{Pruning CNNs}} at {{Initialization}}},
  author = {Cai, Yaohui and Hua, Weizhe and Chen, Hongzheng and Suh, G. Edward and De Sa, Christopher and Zhang, Zhiru},
  date = {2022-05-31},
  eprint = {2203.02549},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2203.02549},
  url = {http://arxiv.org/abs/2203.02549},
  urldate = {2024-01-22},
  abstract = {Pruning is a popular technique for reducing the model size and computational cost of convolutional neural networks (CNNs). However, a slow retraining or fine-tuning procedure is often required to recover the accuracy loss caused by pruning. Recently, a new research direction on weight pruning, pruning-at-initialization (PAI), is proposed to directly prune CNNs before training so that fine-tuning or retraining can be avoided. While PAI has shown promising results in reducing the model size, existing approaches rely on fine-grained weight pruning which requires unstructured sparse matrix computation, making it difficult to achieve real speedup in practice unless the sparsity is very high. This work is the first to show that fine-grained weight pruning is in fact not necessary for PAI. Instead, the layerwise compression ratio is the main critical factor to determine the accuracy of a CNN model pruned at initialization. Based on this key observation, we propose PreCropping, a structured hardware-efficient model compression scheme. PreCropping directly compresses the model at the channel level following the layerwise compression ratio. Compared to weight pruning, the proposed scheme is regular and dense in both storage and computation without sacrificing accuracy. In addition, since PreCropping compresses CNNs at initialization, the computational and memory costs of CNNs are reduced for both training and inference on commodity hardware. We empirically demonstrate our approaches on several modern CNN architectures, including ResNet, ShuffleNet, and MobileNet for both CIFAR-10 and ImageNet.},
  pubstate = {preprint},
  version = {2},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/carlos/Zotero/storage/5ICLM59D/Cai et al. - 2022 - Structured Pruning is All You Need for Pruning CNNs at Initialization.pdf;/home/carlos/Zotero/storage/3PNZ4KJR/2203.html}
}

@online{calvoRedNeuronalRecurrente2018,
  title = {Red Neuronal Recurrente - RNN},
  author = {Calvo, Diego},
  date = {2018-12-09T16:51:14+00:00},
  url = {https://www.diegocalvo.es/red-neuronal-recurrente/},
  urldate = {2024-01-22},
  abstract = {Definición de Red Neuronal Recurrente Una red neuronal recurrente no tiene una estructura de capas definida, sino que permiten conexiones arbitrarias entre las neuronas, incluso pudiendo crear ciclos, con esto se consigue crear la temporalidad, permitiendo que la red tenga memoria. Las redes neuronales recurrentes son muy potentes para todo lo que tiene que ver […]},
  langid = {spanish},
  organization = {{Diego Calvo}},
  file = {/home/carlos/Zotero/storage/HMJ2MIVB/red-neuronal-recurrente.html}
}

@article{campbellDeepBlue2002,
  title = {Deep {{Blue}}},
  author = {Campbell, Murray and Hoane, A. Joseph and Hsu, Feng-hsiung},
  date = {2002-01-01},
  journaltitle = {Artificial Intelligence},
  shortjournal = {Artificial Intelligence},
  volume = {134},
  number = {1},
  pages = {57--83},
  issn = {0004-3702},
  doi = {10.1016/S0004-3702(01)00129-1},
  url = {https://www.sciencedirect.com/science/article/pii/S0004370201001291},
  urldate = {2023-10-29},
  abstract = {Deep Blue is the chess machine that defeated then-reigning World Chess Champion Garry Kasparov in a six-game match in 1997. There were a number of factors that contributed to this success, including: •a single-chip chess search engine,•a massively parallel system with multiple levels of parallelism,•a strong emphasis on search extensions,•a complex evaluation function, and•effective use of a Grandmaster game database. This paper describes the Deep Blue system, and gives some of the rationale that went into the design decisions behind Deep Blue.},
  keywords = {Computer chess,Evaluation function,Game tree search,Parallel search,Search extensions,Selective search},
  file = {/home/carlos/Zotero/storage/IAV98XWL/Campbell et al. - 2002 - Deep Blue.pdf;/home/carlos/Zotero/storage/ARPI4JK5/S0004370201001291.html}
}

@online{caoAllYouNeed2020,
  title = {All You Need Is a Second Look: {{Towards Tighter Arbitrary}} Shape Text Detection},
  shorttitle = {All You Need Is a Second Look},
  author = {Cao, Meng and Zou, Yuexian},
  date = {2020-04-26},
  eprint = {2004.12436},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2004.12436},
  url = {http://arxiv.org/abs/2004.12436},
  urldate = {2024-01-22},
  abstract = {Deep learning-based scene text detection methods have progressed substantially over the past years. However, there remain several problems to be solved. Generally, long curve text instances tend to be fragmented because of the limited receptive field size of CNN. Besides, simple representations using rectangle or quadrangle bounding boxes fall short when dealing with more challenging arbitrary-shaped texts. In addition, the scale of text instances varies greatly which leads to the difficulty of accurate prediction through a single segmentation network. To address these problems, we innovatively propose a two-stage segmentation based arbitrary text detector named \textbackslash textit\{NASK\} (\textbackslash textbf\{N\}eed \textbackslash textbf\{A\} \textbackslash textbf\{S\}econd loo\textbackslash textbf\{K\}). Specifically, \textbackslash textit\{NASK\} consists of a Text Instance Segmentation network namely \textbackslash textit\{TIS\} (\textbackslash (1\^\{st\}\textbackslash ) stage), a Text RoI Pooling module and a Fiducial pOint eXpression module termed as \textbackslash textit\{FOX\} (\textbackslash (2\^\{nd\}\textbackslash ) stage). Firstly, \textbackslash textit\{TIS\} conducts instance segmentation to obtain rectangle text proposals with a proposed Group Spatial and Channel Attention module (\textbackslash textit\{GSCA\}) to augment the feature expression. Then, Text RoI Pooling transforms these rectangles to the fixed size. Finally, \textbackslash textit\{FOX\} is introduced to reconstruct text instances with a more tighter representation using the predicted geometrical attributes including text center line, text line orientation, character scale and character orientation. Experimental results on two public benchmarks including \textbackslash textit\{Total-Text\} and \textbackslash textit\{SCUT-CTW1500\} have demonstrated that the proposed \textbackslash textit\{NASK\} achieves state-of-the-art results.},
  pubstate = {preprint},
  version = {1},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/carlos/Zotero/storage/7FSIZ6HW/Cao y Zou - 2020 - All you need is a second look Towards Tighter Arbitrary shape text detection.pdf;/home/carlos/Zotero/storage/ALQ7N894/2004.html}
}

@book{carrionisbertDisenoAcusticoEspacios1998,
  title = {Diseño acústico de espacios arquitectónicos},
  author = {Carrión Isbert, Antonio},
  date = {1998},
  publisher = {{Edicions UPC}},
  url = {https://upcommons.upc.edu/handle/2099.3/36341},
  urldate = {2023-05-23},
  isbn = {978-84-9880-073-9},
  langid = {spanish},
  keywords = {Acústica arquitectònica,Àrees temàtiques de la UPC::Arquitectura::Projectes arquitectònics},
  annotation = {Accepted: 2013-12-18T09:50:11Z},
  file = {/home/carlos/Zotero/storage/7333RX7M/Carrión Isbert - 1998 - Diseño acústico de espacios arquitectónicos.pdf}
}

@online{ChallengesAssociatedBuilding,
  title = {The Challenges Associated With Building Products Using Large Language Models (LLMs).},
  url = {https://www.linkedin.com/pulse/challenges-associated-building-products-using-large-language-das},
  urldate = {2023-10-31},
  abstract = {Hello there. I hope you all are doing well.},
  langid = {spanish},
  file = {/home/carlos/Zotero/storage/A78XI6JS/challenges-associated-building-products-using-large-language-das.html}
}

@online{chamandFinetuneYourClassifier2022,
  title = {Fine-Tune Your {{Classifier}}: {{Finding Correlations With Temperature}}},
  shorttitle = {Fine-Tune Your {{Classifier}}},
  author = {Chamand, Benjamin and Risser-Maroix, Olivier and Kurtz, Camille and Joly, Philippe and Loménie, Nicolas},
  date = {2022-10-18},
  eprint = {2210.09715},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2210.09715},
  url = {http://arxiv.org/abs/2210.09715},
  urldate = {2023-11-07},
  abstract = {Temperature is a widely used hyperparameter in various tasks involving neural networks, such as classification or metric learning, whose choice can have a direct impact on the model performance. Most of existing works select its value using hyperparameter optimization methods requiring several runs to find the optimal value. We propose to analyze the impact of temperature on classification tasks by describing a dataset as a set of statistics computed on representations on which we can build a heuristic giving us a default value of temperature. We study the correlation between these extracted statistics and the observed optimal temperatures. This preliminary study on more than a hundred combinations of different datasets and features extractors highlights promising results towards the construction of a general heuristic for temperature.},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/home/carlos/Zotero/storage/EVJ4JQ22/Chamand et al. - 2022 - Fine-tune your Classifier Finding Correlations Wi.pdf;/home/carlos/Zotero/storage/7ZL2LZHW/2210.html}
}

@article{chandaNeurochemistryMusic2013,
  title = {The Neurochemistry of Music},
  author = {Chanda, Mona Lisa and Levitin, Daniel J.},
  date = {2013-04-01},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {17},
  number = {4},
  eprint = {23541122},
  eprinttype = {pmid},
  pages = {179--193},
  publisher = {{Elsevier}},
  issn = {1364-6613, 1879-307X},
  doi = {10.1016/j.tics.2013.02.007},
  url = {https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(13)00049-1},
  urldate = {2023-05-23},
  langid = {english},
  keywords = {immunity,music,neurochemistry,reward,social affiliation,stress},
  file = {/home/carlos/Zotero/storage/J3ZRX58P/S1364661313000491.html}
}

@online{chenNewNewMoats2023,
  title = {The {{New New Moats}}},
  author = {Chen, Jerry},
  date = {2023-06-21T22:09:23+00:00},
  url = {https://greylock.com/greymatter/the-new-new-moats/},
  urldate = {2023-06-27},
  langid = {american},
  organization = {{Greylock}},
  file = {/home/carlos/Zotero/storage/PDG3GFGU/the-new-new-moats.html}
}

@online{chenTeachingLargeLanguage2023,
  title = {Teaching {{Large Language Models}} to {{Self-Debug}}},
  author = {Chen, Xinyun and Lin, Maxwell and Schärli, Nathanael and Zhou, Denny},
  date = {2023-10-05},
  eprint = {2304.05128},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2304.05128},
  url = {http://arxiv.org/abs/2304.05128},
  urldate = {2023-10-23},
  abstract = {Large language models (LLMs) have achieved impressive performance on code generation. However, for complex programming tasks, generating the correct solution in one go becomes challenging, thus some prior works have designed program repair approaches to improve code generation performance. In this work, we propose Self-Debugging, which teaches a large language model to debug its predicted program via few-shot demonstrations. In particular, we demonstrate that Self-Debugging can teach the large language model to perform rubber duck debugging; i.e., without any human feedback on the code correctness or error messages, the model is able to identify its mistakes by investigating the execution results and explaining the generated code in natural language. Self-Debugging achieves the state-of-the-art performance on several code generation benchmarks, including the Spider dataset for text-to-SQL generation, TransCoder for C++-to-Python translation, and MBPP for text-to-Python generation. On the Spider benchmark where there are no unit tests to verify the correctness of predictions, Self-Debugging with code explanation consistently improves the baseline by 2-3\%, and improves the prediction accuracy on problems of the hardest level by 9\%. On TransCoder and MBPP where unit tests are available, Self-Debugging improves the baseline accuracy by up to 12\%. Meanwhile, by leveraging feedback messages and reusing failed predictions, Self-Debugging notably improves sample efficiency, and can match or outperform baseline models that generate more than 10x candidate programs.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/carlos/Zotero/storage/7APGY9B9/Chen et al. - 2023 - Teaching Large Language Models to Self-Debug.pdf;/home/carlos/Zotero/storage/B54ZXYI4/2304.html}
}

@online{CodeLlamaOpen,
  title = {Code {{Llama}}: {{Open Foundation Models}} for {{Code}} | {{Research}} - {{AI}} at {{Meta}}},
  url = {https://ai.meta.com/research/publications/code-llama-open-foundation-models-for-code/},
  urldate = {2023-09-27},
  file = {/home/carlos/Zotero/storage/RIT3IM2P/code-llama-open-foundation-models-for-code.html}
}

@article{crawfordHOTCHOCOLATEEFFECT1980,
  title = {{{THE HOT CHOCOLATE EFFECT}}},
  author = {Crawford, Frank S.},
  date = {1980-12-01},
  url = {https://escholarship.org/uc/item/9dh21770},
  urldate = {2023-05-23},
  abstract = {Author(s): Crawford, Frank S.},
  langid = {english},
  file = {/home/carlos/Zotero/storage/ZJL688W2/Crawford - 1980 - THE HOT CHOCOLATE EFFECT.pdf}
}

@article{cremerDifferentDistributionsAudience1975,
  title = {The Different Distributions of the Audience},
  author = {Cremer, Lothar},
  date = {1975-07-01},
  journaltitle = {Applied Acoustics},
  shortjournal = {Applied Acoustics},
  volume = {8},
  number = {3},
  pages = {173--191},
  issn = {0003-682X},
  doi = {10.1016/0003-682X(75)90020-1},
  url = {https://www.sciencedirect.com/science/article/pii/0003682X75900201},
  urldate = {2023-05-23},
  langid = {english},
  file = {/home/carlos/Zotero/storage/AG7K6PYT/0003682X75900201.html}
}

@inproceedings{crookConversationalSemanticSearch2018,
  title = {Conversational {{Semantic Search}}: {{Looking BeyondWeb Search}}, {{Q}}\&{{A}} and {{Dialog Systems}}},
  shorttitle = {Conversational {{Semantic Search}}},
  author = {Crook, Paul A. and Marin, Alex and Agarwal, Vipul and Anderson, Samantha and Jang, Ohyoung and Lanewala, Aliasgar and Tangirala, Karthik and Zitouni, Imed},
  date = {2018-02-05},
  url = {https://www.microsoft.com/en-us/research/publication/conversational-semantic-search-looking-beyondweb-search-qa-and-dialog-systems/},
  urldate = {2023-07-06},
  abstract = {User expectations of web search are changing. They are expecting search engines to answer questions, to be more conversational, and to offer means to complete tasks on their behalf. At the same time, to increase the breadth of tasks that personal digital assistants (PDAs), such as Microsoft’s Cortana or Amazon’s Alexa, are capable of, PDAs […]},
  eventtitle = {The 11th {{ACM International Conference}} on {{Web Search}} and {{Data Minining}} ({{WSDM}} 2018)},
  langid = {american},
  file = {/home/carlos/Zotero/storage/XS5AUBND/Crook et al. - 2018 - Conversational Semantic Search Looking BeyondWeb .pdf}
}

@book{Csound_book,
  title = {The {{Csound}} Book. {{Perspectives}} in Software Synthesis, Sound Design, Signal Processing, and Programming},
  editor = {Boulanger, Richard},
  date = {2000},
  publisher = {{The MIT Press}},
  location = {{Massachusetts}}
}

@book{Curtis,
  title = {The Computer Music Tutorial},
  author = {Roads, Curtis and Strawn, John and Abbott, Curtis and Gordon, John and Philip, Greenspun},
  date = {1996},
  publisher = {{The MIT Press}},
  location = {{Cambride}}
}

@misc{Cycling74,
  type = {página web},
  title = {Cycling '74},
  url = {https://cycling74.com/products/max/}
}

@article{dalessandroPipesPatchesListening2019,
  title = {Of {{Pipes}} and {{Patches}}: {{Listening}} to Augmented Pipe Organs},
  shorttitle = {Of {{Pipes}} and {{Patches}}},
  author = {family=Alessandro, given=Christophe, prefix=d’, useprefix=true and Noisternig, Markus},
  date = {2019-04},
  journaltitle = {Organised Sound},
  volume = {24},
  number = {1},
  pages = {41--53},
  publisher = {{Cambridge University Press}},
  issn = {1355-7718, 1469-8153},
  doi = {10.1017/S1355771819000050},
  url = {https://www.cambridge.org/core/journals/organised-sound/article/abs/of-pipes-and-patches-listening-to-augmented-pipe-organs/E7B136E381EA07C94ACB34F691AC8077},
  urldate = {2023-05-23},
  abstract = {Pipe organs are complex timbral synthesisers in an early acousmatic setting, which have always accompanied the evolution of music and technology. The most recent development is digital augmentation: the organ sound is captured, transformed and then played back in real time. The present augmented organ project relies on three main aesthetic principles: microphony, fusion and instrumentality. Microphony means that sounds are captured inside the organ case, close to the pipes. Real-time audio effects are then applied to the internal sounds before they are played back over loudspeakers; the transformed sounds interact with the original sounds of the pipe organ. The fusion principle exploits the blending effect of the acoustic space surrounding the instrument; the room response transforms the sounds of many single-sound sources into a consistent and organ-typical soundscape at the listener’s position. The instrumentality principle restricts electroacoustic processing to organ sounds only, excluding non-organ sound sources or samples. This article proposes a taxonomy of musical effects. It discusses aesthetic questions concerning the perceptual fusion of acoustic and electronic sources. Both extended playing techniques and digital audio can create musical gestures that conjoin the heterogeneous sonic worlds of pipe organs and electronics. This results in a paradoxical listening experience of unity in the diversity: the music is at the same time electroacoustic and instrumental.},
  langid = {english},
  file = {/home/carlos/Zotero/storage/S3QC9Z3B/d’Alessandro y Noisternig - 2019 - Of Pipes and Patches Listening to augmented pipe .pdf}
}

@inproceedings{daumaldomenechCabinasEstudioConservatorios2013a,
  title = {Cabinas de estudio en conservatorios en España: un estado de la cuestión y directrices para una buenas prácticas en diseño, construcción y rehabilitación},
  shorttitle = {Cabinas de estudio en conservatorios en España},
  author = {Daumal Domènech, Francesc de Paula and Luceño Ramos, María Luisa},
  date = {2013},
  pages = {1062--1069},
  publisher = {{Sociedad Española de Acústica (SEA)}},
  url = {https://upcommons.upc.edu/handle/2117/26254},
  urldate = {2023-05-23},
  eventtitle = {Tecniacústica 2013: 44º Congreso español de acústica, EAA European symposium on environmental acoustics and noise mapping: Valladolid, 1-4 octubre, 2014: publicación oficial del congreso},
  isbn = {978-84-87985-23-2},
  langid = {spanish},
  keywords = {Aïllament acústic,Àrees temàtiques de la UPC::Física::Acústica,Conservatories of music -- Rehabilitation,Conservatoris de música -- Construcció,Conservatoris de música -- Rehabilitació,Soundproofing,Stage fright},
  annotation = {Accepted: 2015-02-06T13:13:58Z},
  file = {/home/carlos/Zotero/storage/BB6T6LLU/Daumal Domènech y Luceño Ramos - 2013 - Cabinas de estudio en conservatorios en España un.pdf}
}

@online{DeepLearningDL,
  title = {Deep {{Learning}} ({{DL}})},
  url = {http://mriquestions.com/what-is-a-neural-network.html},
  urldate = {2023-12-21},
  abstract = {Deep Learning (DL)},
  langid = {english},
  organization = {{Questions and Answers \hspace{0pt}in MRI}},
  file = {/home/carlos/Zotero/storage/H68M27JI/what-is-a-neural-network.html}
}

@article{departmentofcomputersciencesrminstituteofscienceandtechnologychennaiindia.MusenetMusicGeneration2020a,
  title = {Musenet : {{Music Generation}} Using {{Abstractive}} and {{Generative Methods}}},
  shorttitle = {Musenet},
  author = {{Department of Computer Science, SRM Institute of Science and Technology, Chennai, India.} and Pal*, Abhilash and Saha, Sourav and {Department of Computer Science, SRM Institute of Science and Technology, Chennai, India.} and {Anita} and {Department of Computer Science, SRM Institute of Science and Technology, Chennai, India.}},
  date = {2020-04-30},
  journaltitle = {International Journal of Innovative Technology and Exploring Engineering},
  shortjournal = {IJITEE},
  volume = {9},
  number = {6},
  pages = {784--788},
  issn = {22783075},
  doi = {10.35940/ijitee.F3580.049620},
  url = {https://www.ijitee.org/portfolio-item/F3580049620/},
  urldate = {2023-12-26},
  abstract = {Humans have been entertained by music for millennia. For ages it has been treated as an art form which requires a lot of imagination, creativity and accumulation of feelings and emotions. Recent trends in the field of Artificial Intelligence have been getting traction and Researchers have been developing and generating rudimentary forms of music through the use of AI. Our goal is to generate novel music, which will be non-repetitive and enjoyable. We aim to utilize a couple of Machine Learning models for the same. Given a seed bar of music, our first Discriminatory network consisting of Support Vector Machines and Neural Nets will choose a note/chord to direct the next bar. Based on this chord or note another network, a Generative Net consisting of Generative Pretrained Transformers(GPT2) and LSTMs will generate the entire bar of music. Our two fold method is novel and our aim is to make the generation method as similar to music composition in reality as possible. This in turn results in better concordant music. Machine generated music will be copyright free and can be generated conditioned on a few parameters for a given use.The paper presents several use cases and while the utilization will be for a niche audience, if a easy to use application can be built, almost anyone will be able to use deep learning to generate concordant music based on their needs.},
  file = {/home/carlos/Zotero/storage/MUPRNIQZ/Department of Computer Science, SRM Institute of Science and Technology, Chennai, India. et al. - 2020 - Musenet  Music Generation using Abstractive and G.pdf}
}

@online{dhariwalJukeboxGenerativeModel2020,
  title = {Jukebox: {{A Generative Model}} for {{Music}}},
  shorttitle = {Jukebox},
  author = {Dhariwal, Prafulla and Jun, Heewoo and Payne, Christine and Kim, Jong Wook and Radford, Alec and Sutskever, Ilya},
  date = {2020-04-30},
  eprint = {2005.00341},
  eprinttype = {arxiv},
  eprintclass = {cs, eess, stat},
  doi = {10.48550/arXiv.2005.00341},
  url = {http://arxiv.org/abs/2005.00341},
  urldate = {2023-12-26},
  abstract = {We introduce Jukebox, a model that generates music with singing in the raw audio domain. We tackle the long context of raw audio using a multi-scale VQ-VAE to compress it to discrete codes, and modeling those using autoregressive Transformers. We show that the combined model at scale can generate high-fidelity and diverse songs with coherence up to multiple minutes. We can condition on artist and genre to steer the musical and vocal style, and on unaligned lyrics to make the singing more controllable. We are releasing thousands of non cherry-picked samples at https://jukebox.openai.com, along with model weights and code at https://github.com/openai/jukebox},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing,Statistics - Machine Learning},
  file = {/home/carlos/Zotero/storage/B294RLLC/Dhariwal et al. - 2020 - Jukebox A Generative Model for Music.pdf;/home/carlos/Zotero/storage/UKDJBJNM/2005.html}
}

@online{dhuliawalaChainofVerificationReducesHallucination2023,
  title = {Chain-of-{{Verification Reduces Hallucination}} in {{Large Language Models}}},
  author = {Dhuliawala, Shehzaad and Komeili, Mojtaba and Xu, Jing and Raileanu, Roberta and Li, Xian and Celikyilmaz, Asli and Weston, Jason},
  date = {2023-09-25},
  eprint = {2309.11495},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2309.11495},
  url = {http://arxiv.org/abs/2309.11495},
  urldate = {2023-10-30},
  abstract = {Generation of plausible yet incorrect factual information, termed hallucination, is an unsolved issue in large language models. We study the ability of language models to deliberate on the responses they give in order to correct their mistakes. We develop the Chain-of-Verification (CoVe) method whereby the model first (i) drafts an initial response; then (ii) plans verification questions to fact-check its draft; (iii) answers those questions independently so the answers are not biased by other responses; and (iv) generates its final verified response. In experiments, we show CoVe decreases hallucinations across a variety of tasks, from list-based questions from Wikidata, closed book MultiSpanQA and longform text generation.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/carlos/Zotero/storage/JLP8R4IU/Dhuliawala et al. - 2023 - Chain-of-Verification Reduces Hallucination in Lar.pdf;/home/carlos/Zotero/storage/5L75C6YB/2309.html}
}

@article{disleyExplorationTimbraiSemantics,
  title = {An Exploration of Timbrai Semantics Related to the Pipe Organ},
  author = {Disley, Alastair Christian},
  abstract = {Timbral semantics is the study of adjectives relating to timbre. This thesis takes existing research on timbral adjectives relating to single source sounds and applies it to the pipe organ, a complex multi-source musical instrument.},
  langid = {english},
  file = {/home/carlos/Zotero/storage/9U8T5YVJ/Disley - An exploration of timbrai semantics related to the.pdf}
}

@online{douglasLargeLanguageModels2023,
  title = {Large {{Language Models}}},
  author = {Douglas, Michael R.},
  date = {2023-07-11},
  eprint = {2307.05782},
  eprinttype = {arxiv},
  eprintclass = {hep-th, physics:physics},
  doi = {10.48550/arXiv.2307.05782},
  url = {http://arxiv.org/abs/2307.05782},
  urldate = {2023-09-27},
  abstract = {Artificial intelligence is making spectacular progress, and one of the best examples is the development of large language models (LLMs) such as OpenAI's GPT series. In these lectures, written for readers with a background in mathematics or physics, we give a brief history and survey of the state of the art, and describe the underlying transformer architecture in detail. We then explore some current ideas on how LLMs work and how models trained to predict the next word in a text are able to perform other tasks displaying intelligence.},
  pubstate = {preprint},
  keywords = {68T01,Computer Science - Computation and Language,High Energy Physics - Theory,I.2.7,Mathematics - History and Overview,Physics - Computational Physics},
  file = {/home/carlos/Zotero/storage/MTB9SGS5/Douglas - 2023 - Large Language Models.pdf;/home/carlos/Zotero/storage/Y46IYSSF/2307.html}
}

@article{duAddressingSyntaxBasedSemantic2022,
  title = {Addressing {{Syntax-Based Semantic Complementation}}: {{Incorporating Entity}} and {{Soft Dependency Constraints}} into {{Metonymy Resolution}}},
  shorttitle = {Addressing {{Syntax-Based Semantic Complementation}}},
  author = {Du, Siyuan and Wang, Hao},
  date = {2022-03},
  journaltitle = {Future Internet},
  volume = {14},
  number = {3},
  pages = {85},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {1999-5903},
  doi = {10.3390/fi14030085},
  url = {https://www.mdpi.com/1999-5903/14/3/85},
  urldate = {2023-12-25},
  abstract = {State-of-the-art methods for metonymy resolution (MR) consider the sentential context by modeling the entire sentence. However, entity representation, or syntactic structure that are informative may be beneficial for identifying metonymy. Other approaches only using deep neural network fail to capture such information. To leverage both entity and syntax constraints, this paper proposes a robust model EBAGCN for metonymy resolution. First, this work extracts syntactic dependency relations under the guidance of syntactic knowledge. Then the work constructs a neural network to incorporate both entity representation and syntactic structure into better resolution representations. In this way, the proposed model alleviates the impact of noisy information from entire sentences and breaks the limit of performance on the complicated texts. Experiments on the SemEval and ReLocaR dataset show that the proposed model significantly outperforms the state-of-the-art method BERT by more than 4\%. Ablation tests demonstrate that leveraging these two types of constraints benefits fine pre-trained language models in the MR task.},
  issue = {3},
  langid = {english},
  keywords = {dependency integration,entity representation,metonymy resolution},
  file = {/home/carlos/Zotero/storage/AP3AK6JY/Du y Wang - 2022 - Addressing Syntax-Based Semantic Complementation .pdf}
}

@book{duffin2008equal,
  title = {How Equal Temperament Ruined Harmony (and Why You Should Care)},
  author = {Duffin, R.W.},
  date = {2008},
  publisher = {{W. W. Norton}},
  url = {https://books.google.es/books?id=i5LC7Csnw7UC},
  isbn = {978-0-393-07564-9}
}

@misc{ElectronicMuscicStudios1998,
  type = {página web},
  title = {Electronic {{Muscic Studios}}},
  date = {1998},
  url = {http://emssynthesisers.co.uk/}
}

@article{emeryAnatomyPipeOrgan,
  title = {Anatomy of a {{Pipe Organ}}:},
  author = {Emery, James C},
  abstract = {This brief overview of fundamental acoustical principles of a pipe organ is presented as a teaching module for the inquiring young student in the music education classroom.},
  langid = {english},
  file = {/home/carlos/Zotero/storage/WBL6XMM5/Emery - Anatomy of a Pipe Organ.pdf}
}

@misc{ems,
  type = {página web},
  title = {Electronic Muscic Studios},
  date = {1998},
  url = {http://emssynthesisers.co.uk/}
}

@online{erkerImaginationAllYou2023,
  title = {Imagination Is {{All You Need}}! {{Curved Contrastive Learning}} for {{Abstract Sequence Modeling Utilized}} on {{Long Short-Term Dialogue Planning}}},
  author = {Erker, Justus-Jonas and Schaffer, Stefan and Spanakis, Gerasimos},
  date = {2023-06-26},
  eprint = {2211.07591},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2211.07591},
  url = {http://arxiv.org/abs/2211.07591},
  urldate = {2024-01-22},
  abstract = {Inspired by the curvature of space-time (Einstein, 1921), we introduce Curved Contrastive Learning (CCL), a novel representation learning technique for learning the relative turn distance between utterance pairs in multi-turn dialogues. The resulting bi-encoder models can guide transformers as a response ranking model towards a goal in a zero-shot fashion by projecting the goal utterance and the corresponding reply candidates into a latent space. Here the cosine similarity indicates the distance/reachability of a candidate utterance toward the corresponding goal. Furthermore, we explore how these forward-entailing language representations can be utilized for assessing the likelihood of sequences by the entailment strength i.e. through the cosine similarity of its individual members (encoded separately) as an emergent property in the curved space. These non-local properties allow us to imagine the likelihood of future patterns in dialogues, specifically by ordering/identifying future goal utterances that are multiple turns away, given a dialogue context. As part of our analysis, we investigate characteristics that make conversations (un)plannable and find strong evidence of planning capability over multiple turns (in 61.56\% over 3 turns) in conversations from the DailyDialog (Li et al., 2017) dataset. Finally, we show how we achieve higher efficiency in sequence modeling tasks compared to previous work thanks to our relativistic approach, where only the last utterance needs to be encoded and computed during inference.},
  pubstate = {preprint},
  version = {2},
  keywords = {Computer Science - Computation and Language},
  file = {/home/carlos/Zotero/storage/8M275USC/Erker et al. - 2023 - Imagination is All You Need! Curved Contrastive Learning for Abstract Sequence Modeling Utilized on .pdf;/home/carlos/Zotero/storage/TA4U6C5F/2211.html}
}

@article{escalasllimonaTemperamentTuningEarly2013,
  title = {Temperament and Tuning of Early 19th Century {{Hispanic}} Keyboard Instruments: {{A}} Study of the Monochord Integrated into a Fortepiano Made by {{Francisco Fernández}} (1828)},
  shorttitle = {Temperament and Tuning of Early 19th Century {{Hispanic}} Keyboard Instruments},
  author = {Escalas Llimona, Romà},
  date = {2013},
  journaltitle = {Contributions to Science},
  volume = {9},
  number = {1},
  pages = {75--88},
  publisher = {{Section of Science and Technology}},
  issn = {1575-6343},
  url = {https://dialnet.unirioja.es/servlet/articulo?codigo=5047287},
  urldate = {2023-05-31},
  abstract = {The recovery of previously used tuning systems of musical instruments, led by the interpreters of historical repertoires, has widened our knowledge and our aesthetic perception of the sounds, harmonies, and repertoires of works from those times. For only a very few instruments have we been able to determine the original tones, whereas the mechanisms designed to tune keyboard instruments are of a remarkable reliability. Among the latter is the monochord integrated into the fortepiano made by Francisco Fernández in 1828. In this article, we evaluate the measurements, both physical and acoustic, of the tones of this device, and offer comparisons. Based on the conclusions of this analysis, we define a tuning system closely linked to another, contemporary one but with unique features that result in a number of sonorities perfectly adapted to the performance and aesthetics of the musical repertoires of Romanticism. Moreover, this system, which was probably used until the early 20th century, offers us a new harmonic coloring, one especially suited to the Iberian repertoire of the same time. La recuperació dels sistemes d’afinació dels instruments musicals anteriors al sistema actual, liderada pels intèrprets dels repertoris històrics, ha eixamplat el nostre coneixement i la nostra percepció estètica dels sons, les harmonies i els repertoris procedents de les obres d’altres èpoques. Només hem estat capaços de determinar els sons originals de molt pocs instruments, mentre que els mecanismes ideats per afinar instruments de teclat són d’una fia- bilitat considerable. Entre aquests últims hi ha el monocordi integrat al fortepiano de Fran- cisco Fernández del 1828. En aquest article analitzem les mesures, físiques i acústiques, dels sons d’aquest aparell i oferim comparacions. Basant-nos en les conclusions d’aquesta anàlisi, hem definit un sistema d’afinació que té molta relació amb d’altres de contemporanis seus, però amb característiques pròpies que fan que gaudeixi d’unes sonoritats perfectament adap- tades a la interpretació i l’estètica dels repertoris musicals del Romanticisme. Alhora aquest sistema, probablement emprat fins a principis del segle xx, ofereix un nou colorit harmònic, especialment adequat al repertori ibèric de la mateixa època.},
  langid = {english},
  file = {/home/carlos/Zotero/storage/KIFS5JVZ/articulo.html}
}

@book{everestMasterHandbookAcoustics2009,
  title = {Master {{Handbook}} of {{Acoustics}}},
  author = {Everest, F. Alton and Pohlmann, Ken},
  date = {2009-05-31},
  eprint = {6tiJ1cwnwxoC},
  eprinttype = {googlebooks},
  publisher = {{McGraw Hill Professional}},
  abstract = {Practical Instruction on the Art and Science of Acoustic Design and Architecture Build your own acoustic environments such as recording studios, control rooms, and home listening rooms with expert insights from two engineering professionals. Fully expanded to cover the latest methods and software tools, Master Handbook of Acoustics, Fifth Edition presents clear explanations of acoustic phenomena and provides a hands-on approach to room design. Learn how to perform acoustic measurements, choose room dimensions, assign speaker placement, analyze response curves, and design and install sound absorbers and diffusers. You will also find details on how to fine-tune room reverberation, minimize external noise, and apply psychoacoustic concepts. Master Handbook of Acoustics, Fifth Edition explains how to: Determine how sound propagates in open and enclosed spaces Measure sound-pressure levels and work with decibels Analyze the characteristics of room modal resonances Treat rooms for optimal early reflections, reverberation, and diffusion Minimize acoustic distortion, comb-filter effects, and HVAC interference Construct high-quality stereo and surround-sound listening rooms Design personal and professional recording studios and control rooms Understand the acoustics of auditoriums and concert halls Optimize room designs using measurement, modeling, and auralization software},
  isbn = {978-0-07-160333-1},
  langid = {english},
  pagetotal = {530},
  keywords = {Music / Recording \& Reproduction}
}

@online{eysenbachDiversityAllYou2018,
  title = {Diversity Is {{All You Need}}: {{Learning Skills}} without a {{Reward Function}}},
  shorttitle = {Diversity Is {{All You Need}}},
  author = {Eysenbach, Benjamin and Gupta, Abhishek and Ibarz, Julian and Levine, Sergey},
  date = {2018-10-09},
  eprint = {1802.06070},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1802.06070},
  url = {http://arxiv.org/abs/1802.06070},
  urldate = {2024-01-22},
  abstract = {Intelligent creatures can explore their environments and learn useful skills without supervision. In this paper, we propose DIAYN ('Diversity is All You Need'), a method for learning useful skills without a reward function. Our proposed method learns skills by maximizing an information theoretic objective using a maximum entropy policy. On a variety of simulated robotic tasks, we show that this simple objective results in the unsupervised emergence of diverse skills, such as walking and jumping. In a number of reinforcement learning benchmark environments, our method is able to learn a skill that solves the benchmark task despite never receiving the true task reward. We show how pretrained skills can provide a good parameter initialization for downstream tasks, and can be composed hierarchically to solve complex, sparse reward tasks. Our results suggest that unsupervised discovery of skills can serve as an effective pretraining mechanism for overcoming challenges of exploration and data efficiency in reinforcement learning.},
  pubstate = {preprint},
  version = {6},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Robotics},
  file = {/home/carlos/Zotero/storage/FSHXYMD5/Eysenbach et al. - 2018 - Diversity is All You Need Learning Skills without a Reward Function.pdf;/home/carlos/Zotero/storage/HUTK4SCB/1802.html}
}

@book{farinaTipologiasArquitectonicasCalidad2019,
  title = {Tipologías Arquitectónicas y Calidad Acústica de Salas Para Música},
  author = {Farina, María Andrea},
  date = {2019},
  publisher = {{Universidad Nacional de Quilmes Editorial}}
}

@online{FindWaysDeal,
  title = {Find ways to deal with the scarcity of labeled data},
  url = {https://www.linkedin.com/pulse/find-ways-deal-scarcity-labeled-data-amit-asawa},
  urldate = {2023-12-21},
  abstract = {Compared to other available choices such as unsupervised and deep learning algorithms: the whole learning process of supervised machine learning (ML) based algorithms is much simpler; the training \& deployment costs are considerably low too; and most importantly supervised models work perfectly for},
  langid = {spanish},
  file = {/home/carlos/Zotero/storage/K3EN3SDY/find-ways-deal-scarcity-labeled-data-amit-asawa.html}
}

@book{fletcherPhysicsMusicalInstruments1998,
  title = {The {{Physics}} of {{Musical Instruments}}},
  author = {Fletcher, Neville H. and Rossing, Thomas D.},
  date = {1998},
  publisher = {{Springer}},
  location = {{New York, NY}},
  doi = {10.1007/978-0-387-21603-4},
  url = {http://link.springer.com/10.1007/978-0-387-21603-4},
  urldate = {2023-05-24},
  isbn = {978-1-4419-3120-7 978-0-387-21603-4},
  langid = {english},
  keywords = {Dulcimer,Gong,Harp,Horn,Music / General,Pi,Piano,Science / Acoustics \& Sound,Science / Physics / General,Science / Waves \& Wave Mechanics,Tar,Vibration,Wave},
  file = {/home/carlos/Zotero/storage/Y92F6W7P/Fletcher y Rossing - 1998 - The Physics of Musical Instruments.pdf}
}

@article{fletcherRecentProgressAcoustics2001,
  title = {Recent Progress in the Acoustics of Wind Instruments},
  author = {Fletcher, Neville},
  date = {2001-12-28},
  journaltitle = {Acoustical Science and Technology},
  shortjournal = {Acoustical Science and Technology},
  volume = {22},
  doi = {10.1250/ast.22.169},
  abstract = {Progress made over the past decade in understanding the mechanisms of sound production in music wind instruments is reviewed. The behavior of air columns, horns, and fingerholes is now fairly well understood, and most recent interest centers on details of the sound generator — the reed in woodwinds, the lips in brass instruments, and the air jet in flute-family instruments. Not only do these generators produce the sound, but they are also largely responsible, through their nonlinearity, for controlling the harmonic content and thus the musical timbre of the instrument, the one major excep-tion being in loud playing on brass instruments where propagation nonlinearities in the air column are also important. Despite considerable progress, there remain important and interesting questions to be answered.},
  file = {/home/carlos/Zotero/storage/RWGWZH92/Fletcher - 2001 - Recent progress in the acoustics of wind instrumen.pdf}
}

@online{frackiewiczEvolucionIAComposicion2023,
  title = {La evolución de la IA en la composición musical},
  author = {Frąckiewicz, Marcin},
  date = {2023-07-07T10:31:00+00:00},
  url = {https://ts2.space/es/la-evolucion-de-la-ia-en-la-composicion-musical/},
  urldate = {2023-11-03},
  abstract = {La evolución de la IA en la composición musical TS2 SPACE},
  langid = {spanish},
  organization = {{TS2 SPACE}},
  file = {/home/carlos/Zotero/storage/Z76TKKBM/la-evolucion-de-la-ia-en-la-composicion-musical.html}
}

@misc{free_emulations,
  type = {página web},
  title = {Free {{EMS VCS3}} and Synthi {{AKS VST}} Emulations},
  url = {https://blog.wavosaur.com/free-ems-vcs3-synthi-aks-vst-emulations/}
}

@misc{FreeEMSVCS3,
  type = {página web},
  title = {Free {{EMS VCS3}} and {{Synthi AKS VST}} Emulations},
  url = {https://blog.wavosaur.com/free-ems-vcs3-synthi-aks-vst-emulations/}
}

@inproceedings{fuentecharfoleFondoMusicalArchivo2022,
  title = {El fondo musical del archivo capitular de la catedral de Cuenca: de los inventarios al catálogo (1578-1965)},
  shorttitle = {El fondo musical del archivo capitular de la catedral de Cuenca},
  booktitle = {De memoria scribenda et custodienda: miscelánea de estudios sobre archivos catedralicios, monásticos y de órdenes militares, 2022, ISBN 978-84-16242-36-8, págs. 67-87},
  author = {family=Fuente Charfolé, given=José Luis, prefix=de la, useprefix=false},
  date = {2022},
  pages = {67--87},
  publisher = {{La Ergástula}},
  url = {https://dialnet.unirioja.es/servlet/articulo?codigo=8851884},
  urldate = {2023-07-10},
  eventtitle = {De memoria scribenda et custodienda: miscelánea de estudios sobre archivos catedralicios, monásticos y de órdenes militares},
  isbn = {978-84-16242-36-8},
  langid = {spanish},
  file = {/home/carlos/Zotero/storage/4M699967/articulo.html}
}

@article{fuentecharfolePapelesMusicaMiguel2017,
  title = {Los papeles de música de Miguel Martínez Millán, organista de la Catedral de Cuenca},
  author = {family=Fuente Charfolé, given=José Luis, prefix=de la, useprefix=false},
  date = {2017},
  journaltitle = {Lope de Barrientos: Seminario de cultura},
  number = {10},
  pages = {2},
  publisher = {{Asociación Seminario de Cultura Lope de Barrientos}},
  issn = {1888-9530},
  url = {https://dialnet.unirioja.es/servlet/articulo?codigo=7079268},
  urldate = {2023-07-10},
  abstract = {El artículo presenta la sinopsis de un legado documental, aportado por el organista de la catedral de Cuenca, Miguel Martínez Millán, de gran interés para el estudio del movimiento regeneracionista musical (siglo XX), y su recepción en Castilla-La Mancha This paper presents the original synopsis of an uninvestigated legacy, provided by the organist of Cuenca Cathedral, Miguel Martínez Millán, who may be of interest for the study of the reception of the Reformist movement (XX Century) in Castilla-La Mancha},
  langid = {spanish},
  file = {/home/carlos/Zotero/storage/T8ZAIM7C/articulo.html}
}

@article{funkMusicalSuiteComposed2018a,
  title = {A {{Musical Suite Composed}} by an {{Electronic Brain}}: {{Reexamining}} the {{Illiac Suite}} and the {{Legacy}} of {{Lejaren A}}. {{Hiller Jr}}.},
  shorttitle = {A {{Musical Suite Composed}} by an {{Electronic Brain}}},
  author = {Funk, Tiffany},
  date = {2018},
  journaltitle = {Leonardo Music Journal},
  volume = {28},
  pages = {19--24},
  publisher = {{MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info …}},
  url = {https://direct.mit.edu/lmj/article-abstract/doi/10.1162/lmj_a_01037/69560},
  urldate = {2023-12-28},
  file = {/home/carlos/Zotero/storage/JSP23EKX/Funk - 2018 - A Musical Suite Composed by an Electronic Brain R.pdf}
}

@misc{fuzzy,
  type = {página web},
  title = {Fuzzy Gab 4},
  date = {2020},
  url = {http://fuzzygab.uclm.es/}
}

@misc{FuzzyGab2020,
  type = {página web},
  title = {Fuzzy {{Gab}} 4},
  date = {2020},
  url = {http://fuzzygab.uclm.es/}
}

@incollection{gadeAcousticsHallsSpeech2007,
  title = {Acoustics in {{Halls}} for {{Speech}} and {{Music}}},
  booktitle = {Springer {{Handbook}} of {{Acoustics}}},
  author = {Gade, Anders},
  editor = {Rossing, Thomas D.},
  date = {2007},
  series = {Springer {{Handbooks}}},
  pages = {301--350},
  publisher = {{Springer}},
  location = {{New York, NY}},
  doi = {10.1007/978-0-387-30425-0_9},
  url = {https://doi.org/10.1007/978-0-387-30425-0_9},
  urldate = {2023-05-23},
  abstract = {This chapter deals specifically with concepts, tools, and architectural variables of importance when designing auditoria for speech and music. The focus will be on cultivating the useful components of the sound in the room rather than on avoiding noise from outside or from installations, which is dealt with in Chap.~11. The chapter starts by presenting the subjective aspects of the room acoustic experience according to consensus at the time of writing. Then follows a~description of their objective counterparts, the objective room acoustic parameters, among which the classical reverberation time measure is only one of many, but still of fundamental value. After explanations on how these parameters can be measured and predicted during the design phase, the remainder of the chapter deals with how the acoustic properties can be controlled by the architectural design of auditoria. This is done by presenting the influence of individual design elements as well as brief descriptions of halls designed for specific purposes, such as drama, opera, and symphonic concerts. Finally, some important aspects of loudspeaker installations in auditoria are briefly touched upon.},
  isbn = {978-0-387-30425-0},
  langid = {english},
  keywords = {Acoustic Parameter,Classical Music,Impulse Response,Sound Field,Sound Source}
}

@book{gaínza2004afinación,
  title = {Afinación y Temperamentos Históricos},
  author = {Gaínza, J.J.G.},
  date = {2004},
  series = {Alianza Música},
  publisher = {{Alianza Editorial}},
  url = {https://books.google.es/books?id=0LnewAEACAAJ},
  isbn = {978-84-206-6546-7}
}

@inproceedings{ganguliPredictabilitySurpriseLarge2022,
  title = {Predictability and {{Surprise}} in {{Large Generative Models}}},
  booktitle = {2022 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Ganguli, Deep and Hernandez, Danny and Lovitt, Liane and DasSarma, Nova and Henighan, Tom and Jones, Andy and Joseph, Nicholas and Kernion, Jackson and Mann, Ben and Askell, Amanda and Bai, Yuntao and Chen, Anna and Conerly, Tom and Drain, Dawn and Elhage, Nelson and Showk, Sheer El and Fort, Stanislav and Hatfield-Dodds, Zac and Johnston, Scott and Kravec, Shauna and Nanda, Neel and Ndousse, Kamal and Olsson, Catherine and Amodei, Daniela and Amodei, Dario and Brown, Tom and Kaplan, Jared and McCandlish, Sam and Olah, Chris and Clark, Jack},
  date = {2022-06-21},
  eprint = {2202.07785},
  eprinttype = {arxiv},
  eprintclass = {cs},
  pages = {1747--1764},
  doi = {10.1145/3531146.3533229},
  url = {http://arxiv.org/abs/2202.07785},
  urldate = {2023-06-27},
  abstract = {Large-scale pre-training has recently emerged as a technique for creating capable, general purpose, generative models such as GPT-3, Megatron-Turing NLG, Gopher, and many others. In this paper, we highlight a counterintuitive property of such models and discuss the policy implications of this property. Namely, these generative models have an unusual combination of predictable loss on a broad training distribution (as embodied in their "scaling laws"), and unpredictable specific capabilities, inputs, and outputs. We believe that the high-level predictability and appearance of useful capabilities drives rapid development of such models, while the unpredictable qualities make it difficult to anticipate the consequences of model deployment. We go through examples of how this combination can lead to socially harmful behavior with examples from the literature and real world observations, and we also perform two novel experiments to illustrate our point about harms from unpredictability. Furthermore, we analyze how these conflicting properties combine to give model developers various motivations for deploying these models, and challenges that can hinder deployment. We conclude with a list of possible interventions the AI community may take to increase the chance of these models having a beneficial impact. We intend this paper to be useful to policymakers who want to understand and regulate AI systems, technologists who care about the potential policy impact of their work, and academics who want to analyze, critique, and potentially develop large generative models.},
  langid = {english},
  keywords = {Computer Science - Computers and Society},
  file = {/home/carlos/Zotero/storage/93WQ2BRW/Ganguli et al. - 2022 - Predictability and Surprise in Large Generative Mo.pdf}
}

@online{geipingCrammingTrainingLanguage2022,
  title = {Cramming: {{Training}} a {{Language Model}} on a {{Single GPU}} in {{One Day}}},
  shorttitle = {Cramming},
  author = {Geiping, Jonas and Goldstein, Tom},
  date = {2022-12-28},
  eprint = {2212.14034},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2212.14034},
  url = {http://arxiv.org/abs/2212.14034},
  urldate = {2023-09-27},
  abstract = {Recent trends in language modeling have focused on increasing performance through scaling, and have resulted in an environment where training language models is out of reach for most researchers and practitioners. While most in the community are asking how to push the limits of extreme computation, we ask the opposite question: How far can we get with a single GPU in just one day? We investigate the downstream performance achievable with a transformer-based language model trained completely from scratch with masked language modeling for a single day on a single consumer GPU. Aside from re-analyzing nearly all components of the pretraining pipeline for this scenario and providing a modified pipeline with performance close to BERT, we investigate why scaling down is hard, and which modifications actually improve performance in this scenario. We provide evidence that even in this constrained setting, performance closely follows scaling laws observed in large-compute settings. Through the lens of scaling laws, we categorize a range of recent improvements to training and architecture and discuss their merit and practical applicability (or lack thereof) for the limited compute setting.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/carlos/Zotero/storage/KHP5YQLU/Geiping y Goldstein - 2022 - Cramming Training a Language Model on a Single GP.pdf;/home/carlos/Zotero/storage/PDTSUDC9/2212.html}
}

@online{GenerationLLMs,
  title = {Generation with {{LLMs}}},
  url = {https://huggingface.co/docs/transformers/main/en/llm_tutorial},
  urldate = {2023-10-31},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
  file = {/home/carlos/Zotero/storage/Q83ZWSQC/llm_tutorial.html}
}

@online{gillickLearningGrooveInverse2019,
  title = {Learning to {{Groove}} with {{Inverse Sequence Transformations}}},
  author = {Gillick, Jon and Roberts, Adam and Engel, Jesse and Eck, Douglas and Bamman, David},
  date = {2019-07-26},
  eprint = {1905.06118},
  eprinttype = {arxiv},
  eprintclass = {cs, eess, stat},
  doi = {10.48550/arXiv.1905.06118},
  url = {http://arxiv.org/abs/1905.06118},
  urldate = {2023-05-24},
  abstract = {We explore models for translating abstract musical ideas (scores, rhythms) into expressive performances using Seq2Seq and recurrent Variational Information Bottleneck (VIB) models. Though Seq2Seq models usually require painstakingly aligned corpora, we show that it is possible to adapt an approach from the Generative Adversarial Network (GAN) literature (e.g. Pix2Pix (Isola et al., 2017) and Vid2Vid (Wang et al. 2018a)) to sequences, creating large volumes of paired data by performing simple transformations and training generative models to plausibly invert these transformations. Music, and drumming in particular, provides a strong test case for this approach because many common transformations (quantization, removing voices) have clear semantics, and models for learning to invert them have real-world applications. Focusing on the case of drum set players, we create and release a new dataset for this purpose, containing over 13 hours of recordings by professional drummers aligned with fine-grained timing and dynamics information. We also explore some of the creative potential of these models, including demonstrating improvements on state-of-the-art methods for Humanization (instantiating a performance from a musical score).},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Computer Science - Multimedia,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing,I.2,J.5,Statistics - Machine Learning},
  file = {/home/carlos/Zotero/storage/RAPVVQH7/Gillick et al. - 2019 - Learning to Groove with Inverse Sequence Transform.pdf;/home/carlos/Zotero/storage/ASKD5MG6/1905.html}
}

@book{GME,
  title = {Las Colecciones Del {{GME}}: Presente, Pasado y Futuro},
  author = {Molina, Sylvia and Osona, Javier and Sanz Vázquez, Julio and family=Saz, given=Daniel, prefix=del, useprefix=true and Alcázar, Antonio J.},
  date = {2018},
  edition = {1ª},
  publisher = {{Ed. de la Universidad de Castilla–La Mancha}},
  location = {{Cuenca}}
}

@misc{GNUGeneralPublic2016,
  type = {página web},
  title = {{{GNU General Public License}}},
  date = {2016-11},
  url = {https://www.gnu.org/licenses/gpl-3.0.html}
}

@online{gonzaloAsomandonosVentanaContextual2023,
  type = {Billet},
  title = {Asomándonos a la ventana contextual de la Inteligencia Artificial: decálogo de ayuda para la identificación del uso de ChatGPT en textos académicos},
  shorttitle = {Asomándonos a la ventana contextual de la Inteligencia Artificial},
  author = {Gonzalo, Jover and Carabantes, David and González Geraldo, José L.},
  date = {2023-06-02},
  url = {https://cuedespyd.hypotheses.org/13299},
  urldate = {2023-11-08},
  abstract = {Por Gonzalo Jover*, David Carabantes* y José L. González Geraldo** *Universidad Complutense de Madrid **Universidad de Castilla La Mancha Palabras clave:~ChatGPT, OpenAI, Inteligencia Artificial ~ Que la Inteligencia Artificial (IA) ha contaminado cada rincón de nuestra sociedad a un ritmo tan espeluznante como atractivo y peligroso es más que evidente a … Continuar leyendo "Asomándonos a la ventana contextual de la Inteligencia Artificial: decálogo de ayuda para la identificación del uso de ChatGPT en textos académicos"},
  langid = {spanish},
  organization = {{Aula Magna 2.0}},
  file = {/home/carlos/Zotero/storage/FZ5IHE5I/13299.html}
}

@book{Goodfellow-et-al-2016,
  title = {Deep Learning},
  author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  date = {2016},
  publisher = {{MIT Press}}
}

@misc{gpl,
  type = {página web},
  title = {{{GNU}} General Public License},
  date = {2016-11},
  url = {https://www.gnu.org/licenses/gpl-3.0.html}
}

@online{GPT3RiseFoundation,
  title = {GPT-3 and the rise of foundation models},
  url = {https://www.linkedin.com/pulse/gpt-3-rise-foundation-models-joseph-boland},
  urldate = {2023-12-10},
  abstract = {GPT-3 (Generative Pre-Trained Transformer 3) is a large language model with 175 billion parameters, trained using the Common Crawl internet dataset, Wikipedia, and several large digital document collections. Its transformer-based algorithm has demonstrated superior performance in text generation, co},
  langid = {spanish},
  file = {/home/carlos/Zotero/storage/9E6YS6FB/gpt-3-rise-foundation-models-joseph-boland.html}
}

@online{grahamOneModelAll2022,
  title = {One {{Model}} Is {{All You Need}}: {{Multi-Task Learning Enables Simultaneous Histology Image Segmentation}} and {{Classification}}},
  shorttitle = {One {{Model}} Is {{All You Need}}},
  author = {Graham, Simon and Vu, Quoc Dang and Jahanifar, Mostafa and Raza, Shan E. Ahmed and Minhas, Fayyaz and Snead, David and Rajpoot, Nasir},
  date = {2022-11-14},
  eprint = {2203.00077},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2203.00077},
  url = {http://arxiv.org/abs/2203.00077},
  urldate = {2024-01-22},
  abstract = {The recent surge in performance for image analysis of digitised pathology slides can largely be attributed to the advances in deep learning. Deep models can be used to initially localise various structures in the tissue and hence facilitate the extraction of interpretable features for biomarker discovery. However, these models are typically trained for a single task and therefore scale poorly as we wish to adapt the model for an increasing number of different tasks. Also, supervised deep learning models are very data hungry and therefore rely on large amounts of training data to perform well. In this paper, we present a multi-task learning approach for segmentation and classification of nuclei, glands, lumina and different tissue regions that leverages data from multiple independent data sources. While ensuring that our tasks are aligned by the same tissue type and resolution, we enable meaningful simultaneous prediction with a single network. As a result of feature sharing, we also show that the learned representation can be used to improve the performance of additional tasks via transfer learning, including nuclear classification and signet ring cell detection. As part of this work, we train our developed Cerberus model on a huge amount of data, consisting of over 600K objects for segmentation and 440K patches for classification. We use our approach to process 599 colorectal whole-slide images from TCGA, where we localise 377 million, 900K and 2.1 million nuclei, glands and lumina, respectively and make the results available to the community for downstream analysis.},
  pubstate = {preprint},
  version = {2},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/home/carlos/Zotero/storage/EFDRE7RU/Graham et al. - 2022 - One Model is All You Need Multi-Task Learning Enables Simultaneous Histology Image Segmentation and.pdf;/home/carlos/Zotero/storage/6E4DBE9Y/2203.html}
}

@book{grogonoSynthiEducationalHandbook1972,
  type = {folleto},
  title = {The {{Synthi Educational Handbook}}},
  author = {Grogono, Peter},
  date = {1972},
  publisher = {{Electronic Music Studios of American Inc}}
}

@thesis{guerraparraMesjetiuTFM_Arte_Sonoro_MEMORIA2020,
  title = {Mesjetiu/{{TFM}}\_{{Arte}}\_{{Sonoro}}\_{{MEMORIA}}},
  author = {Guerra Parra, Carlos Arturo},
  date = {2020},
  institution = {{Universidad de Barcelona}},
  url = {https://github.com/mesjetiu/TFM_Arte_Sonoro_MEMORIA},
  urldate = {2023-12-09},
  file = {/home/carlos/Zotero/storage/TRE2DQ8J/TFM_Arte_Sonoro_MEMORIA.html}
}

@online{gunasekarTextbooksAreAll2023,
  title = {Textbooks {{Are All You Need}}},
  author = {Gunasekar, Suriya and Zhang, Yi and Aneja, Jyoti and Mendes, Caio César Teodoro and Del Giorno, Allie and Gopi, Sivakanth and Javaheripi, Mojan and Kauffmann, Piero and family=Rosa, given=Gustavo, prefix=de, useprefix=true and Saarikivi, Olli and Salim, Adil and Shah, Shital and Behl, Harkirat Singh and Wang, Xin and Bubeck, Sébastien and Eldan, Ronen and Kalai, Adam Tauman and Lee, Yin Tat and Li, Yuanzhi},
  date = {2023-06-20},
  eprint = {2306.11644},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2306.11644},
  url = {http://arxiv.org/abs/2306.11644},
  urldate = {2023-06-29},
  abstract = {We introduce phi-1, a new large language model for code, with significantly smaller size than competing models: phi-1 is a Transformer-based model with 1.3B parameters, trained for 4 days on 8 A100s, using a selection of ``textbook quality" data from the web (6B tokens) and synthetically generated textbooks and exercises with GPT-3.5 (1B tokens). Despite this small scale, phi-1 attains pass@1 accuracy 50.6\% on HumanEval and 55.5\% on MBPP. It also displays surprising emergent properties compared to phi-1-base, our model before our finetuning stage on a dataset of coding exercises, and phi-1-small, a smaller model with 350M parameters trained with the same pipeline as phi-1 that still achieves 45\% on HumanEval.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/carlos/Zotero/storage/IMBD7FR8/Gunasekar et al. - 2023 - Textbooks Are All You Need.pdf;/home/carlos/Zotero/storage/PP9DGAW6/2306.html}
}

@article{halewoodEqualTemperamentTuning2015,
  title = {On {{Equal Temperament}}: {{Tuning}}, {{Modernity}} and {{Compromise}}},
  shorttitle = {On {{Equal Temperament}}},
  author = {Halewood, Michael},
  date = {2015},
  journaltitle = {History of the Human Sciences},
  volume = {28},
  number = {3},
  pages = {3--21},
  publisher = {{Sage Publications}},
  doi = {10.1177/0952695114567480},
  file = {/home/carlos/Zotero/storage/PEB24952/Halewood - 2015 - On Equal Temperament Tuning, Modernity and Compro.pdf;/home/carlos/Zotero/storage/LIIRW5QY/HALOET.html}
}

@online{HandbookMaterialsWind,
  title = {Handbook of {{Materials}} for {{Wind Musical Instruments}} | {{SpringerLink}}},
  url = {https://link.springer.com/book/10.1007/978-3-030-19175-7},
  urldate = {2023-05-24},
  file = {/home/carlos/Zotero/storage/R9T84FLZ/978-3-030-19175-7.html}
}

@online{hanPreTrainedModelsPresent2021,
  title = {Pre-{{Trained Models}}: {{Past}}, {{Present}} and {{Future}}},
  shorttitle = {Pre-{{Trained Models}}},
  author = {Han, Xu and Zhang, Zhengyan and Ding, Ning and Gu, Yuxian and Liu, Xiao and Huo, Yuqi and Qiu, Jiezhong and Yao, Yuan and Zhang, Ao and Zhang, Liang and Han, Wentao and Huang, Minlie and Jin, Qin and Lan, Yanyan and Liu, Yang and Liu, Zhiyuan and Lu, Zhiwu and Qiu, Xipeng and Song, Ruihua and Tang, Jie and Wen, Ji-Rong and Yuan, Jinhui and Zhao, Wayne Xin and Zhu, Jun},
  date = {2021-08-11},
  eprint = {2106.07139},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2106.07139},
  url = {http://arxiv.org/abs/2106.07139},
  urldate = {2024-01-25},
  abstract = {Large-scale pre-trained models (PTMs) such as BERT and GPT have recently achieved great success and become a milestone in the field of artificial intelligence (AI). Owing to sophisticated pre-training objectives and huge model parameters, large-scale PTMs can effectively capture knowledge from massive labeled and unlabeled data. By storing knowledge into huge parameters and fine-tuning on specific tasks, the rich knowledge implicitly encoded in huge parameters can benefit a variety of downstream tasks, which has been extensively demonstrated via experimental verification and empirical analysis. It is now the consensus of the AI community to adopt PTMs as backbone for downstream tasks rather than learning models from scratch. In this paper, we take a deep look into the history of pre-training, especially its special relation with transfer learning and self-supervised learning, to reveal the crucial position of PTMs in the AI development spectrum. Further, we comprehensively review the latest breakthroughs of PTMs. These breakthroughs are driven by the surge of computational power and the increasing availability of data, towards four important directions: designing effective architectures, utilizing rich contexts, improving computational efficiency, and conducting interpretation and theoretical analysis. Finally, we discuss a series of open problems and research directions of PTMs, and hope our view can inspire and advance the future study of PTMs.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/carlos/Zotero/storage/79LBRCTL/Han et al. - 2021 - Pre-Trained Models Past, Present and Future.pdf;/home/carlos/Zotero/storage/CEQNUL7H/2106.html}
}

@book{haynes2002history,
  title = {A History of Performing Pitch: {{The}} Story of '{{A}}'},
  author = {Haynes, B.},
  date = {2002},
  series = {G - {{Reference}},{{Information}} and Interdisciplinary Subjects Series},
  publisher = {{Scarecrow Press}},
  url = {https://books.google.es/books?id=3Vwh0PZ3EuMC},
  isbn = {978-0-8108-4185-7},
  lccn = {2002075248}
}

@online{hernandez-olivanSurveyArtificialIntelligence2022,
  title = {A {{Survey}} on {{Artificial Intelligence}} for {{Music Generation}}: {{Agents}}, {{Domains}} and {{Perspectives}}},
  shorttitle = {A {{Survey}} on {{Artificial Intelligence}} for {{Music Generation}}},
  author = {Hernandez-Olivan, Carlos and Hernandez-Olivan, Javier and Beltran, Jose R.},
  date = {2022-11-03},
  eprint = {2210.13944},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2210.13944},
  url = {http://arxiv.org/abs/2210.13944},
  urldate = {2023-09-27},
  abstract = {Music is one of the Gardner's intelligences in his theory of multiple intelligences. How humans perceive and understand music is still being studied and is crucial to develop artificial intelligence models that imitate such processes. Music generation with Artificial Intelligence is an emerging field that is gaining much attention in the recent years. In this paper, we describe how humans compose music and how new AI systems could imitate such process by comparing past and recent advances in the field with music composition techniques. To understand how AI models and algorithms generate music and the potential applications that might appear in the future, we explore, analyze and describe the agents that take part of the music generation process: the datasets, models, interfaces, the users and the generated music. We mention possible applications that might benefit from this field and we also propose new trends and future research directions that could be explored in the future.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/home/carlos/Zotero/storage/498MZNDW/Hernandez-Olivan et al. - 2022 - A Survey on Artificial Intelligence for Music Gene.pdf;/home/carlos/Zotero/storage/AMJVURKG/2210.html}
}

@online{HistoriaInteligenciaArtificial,
  title = {Historia de la Inteligencia Artificial, el Machine Learning y el Deep Learning},
  url = {https://www.algotive.ai/es-mx/blog/historia-de-la-inteligencia-artificial-el-machine-learning-y-el-deep-learning},
  urldate = {2023-10-30},
  abstract = {Conoce toda la historia de la Inteligencia Artificial (IA), el Machine Learning (ML) y el Deep Learning (DL), de manera breve, sencilla e ilustrativa.},
  langid = {mexican},
  file = {/home/carlos/Zotero/storage/LU4PW86U/historia-de-la-inteligencia-artificial-el-machine-learning-y-el-deep-learning.html}
}

@online{holtzmanCuriousCaseNeural2020,
  title = {The {{Curious Case}} of {{Neural Text Degeneration}}},
  author = {Holtzman, Ari and Buys, Jan and Du, Li and Forbes, Maxwell and Choi, Yejin},
  date = {2020-02-14},
  eprint = {1904.09751},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1904.09751},
  url = {http://arxiv.org/abs/1904.09751},
  urldate = {2023-11-07},
  abstract = {Despite considerable advancements with deep neural language models, the enigma of neural text degeneration persists when these models are tested as text generators. The counter-intuitive empirical observation is that even though the use of likelihood as training objective leads to high quality models for a broad range of language understanding tasks, using likelihood as a decoding objective leads to text that is bland and strangely repetitive. In this paper, we reveal surprising distributional differences between human text and machine text. In addition, we find that decoding strategies alone can dramatically effect the quality of machine text, even when generated from exactly the same neural language model. Our findings motivate Nucleus Sampling, a simple but effective method to draw the best out of neural generation. By sampling text from the dynamic nucleus of the probability distribution, which allows for diversity while effectively truncating the less reliable tail of the distribution, the resulting text better demonstrates the quality of human text, yielding enhanced diversity without sacrificing fluency and coherence.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/home/carlos/Zotero/storage/J4H86DF3/Holtzman et al. - 2020 - The Curious Case of Neural Text Degeneration.pdf;/home/carlos/Zotero/storage/6Z9WQDE7/1904.html}
}

@article{hornikMultilayerFeedforwardNetworks1989,
  title = {Multilayer Feedforward Networks Are Universal Approximators},
  author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  date = {1989-01-01},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  volume = {2},
  number = {5},
  pages = {359--366},
  issn = {0893-6080},
  doi = {10.1016/0893-6080(89)90020-8},
  url = {https://www.sciencedirect.com/science/article/pii/0893608089900208},
  urldate = {2023-12-21},
  abstract = {This paper rigorously establishes that standard multilayer feedforward networks with as few as one hidden layer using arbitrary squashing functions are capable of approximating any Borel measurable function from one finite dimensional space to another to any desired degree of accuracy, provided sufficiently many hidden units are available. In this sense, multilayer feedforward networks are a class of universal approximators.},
  keywords = {Back-propagation networks,Feedforward networks,Mapping networks,Network representation capability,Sigma-Pi networks,Squashing functions,Stone-Weierstrass Theorem,Universal approximation},
  file = {/home/carlos/Zotero/storage/DIC8KESB/0893608089900208.html}
}

@online{HowGetBetter2023,
  title = {How to {{Get Better Outputs}} from {{Your Large Language Model}}},
  date = {2023-06-14T16:18+00:00},
  url = {https://developer.nvidia.com/blog/how-to-get-better-outputs-from-your-large-language-model/},
  urldate = {2024-01-25},
  abstract = {Large language models (LLMs) have generated excitement worldwide due to their ability to understand and process human language at a scale that is unprecedented. It has transformed the way that we…},
  langid = {american},
  organization = {{NVIDIA Technical Blog}},
  file = {/home/carlos/Zotero/storage/ZWDH2CVI/how-to-get-better-outputs-from-your-large-language-model.html}
}

@article{hruskaInvestigationSoundSource2019,
  title = {Investigation of the {{Sound Source Regions}} in {{Open}} and {{Closed Organ Pipes}}},
  author = {Hruška, Viktor and Dlask, Pavel},
  date = {2019-01-01},
  journaltitle = {Archives of Acoustics},
  shortjournal = {Archives of Acoustics},
  volume = {44},
  pages = {467--474},
  doi = {10.24425/aoa.2019.129262},
  abstract = {The airflow in the mouth of an open and closed flue organ pipe of corresponding geometrical proportions is studied. The phase locked particle image velocimetry with subsequent analysis by the biorthogonal decomposition is employed in order to compare the flow mechanisms and related features. The most significant differences lie in the mean velocity distribution and rapidity of the jet lateral motion. Remarks on the pressure estimation from PIV data and its importance for the aeroacoustic source terms are made and a specific example is discussed.},
  file = {/home/carlos/Zotero/storage/949LEEEM/Hruška y Dlask - 2019 - Investigation of the Sound Source Regions in Open .pdf}
}

@inproceedings{hruskaOrganPipeVoicing2021,
  title = {Organ Pipe Voicing and Heuristic Optimization},
  author = {Hruška, Viktor and Dlask, Pavel},
  date = {2021-07-15},
  abstract = {Dependence of the radiated sound features on the voicing parameters (such as the flue width, the cut-up height or the foot pressure) belongs among the most desired pieces of knowledge in organ design and building. Due to the complex feedback behavior of the flow-acoustic interactions, it is not straightforward to simplify the theory, so the heuristic approach might provide an efficient way of dealing with the experimental results to extract the key dependencies. The article begins with a dimensional analysis based on the Buckingham Pi theorem, which then serves as a base for the heuristic algorithm. The text's main concern is providing formulas for the pipe's fundamental frequency, the sound pressure level and the spectral centroid in terms of voicing parameters.},
  file = {/home/carlos/Zotero/storage/55L5UDD7/Hruška y Dlask - 2021 - Organ pipe voicing and heuristic optimization.pdf}
}

@online{huangAgentCoderMultiAgentbasedCode2023,
  title = {{{AgentCoder}}: {{Multi-Agent-based Code Generation}} with {{Iterative Testing}} and {{Optimisation}}},
  shorttitle = {{{AgentCoder}}},
  author = {Huang, Dong and Bu, Qingwen and Zhang, Jie M. and Luck, Michael and Cui, Heming},
  date = {2023-12-20},
  eprint = {2312.13010},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2312.13010},
  url = {http://arxiv.org/abs/2312.13010},
  urldate = {2024-01-02},
  abstract = {The advancement of natural language processing (NLP) has been significantly boosted by the development of transformer-based large language models (LLMs). These models have revolutionized NLP tasks, particularly in code generation, aiding developers in creating software with enhanced efficiency. Despite their advancements, challenges in balancing code snippet generation with effective test case generation and execution persist. To address these issues, this paper introduces Multi-Agent Assistant Code Generation (AgentCoder), a novel solution comprising a multi-agent framework with specialized agents: the programmer agent, the test designer agent, and the test executor agent. During the coding procedure, the programmer agent will focus on the code generation and refinement based on the test executor agent's feedback. The test designer agent will generate test cases for the generated code, and the test executor agent will run the code with the test cases and write the feedback to the programmer. This collaborative system ensures robust code generation, surpassing the limitations of single-agent models and traditional methodologies. Our extensive experiments on 9 code generation models and 12 enhancement approaches showcase AgentCoder's superior performance over existing code generation models and prompt engineering techniques across various benchmarks. For example, AgentCoder achieves 77.4\% and 89.1\% pass@1 in HumanEval-ET and MBPP-ET with GPT-3.5, while SOTA baselines obtain only 69.5\% and 63.0\%.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/home/carlos/Zotero/storage/495L4V9P/Huang et al. - 2023 - AgentCoder Multi-Agent-based Code Generation with Iterative Testing and Optimisation.pdf;/home/carlos/Zotero/storage/GBNPDX77/2312.html}
}

@inproceedings{huangCounterpointConvolution2017,
  title = {Counterpoint by {{Convolution}}},
  booktitle = {Proceedings of {{ISMIR}} 2017},
  author = {Huang, Cheng-Zhi Anna and Cooijmans, Tim and Roberts, Adam and Courville, Aaron and Eck, Douglas},
  date = {2017},
  url = {https://ismir2017.smcnus.org/wp-content/uploads/2017/10/187_Paper.pdf},
  urldate = {2023-05-24}
}

@online{hungTranscriptionAllYou2020,
  title = {Transcription {{Is All You Need}}: {{Learning}} to {{Separate Musical Mixtures}} with {{Score}} as {{Supervision}}},
  shorttitle = {Transcription {{Is All You Need}}},
  author = {Hung, Yun-Ning and Wichern, Gordon and Roux, Jonathan Le},
  date = {2020-10-22},
  eprint = {2010.11904},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2010.11904},
  url = {http://arxiv.org/abs/2010.11904},
  urldate = {2024-01-22},
  abstract = {Most music source separation systems require large collections of isolated sources for training, which can be difficult to obtain. In this work, we use musical scores, which are comparatively easy to obtain, as a weak label for training a source separation system. In contrast with previous score-informed separation approaches, our system does not require isolated sources, and score is used only as a training target, not required for inference. Our model consists of a separator that outputs a time-frequency mask for each instrument, and a transcriptor that acts as a critic, providing both temporal and frequency supervision to guide the learning of the separator. A harmonic mask constraint is introduced as another way of leveraging score information during training, and we propose two novel adversarial losses for additional fine-tuning of both the transcriptor and the separator. Results demonstrate that using score information outperforms temporal weak-labels, and adversarial structures lead to further improvements in both separation and transcription performance.},
  pubstate = {preprint},
  version = {1},
  keywords = {Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/home/carlos/Zotero/storage/H5CEA699/Hung et al. - 2020 - Transcription Is All You Need Learning to Separate Musical Mixtures with Score as Supervision.pdf;/home/carlos/Zotero/storage/QYZ9B53T/2010.html}
}

@article{jeonInvestigationAcousticalCharacteristics2014,
  title = {Investigation of the Acoustical Characteristics of Organ Pipes in a Performing Space},
  author = {Jeon, Jin Yong and Hwang, In Hwan and Kim, Yong Hee},
  date = {2014-07-01},
  journaltitle = {Building and Environment},
  shortjournal = {Building and Environment},
  volume = {77},
  pages = {50--60},
  doi = {10.1016/j.buildenv.2014.03.020},
  abstract = {The acoustical influence of organ pipes on the sound fields within a performing space was investigated. Test specimens with appropriate characteristics were determined after a field survey of various prospect pipes. Laboratory tests using 1:10 scale models were carried out to identify the surface characteristics of an organ's prospect pipes. The absorption, scattering and diffusion coefficients of the prospect pipes were found to range from 0.09 to 0.10, 0.11 to 0.31, and from 0.18 to 0.37, respectively. From the field measurements made in a large concert hall with a pipe organ on the right lateral wall, higher G and LFE4 values were observed at positions nearer the pipe organ. Additionally, a computer simulation was employed to identify the acoustic properties of the pipe organ within a hall. As a result, it was derived that the pipe organ, including the prospect pipes and the organ enclosure had an absorption coefficient of 0.21 with higher absorption at lower frequency bands and an average scattering coefficient of 0.50.},
  file = {/home/carlos/Zotero/storage/EHYL4T9Q/Jeon et al. - 2014 - Investigation of the acoustical characteristics of.pdf}
}

@online{jonesDoesGPT4Pass2023,
  title = {Does {{GPT-4 Pass}} the {{Turing Test}}?},
  author = {Jones, Cameron and Bergen, Benjamin},
  date = {2023-10-31},
  eprint = {2310.20216},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2310.20216},
  url = {http://arxiv.org/abs/2310.20216},
  urldate = {2024-01-27},
  abstract = {We evaluated GPT-4 in a public online Turing Test. The best-performing GPT-4 prompt passed in 41\% of games, outperforming baselines set by ELIZA (27\%) and GPT-3.5 (14\%), but falling short of chance and the baseline set by human participants (63\%). Participants' decisions were based mainly on linguistic style (35\%) and socio-emotional traits (27\%), supporting the idea that intelligence is not sufficient to pass the Turing Test. Participants' demographics, including education and familiarity with LLMs, did not predict detection rate, suggesting that even those who understand systems deeply and interact with them frequently may be susceptible to deception. Despite known limitations as a test of intelligence, we argue that the Turing Test continues to be relevant as an assessment of naturalistic communication and deception. AI models with the ability to masquerade as humans could have widespread societal consequences, and we analyse the effectiveness of different strategies and criteria for judging humanlikeness.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/carlos/Zotero/storage/BQ9SQ2XE/Jones y Bergen - 2023 - Does GPT-4 Pass the Turing Test.pdf;/home/carlos/Zotero/storage/6CFU2PUC/2310.html}
}

@book{julio_sanz,
  type = {Libro electrónico},
  author = {family=cuántica., given=¿Qué, prefix=es música?, useprefix=true},
  date = {2019},
  location = {{Cuenca}}
}

@book{jurafskySpeechLanguageProcessing2008,
  title = {Speech and {{Language Processing}}: {{An Introduction}} to {{Natural Language Processing}}, {{Computational Linguistics}}, and {{Speech Recognition}}},
  shorttitle = {Speech and {{Language Processing}}},
  author = {Jurafsky, Daniel and Martin, James},
  date = {2008-02-01},
  volume = {2},
  file = {/home/carlos/Zotero/storage/LPYC52WI/Jurafsky y Martin - 2008 - Speech and Language Processing An Introduction to.pdf}
}

@online{jzh2074,
  title = {{{AI}} Types. {{Tipos}} Inteligencia {{Artificial}}.Svg},
  author = {{Jzh2074}},
  date = {2022},
  url = {https://commons.wikimedia.org/wiki/File:AI_Types._Tipos_Inteligencia_Artificial.svg}
}

@online{kaddourChallengesApplicationsLarge2023,
  title = {Challenges and {{Applications}} of {{Large Language Models}}},
  author = {Kaddour, Jean and Harris, Joshua and Mozes, Maximilian and Bradley, Herbie and Raileanu, Roberta and McHardy, Robert},
  date = {2023-07-19},
  eprint = {2307.10169},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2307.10169},
  url = {http://arxiv.org/abs/2307.10169},
  urldate = {2023-09-27},
  abstract = {Large Language Models (LLMs) went from non-existent to ubiquitous in the machine learning discourse within a few years. Due to the fast pace of the field, it is difficult to identify the remaining challenges and already fruitful application areas. In this paper, we aim to establish a systematic set of open problems and application successes so that ML researchers can comprehend the field's current state more quickly and become productive.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/carlos/Zotero/storage/N4TI6Q5V/Kaddour et al. - 2023 - Challenges and Applications of Large Language Mode.pdf;/home/carlos/Zotero/storage/EWGBTNGU/2307.html}
}

@online{kainatIntroductionGenerativeAI2023,
  title = {Introduction to {{Generative AI}}},
  author = {Kainat},
  date = {2023-08-03T08:04:12},
  url = {https://medium.com/@kitkat73275/introduction-to-generative-ai-833c9c467dfa},
  urldate = {2024-01-23},
  abstract = {AI (Artificial Intelligence) is the broad field of creating intelligent machines that can perform tasks that typically require human…},
  langid = {english},
  organization = {{Medium}},
  file = {/home/carlos/Zotero/storage/HANH4MKW/introduction-to-generative-ai-833c9c467dfa.html}
}

@software{kirkbrideQirkyFoxDot2023,
  title = {Qirky/{{FoxDot}}},
  author = {Kirkbride, Ryan},
  date = {2023-12-06T19:35:50Z},
  origdate = {2015-08-30T13:32:18Z},
  url = {https://github.com/Qirky/FoxDot},
  urldate = {2023-12-09},
  abstract = {Python driven environment for Live Coding}
}

@article{kokkelmansAcousticBehaviorChimney1999,
  title = {Acoustic Behavior of Chimney Pipes},
  author = {Kokkelmans, Servaas J. J. M. F. and Verge, Marc-Pierre and Hirschberg, A. and Wijnands, A. P. J. and Schoffelen, R. L. M.},
  date = {1999-01-01},
  journaltitle = {The Journal of the Acoustical Society of America},
  shortjournal = {The Journal of the Acoustical Society of America},
  volume = {105},
  number = {1},
  pages = {546--551},
  issn = {0001-4966},
  doi = {10.1121/1.424590},
  url = {https://doi.org/10.1121/1.424590},
  urldate = {2023-05-23},
  abstract = {The objective of this work is to study the acoustic behavior of chimney organ pipes. The working hypothesis is that its role is to reinforce the fifth harmonic of the tone of a stopped pipe. According to Helmholtz, the chimney should have the length of an open pipe resonating at the frequency of the fifth harmonic. This design appears to be the least favorable one, except if the chimney is placed half inside and half outside the main pipe, and should therefore be avoided. The ratio of the modulus of the admittance of the different harmonics appears to describe, for the chimney pipe used in this study, the dependency of the ratio of the measured amplitude of the fifth, third, and first harmonic with the geometry of the chimney. The admittance curve can therefore be used to determine the effects of the geometry of the chimney on the timbre of the organ pipe. This result is used in order to determine the optimal diameter of the chimney as a function of its length.},
  file = {/home/carlos/Zotero/storage/9RKDRHQG/Kokkelmans et al. - 1999 - Acoustic behavior of chimney pipes.pdf;/home/carlos/Zotero/storage/H26QB6LX/Acoustic-behavior-of-chimney-pipes.html}
}

@article{kravchunAcousticFeaturesOrgan2019,
  title = {Acoustic {{Features}} of {{Organ Concert Halls}}: {{Trends}} and {{Problems}}},
  shorttitle = {Acoustic {{Features}} of {{Organ Concert Halls}}},
  author = {Kravchun, P. N.},
  date = {2019-11-01},
  journaltitle = {Acoustical Physics},
  shortjournal = {Acoust. Phys.},
  volume = {65},
  number = {6},
  pages = {742--748},
  issn = {1562-6865},
  doi = {10.1134/S1063771019660011},
  url = {https://doi.org/10.1134/S1063771019660011},
  urldate = {2023-05-23},
  abstract = {The main acoustic requirements in organ concert halls, their evolution in recent decades, and the problems arising in the creation and rebuilding of these halls are considered. The problems associated with the specific features of organs in the acoustic design of halls are briefly discussed.},
  langid = {english},
  keywords = {acoustics of concert halls,organ building,organ halls}
}

@article{lathamMeasurementQualityAuditorium1983,
  title = {The Measurement of Quality in Auditorium Acoustics by Subjective Scaling Methods—{{A}} Review of Developments in Theory and Practice},
  author = {Latham, Howard G. and Tagg, Stephen K.},
  date = {1983-01-01},
  journaltitle = {Applied Acoustics},
  shortjournal = {Applied Acoustics},
  volume = {16},
  number = {4},
  pages = {257--278},
  issn = {0003-682X},
  doi = {10.1016/0003-682X(83)90019-1},
  url = {https://www.sciencedirect.com/science/article/pii/0003682X83900191},
  urldate = {2023-05-23},
  abstract = {A review is given of subjective measurement methods in auditorium acoustics. Particular emphasis is laid on research in what may be termed the field of psychometric room acoustics. In the past, traditional psychophysical methods have proved useful for the more limited purpose of determining the effects of physical changes on subjective attributes, but more recent developments in psychometric theory now permit aesthetic characteristics, such as quality, to be evaluated on valid subjective measurement scales. At present there is contention concerning the best approach to adopt in applying such subjective scales to the evaluation of auditoria. Two schools of thought have emerged: one favouring preference comparisons, the other semantic differential ratings. The advantages and disadvantages of both methods are discussed in relation to recent projects. It is suggested that the advantages of these two approaches could be combined to derive a reliable subjective measure for evaluating auditoria in the field.},
  langid = {english},
  file = {/home/carlos/Zotero/storage/RGW9HV3M/0003682X83900191.html}
}

@incollection{lauterbornNonlinearAcousticsFluids2007,
  title = {Nonlinear {{Acoustics}} in {{Fluids}}},
  booktitle = {Springer {{Handbook}} of {{Acoustics}}},
  author = {Lauterborn, Werner and Kurz, Thomas and Akhatov, Iskander},
  editor = {Rossing, Thomas D.},
  date = {2007},
  series = {Springer {{Handbooks}}},
  pages = {257--297},
  publisher = {{Springer}},
  location = {{New York, NY}},
  doi = {10.1007/978-0-387-30425-0_8},
  url = {https://doi.org/10.1007/978-0-387-30425-0_8},
  urldate = {2023-05-23},
  abstract = {At high sound intensities or long propagation distances at nonlinear acousticsin fluidssufficiently low damping acoustic phenomena become nonlinear. This chapter focuses on nonlinear acoustic wave properties in gases and liquids. The origin of nonlinearity, equations of state, simple nonlinear waves, nonlinear acoustic wave equations, shock-wave formation, and interaction of waves are presented and discussed. Tables are given for the nonlinearity parameter B/A for water and a~range of organic liquids, liquid metals and gases. Acoustic cavitation with its nonlinear bubble oscillations, pattern formation and sonoluminescence (light from sound) are modern examples of nonlinear acoustics. The language of nonlinear dynamics needed for understanding chaotic dynamics and acoustic chaotic systems is introduced.},
  isbn = {978-0-387-30425-0},
  langid = {english},
  keywords = {Burger Equation,Nonlinear Acoustics,Shock Wave,Sound Wave,Wave Train}
}

@book{lavrySamplingTheoryDigital2004,
  type = {artículo en PDF},
  title = {Sampling {{Theory For Digital Audio}}},
  author = {Lavry, Dan},
  date = {2004},
  url = {http://lavryengineering.com/pdfs/lavry-sampling-theory.pdf}
}

@online{LeasttoMostPromptingEnables,
  title = {Least-to-{{Most Prompting Enables Complex Reasoning}} in {{Large Language Models}}},
  url = {https://ar5iv.labs.arxiv.org/html/2205.10625},
  urldate = {2023-06-25},
  abstract = {Although chain-of-thought prompting has shown impressive results on many natural language reasoning tasks, it often performs poorly on tasks which need to solve problems harder than the demonstration examples. To tackl…},
  langid = {english},
  organization = {{ar5iv}},
  file = {/home/carlos/Zotero/storage/DCS7GPHQ/2205.html}
}

@article{lehmanBachExtraordinaryTemperament2005,
  title = {Bach's Extraordinary Temperament: Our {{Rosetta Stone--1}}},
  shorttitle = {Bach's Extraordinary Temperament},
  author = {Lehman, B.},
  date = {2005-02-01},
  journaltitle = {Early Music},
  shortjournal = {Early Music},
  volume = {33},
  number = {1},
  pages = {3--24},
  issn = {0306-1078, 1741-7260},
  doi = {10.1093/em/cah037},
  url = {https://academic.oup.com/em/article-lookup/doi/10.1093/em/cah037},
  urldate = {2023-05-31},
  langid = {english},
  file = {/home/carlos/Zotero/storage/XQDW83U8/Lehman - 2005 - Bach's extraordinary temperament our Rosetta Ston.pdf}
}

@article{lehmanBachExtraordinaryTemperament2005b,
  title = {Bach's Extraordinary Temperament: Our {{Rosetta Stone}}—2},
  shorttitle = {Bach's Extraordinary Temperament},
  author = {Lehman, Bradley},
  date = {2005-05-01},
  journaltitle = {Early Music},
  volume = {33},
  number = {2},
  pages = {211--232},
  issn = {1741-7260, 0306-1078},
  doi = {10.1093/em/cah067},
  url = {http://academic.oup.com/em/article/33/2/211/338513/Bachs-extraordinary-temperament-our-Rosetta-Stone2},
  urldate = {2023-05-31},
  langid = {english},
  file = {/home/carlos/Zotero/storage/RZW22FL6/Lehman - 2005 - Bach's extraordinary temperament our Rosetta Ston.pdf}
}

@inproceedings{leonSistemasAfinacionBorrosos2010,
  title = {Sistemas de afinación borrosos: un estudio del temperamento igual de 12 notas},
  shorttitle = {Sistemas de afinación borrosos},
  booktitle = {XV Congreso Español sobre Tecnologías y Lógica Fuzzy ESTYLF 2010: Huelva [Recurso electrónico], 2010, ISBN 978-84-92944-02-6, págs. 31-36},
  author = {León, Teresa and Liern Carrión, Vicente},
  date = {2010},
  pages = {31--36},
  publisher = {{Universidad de Huelva}},
  url = {https://dialnet.unirioja.es/servlet/articulo?codigo=7054074},
  urldate = {2023-05-31},
  abstract = {Un sistema de afinación es el conjunto de los sonidos que utiliza la Música. Los sonidos admitidos por el sistema de afinación se denominan sonidos afinados o notas musicales. A lo largo de la Historia han aparecido centenares de afinaciones de las que sólo se siguen utilizando alrededor de media docena, las cuatro que conviven en la orquesta clásica actual son la afinación Pitagórica, la Justa entonación, el temperamento igual de 12 notas y el temperamento de Hölder. En la práctica, para conseguir que la orquesta "suene bien", los músicos modifican "un poco" las notas teóricas. De acuerdo con la lógica booleana podríamos decir que los músicos desafinan, sin embargo la lógica borrosa nos proporciona un modelo flexible que explica satisfactoriamente lo que ocurre en realidad. Consideramos las notas musicales como números borrosos y por tanto los sistemas de afinación estarán formados por notas borrosas. El concepto de similitud entre notas borrosas nos permite justificar teóricamente la práctica diaria de los músicos. Prestamos especial atención al temperamento igual de 12 notas ya que es el sistema más empleado por sus ventajas teóricas y prácticas. A cada una de sus notas (borrosas) le podemos asociar un conjunto de notas que son similares a ella y que serían "intercambiables" por ella.},
  eventtitle = {XV Congreso Español sobre Tecnologías y Lógica Fuzzy ESTYLF 2010: Huelva [Recurso electrónico]},
  isbn = {978-84-92944-02-6},
  langid = {spanish},
  file = {/home/carlos/Zotero/storage/4DIM93ZW/articulo.html}
}

@online{lewisRetrievalAugmentedGenerationKnowledgeIntensive2021,
  title = {Retrieval-{{Augmented Generation}} for {{Knowledge-Intensive NLP Tasks}}},
  author = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and Küttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rocktäschel, Tim and Riedel, Sebastian and Kiela, Douwe},
  date = {2021-04-12},
  eprint = {2005.11401},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2005.11401},
  url = {http://arxiv.org/abs/2005.11401},
  urldate = {2023-11-07},
  abstract = {Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) -- models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.},
  pubstate = {preprint},
  version = {4},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/carlos/Zotero/storage/WVAFYFB3/Lewis et al. - 2021 - Retrieval-Augmented Generation for Knowledge-Inten.pdf;/home/carlos/Zotero/storage/C495Y3UY/2005.html}
}

@book{Lieb,
  title = {A Guide to Modular Worlds},
  author = {Lieb, Rolf-Dieter and Kaiser, Ulf},
  date = {2019},
  edition = {1ª},
  publisher = {{SynMag-Verlag}},
  location = {{Rellingen}}
}

@book{liebGuideModularWorlds2019,
  title = {A {{Guide To Modular Worlds}}},
  author = {Lieb, Rolf-Dieter and Kaiser, Ulf},
  date = {2019},
  edition = {1ª},
  publisher = {{SynMag-Verlag}},
  location = {{Rellingen}}
}

@online{liSelfAlignmentInstructionBacktranslation2023,
  title = {Self-{{Alignment}} with {{Instruction Backtranslation}}},
  author = {Li, Xian and Yu, Ping and Zhou, Chunting and Schick, Timo and Zettlemoyer, Luke and Levy, Omer and Weston, Jason and Lewis, Mike},
  date = {2023-08-14},
  eprint = {2308.06259},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2308.06259},
  url = {http://arxiv.org/abs/2308.06259},
  urldate = {2023-09-27},
  abstract = {We present a scalable method to build a high quality instruction following language model by automatically labelling human-written text with corresponding instructions. Our approach, named instruction backtranslation, starts with a language model finetuned on a small amount of seed data, and a given web corpus. The seed model is used to construct training examples by generating instruction prompts for web documents (self-augmentation), and then selecting high quality examples from among these candidates (self-curation). This data is then used to finetune a stronger model. Finetuning LLaMa on two iterations of our approach yields a model that outperforms all other LLaMa-based models on the Alpaca leaderboard not relying on distillation data, demonstrating highly effective self-alignment.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/home/carlos/Zotero/storage/JADHWQUA/Li et al. - 2023 - Self-Alignment with Instruction Backtranslation.pdf;/home/carlos/Zotero/storage/4SRRSDIW/2308.html}
}

@inreference{ListAudioProgramming2023,
  title = {List of Audio Programming Languages},
  booktitle = {Wikipedia},
  date = {2023-07-26T10:06:56Z},
  url = {https://en.wikipedia.org/w/index.php?title=List_of_audio_programming_languages&oldid=1167204231},
  urldate = {2023-12-11},
  abstract = {This is a list of notable programming languages optimized for sound production, algorithmic composition, and sound synthesis. ABC notation, a language for notating music using the ASCII character set Bol Processor, a model of formal grammars enriched with polymetric expressions for the representation of time structures ChucK, strongly timed, concurrent, and on-the-fly audio programming language Real-time Cmix, a MUSIC-N synthesis language somewhat similar to Csound Cmajor, a high-performance JIT-compiled C-style language for DSP Common Lisp Music (CLM), a music synthesis and signal processing package in the Music V family Csound, a MUSIC-N synthesis language released under the LGPL with many available unit generators Extempore, a live-coding environment that borrows a core foundation from the Impromptu environment FAUST, Functional Audio Stream, a functional compiled language for efficient real-time audio signal processing GLICOL, a graph-oriented live coding language written in Rust Hierarchical Music Specification Language (HMSL), optimized more for music than synthesis, developed in the 1980s in Forth Impromptu, a Scheme language environment for Mac OS X capable of sound and video synthesis, algorithmic composition, and 2D and 3D graphics programming Ixi lang, a programming language for live coding musical expression. JFugue, a Java and JVM library for programming music that outputs to MIDI and has the ability to convert to formats including ABC Notation, Lilypond, and MusicXML jMusic JSyn Keykit, programming language and portable graphical environment for MIDI music composition Kyma (sound design language) LilyPond, a computer program and file format for music engraving. Max/MSP, a proprietary, modular visual programming language aimed at sound synthesis for music Music Macro Language (MML), often used to produce chiptune music in Japan MUSIC-N, includes versions I, II, III, IV, IV-B, IV-BF, V, 11, and 360 Nyquist OpenMusic Orca (music programming language) Pure Data, a modular visual programming language for signal processing aimed at music creation Reaktor Sonic Pi Structured Audio Orchestra Language (SAOL), part of the MPEG-4 Structured Audio standard SuperCollider SynthEdit, a modular visual programming language for signal processing aimed at creating audio plug-ins},
  langid = {english},
  annotation = {Page Version ID: 1167204231},
  file = {/home/carlos/Zotero/storage/GFR76MYV/List_of_audio_programming_languages.html}
}

@online{liStructuredChainofThoughtPrompting2023,
  title = {Structured {{Chain-of-Thought Prompting}} for {{Code Generation}}},
  author = {Li, Jia and Li, Ge and Li, Yongmin and Jin, Zhi},
  date = {2023-09-07},
  eprint = {2305.06599},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2305.06599},
  urldate = {2023-10-23},
  abstract = {Large Language Models (LLMs) (e.g., ChatGPT) have shown impressive performance in code generation. LLMs take prompts as inputs, and Chain-of-Thought (CoT) prompting is the state-of-theart prompting technique. CoT prompting asks LLMs first to generate CoTs (i.e., intermediate natural language reasoning steps) and then output the code. However, CoT prompting is designed for natural language generation and has low accuracy in code generation.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Software Engineering},
  file = {/home/carlos/Zotero/storage/KQ5L5V5X/Li et al. - 2023 - Structured Chain-of-Thought Prompting for Code Gen.pdf}
}

@online{liuLostMiddleHow2023,
  title = {Lost in the {{Middle}}: {{How Language Models Use Long Contexts}}},
  shorttitle = {Lost in the {{Middle}}},
  author = {Liu, Nelson F. and Lin, Kevin and Hewitt, John and Paranjape, Ashwin and Bevilacqua, Michele and Petroni, Fabio and Liang, Percy},
  date = {2023-11-20},
  eprint = {2307.03172},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2307.03172},
  urldate = {2023-12-12},
  abstract = {While recent language models have the ability to take long contexts as input, relatively little is known about how well they use longer context. We analyze the performance of language models on two tasks that require identifying relevant information in their input contexts: multi-document question answering and key-value retrieval. We find that performance can degrade significantly when changing the position of relevant information, indicating that current language models do not robustly make use of information in long input contexts. In particular, we observe that performance is often highest when relevant information occurs at the beginning or end of the input context, and significantly degrades when models must access relevant information in the middle of long contexts, even for explicitly long-context models. Our analysis provides a better understanding of how language models use their input context and provides new evaluation protocols for future long-context language models.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/home/carlos/Zotero/storage/45RW8HRL/Liu et al. - 2023 - Lost in the Middle How Language Models Use Long C.pdf}
}

@online{liuWavJourneyCompositionalAudio2023,
  title = {{{WavJourney}}: {{Compositional Audio Creation}} with {{Large Language Models}}},
  shorttitle = {{{WavJourney}}},
  author = {Liu, Xubo and Zhu, Zhongkai and Liu, Haohe and Yuan, Yi and Cui, Meng and Huang, Qiushi and Liang, Jinhua and Cao, Yin and Kong, Qiuqiang and Plumbley, Mark D. and Wang, Wenwu},
  date = {2023-11-26},
  eprint = {2307.14335},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/2307.14335},
  urldate = {2024-01-04},
  abstract = {Despite breakthroughs in audio generation models, their capabilities are often confined to domain-specific conditions such as speech transcriptions and audio captions. However, real-world audio creation aims to generate harmonious audio containing various elements such as speech, music, and sound effects with controllable conditions, which is challenging to address using existing audio generation systems. We present WavJourney, a novel framework that leverages Large Language Models (LLMs) to connect various audio models for audio creation. WavJourney allows users to create storytelling audio content with diverse audio elements simply from textual descriptions. Specifically, given a text instruction, WavJourney first prompts LLMs to generate an audio script that serves as a structured semantic representation of audio elements. The audio script is then converted into a computer program, where each line of the program calls a task-specific audio generation model or computational operation function. The computer program is then executed to obtain a compositional and interpretable solution for audio creation. Experimental results suggest that WavJourney is capable of synthesizing realistic audio aligned with textually-described semantic, spatial and temporal conditions, achieving state-of-the-art results on text-toaudio generation benchmarks. Additionally, we introduce a new multi-genre story benchmark. Subjective evaluations demonstrate the potential of WavJourney in crafting engaging storytelling audio content from text. We further demonstrate that WavJourney can facilitate human-machine co-creation in multi-round dialogues. To foster future research, the code and synthesized audio are available at: https://audio-agi.github.io/WavJourney\_demopage/.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Multimedia,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/home/carlos/Zotero/storage/FT53GGQ9/Liu et al. - 2023 - WavJourney Compositional Audio Creation with Large Language Models.pdf}
}

@online{LiveCodeTidal,
  title = {Live Code with {{Tidal Cycles}} | {{Tidal Cycles}}},
  url = {https://tidalcycles.org/},
  urldate = {2023-12-09},
  abstract = {Live coding environment for making algorithmic patterns},
  langid = {english},
  file = {/home/carlos/Zotero/storage/6QLETVM5/tidalcycles.org.html}
}

@online{LLMPromptingGuide,
  title = {{{LLM}} Prompting Guide},
  url = {https://huggingface.co/docs/transformers/main/en/tasks/prompting},
  urldate = {2023-10-30},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
  langid = {english},
  file = {/home/carlos/Zotero/storage/MLZ8EYCS/prompting.html}
}

@online{luMuseCocoGeneratingSymbolic2023,
  title = {{{MuseCoco}}: {{Generating Symbolic Music}} from {{Text}}},
  shorttitle = {{{MuseCoco}}},
  author = {Lu, Peiling and Xu, Xin and Kang, Chenfei and Yu, Botao and Xing, Chengyi and Tan, Xu and Bian, Jiang},
  date = {2023-05-31},
  eprint = {2306.00110},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/2306.00110},
  urldate = {2024-01-04},
  abstract = {Generating music from text descriptions is a user-friendly mode since the text is a relatively easy interface for user engagement. While some approaches utilize texts to control music audio generation, editing musical elements in generated audio is challenging for users. In contrast, symbolic music offers ease of editing, making it more accessible for users to manipulate specific musical elements. In this paper, we propose MuseCoco, which generates symbolic music from text descriptions with musical attributes as the bridge to break down the task into text-to-attribute understanding and attribute-to-music generation stages. MuseCoCo stands for Music Composition Copilot that empowers musicians to generate music directly from given text descriptions, offering a significant improvement in efficiency compared to creating music entirely from scratch. The system has two main advantages: Firstly, it is data efficient. In the attribute-to-music generation stage, the attributes can be directly extracted from music sequences, making the model training self-supervised. In the text-to-attribute understanding stage, the text is synthesized and refined by ChatGPT based on the defined attribute templates. Secondly, the system can achieve precise control with specific attributes in text descriptions and offers multiple control options through attribute-conditioned or text-conditioned approaches. MuseCoco outperforms baseline systems in terms of musicality, controllability, and overall score by at least 1.27, 1.08, and 1.32 respectively. Besides, there is a notable enhancement of about 20\% in objective control accuracy. In addition, we have developed a robust large-scale model with 1.2 billion parameters, showcasing exceptional controllability and musicality. Music samples generated by MuseCoco are available via this link 1, and the code is available at this link 2.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Multimedia,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/home/carlos/Zotero/storage/PW28ZPDB/Lu et al. - 2023 - MuseCoco Generating Symbolic Music from Text.pdf}
}

@article{mahuAttackTransientFlue1993,
  title = {Attack Transient of a Flue Organ Pipe},
  author = {Mahu, W.E.A. and Peters, M.C.A.M. and Verge, M.P. and Wijnands, A.P.J. and Fabre, B. and Hirschberg, A.},
  editor = {Dijksman, J.F. and Nieuwstadt, F.T.M.},
  date = {1993},
  journaltitle = {Topics in applied mechanics : integration of theory and applications in applied mechanics [2nd National mechanics conference, November 1992, Kerkrade, The Netherlands]},
  pages = {163--171},
  publisher = {{Kluwer Academic Publishers}},
  location = {{Dordrecht}},
  issn = {0-7923-2442-0}
}

@online{malachAutoRegressiveNextTokenPredictors2023,
  title = {Auto-{{Regressive Next-Token Predictors}} Are {{Universal Learners}}},
  author = {Malach, Eran},
  date = {2023-09-13},
  eprint = {2309.06979},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2309.06979},
  urldate = {2023-09-27},
  abstract = {Large language models display remarkable capabilities in logical and mathematical reasoning, allowing them to solve complex tasks. Interestingly, these abilities emerge in networks trained on the simple task of next-token prediction. In this work, we present a theoretical framework for studying auto-regressive next-token predictors. We demonstrate that even simple models such as linear next-token predictors, trained on Chain-ofThought (CoT) data, can approximate any function efficiently computed by a Turing machine. We introduce a new complexity measure—length complexity—which measures the number of intermediate tokens in a CoT sequence required to approximate some target function, and analyze the interplay between length complexity and other notions of complexity. Finally, we show experimentally that simple next-token predictors, such as linear networks and shallow Multi-Layer Perceptrons (MLPs), display non-trivial performance on text generation and arithmetic tasks. Our results demonstrate that the power of language models can be attributed, to a great extent, to the auto-regressive next-token training scheme, and not necessarily to a particular choice of architecture.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/carlos/Zotero/storage/3B7X3RYX/Malach - 2023 - Auto-Regressive Next-Token Predictors are Universa.pdf}
}

@article{manickamResearchStudyApplications2017,
  title = {Research Study on Applications of Artificial Neural Networks and E-Learning Personalization},
  author = {Manickam, M.R.M. and Mohanapriya, M. and Kale, Sandip and Uday, M. and Kulkarni, Prashant and Khandagale, Y. and Patil, S.P.},
  date = {2017-08-01},
  journaltitle = {International Journal of Civil Engineering and Technology},
  shortjournal = {International Journal of Civil Engineering and Technology},
  volume = {8},
  pages = {1422--1432},
  abstract = {The artificial neural network may likely be the complete solution over the most recent decades which have been broadly utilized as a part of a huge variety of applications. This article focuses on vast artificial neural network applications and importance of e-Learning application. To assess the impact of personalized learning in neural network applications. It is a need to adapt in new smart eLearning system for individual learners personalization. Artificial Neural Networks methodology to the development of new neural network model with an appropriate way of problems formulation is presented in this paper. Student’s performance prediction using neural system its impact is presented to understand the necessity of neural network in smart e-learning model. The outcome focused on the importance of using neural networks in possible applications and its influence on learner’s progress with personalization system.},
  file = {/home/carlos/Zotero/storage/WR3XIC7Q/Manickam et al. - 2017 - Research study on applications of artificial neural networks and e-learning personalization.pdf}
}

@article{martellottaVirtualAcousticReconstruction2014a,
  title = {Virtual Acoustic Reconstruction of the Church of {{Gesú}} in {{Rome}}: A Comparison between Different Design Options},
  shorttitle = {Virtual Acoustic Reconstruction of the Church of {{Gesú}} in {{Rome}}},
  author = {Martellotta, Francesco and Morales, Lidia Alvarez},
  date = {2014},
  publisher = {{Unpublished}},
  doi = {10.13140/2.1.1789.7924},
  url = {http://rgdoi.net/10.13140/2.1.1789.7924},
  urldate = {2023-05-23},
  abstract = {The church of the Gesú in Rome was built as an example of how Counterreformation churches had to be according to the Jesuit order. Among the aspects taken into account, acoustics played a significant role, because preaching was one of the key points of the Jesuit order and, at the same time, the Council of Trent had emphasized the didactic role of the liturgical singing, based on clearly understandable words. During the building of the church a dispute arose as to which was the best way to cover the church in order to get suitable acoustic conditions. Cardinal Farnese (who paid for the church) preferred a barrel vault, while Jesuits seemed to prefer the flat coffered ceiling. In the end, the barrel vault was preferred to the flat coffered ceiling, but was it the right choice? Taking advantage of an on-site measurement campaign, a virtual acoustic model of the church was created and properly calibrated. Then, using the same surface characteristics a set of modified models with a flat coffered ceiling in place of the barrel vault was created. Different ceiling heights were considered, affecting both volume (and hence reverberation time) and delay of early reflections. A point-by-point comparison was finally carried out in order to analyze the effects that the different geometric configurations had on the acoustic parameters. Different sound sources, including human voice directivity patterns, were used in different positions in order to explore in detail the effects of the different covering options. Results suggest that it was ceiling height rather than its shape that could have made a difference on acoustic behaviour.},
  langid = {english},
  file = {/home/carlos/Zotero/storage/9CRNZCDJ/Martellotta y Morales - 2014 - Virtual acoustic reconstruction of the church of G.pdf}
}

@thesis{martinezrodriguezFuzzyClusteringSimilitud2019,
  type = {http://purl.org/dc/dcmitype/Text},
  title = {El fuzzy clustering y la similitud musical: aplicación a la composición asistida por ordenador},
  shorttitle = {El fuzzy clustering y la similitud musical},
  author = {Martínez Rodríguez, Brian Santiago},
  date = {2019},
  institution = {{Universitat Politècnica de València}},
  url = {https://dialnet.unirioja.es/servlet/tesis?codigo=267745},
  urldate = {2023-05-31},
  abstract = {La composición musical asistida por ordenador es un área de conocimiento que tiene sus orígenes en la segunda mitad del siglo pasado. Durante sus más de sesenta años de existencia han aparecido numerosas propuestas para abordar el problema de la creatividad artificial aplicada al ámbito de la variación musical, la emulación de estilos, la escritura automatizada de contrapunto o la composición estocástica, entre muchos otros. En la presente memoria propondremos un nuevo método para la generación computacional de variaciones y transiciones a partir de material musical proporcionado por el compositor, ya sea de carácter melódico, rítmico, armónico o tímbrico. La originalidad de nuestro método radica en la construcción de nuevos algoritmos basados en las técnicas de agrupamiento difuso, capaces incorporar el orden de los elementos de los conjuntos de datos durante el proceso de partición. Para implementar computacionalmente estas técnicas hemos diseñado el software Mercury mediante el que realizaremos distintos experimentos cuyos resultados, en forma de transiciones musicales, ilustrarán la utilidad de nuestra propuesta. Completaremos la presente investigación con la composición de la obra Transiciones difusas, para cuarteto de cuerdas, adjunta como apéndice. La metodología propuesta implica formular una nueva medida de la disimilitud musical, aplicable de forma general a la comparación de dos secuencias numéricas cualesquiera, con las que se pueda representar cualquier tupla de atributos musicales. Es posible, por tanto, aplicar esta disimilitud sobre ámbitos más teóricos como los sistemas de afinación. Finalmente propondremos diversos métodos para estimar la compatibilidad entre un conjunto de notas y un sistema de afinación generando, en última instancia, transiciones entre diferentes sistemas.},
  langid = {spanish},
  file = {/home/carlos/Zotero/storage/N6W34AI6/tesis.html}
}

@online{mastropaoloRobustnessCodeGeneration2023,
  title = {On the {{Robustness}} of {{Code Generation Techniques}}: {{An Empirical Study}} on {{GitHub Copilot}}},
  shorttitle = {On the {{Robustness}} of {{Code Generation Techniques}}},
  author = {Mastropaolo, Antonio and Pascarella, Luca and Guglielmi, Emanuela and Ciniselli, Matteo and Scalabrino, Simone and Oliveto, Rocco and Bavota, Gabriele},
  date = {2023-02-01},
  eprint = {2302.00438},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2302.00438},
  urldate = {2023-12-26},
  abstract = {Software engineering research has always being concerned with the improvement of code completion approaches, which suggest the next tokens a developer will likely type while coding. The release of GitHub Copilot constitutes a big step forward, also because of its unprecedented ability to automatically generate even entire functions from their natural language description. While the usefulness of Copilot is evident, it is still unclear to what extent it is robust. Specifically, we do not know the extent to which semantic-preserving changes in the natural language description provided to the model have an effect on the generated code function. In this paper we present an empirical study in which we aim at understanding whether different but semantically equivalent natural language descriptions result in the same recommended function. A negative answer would pose questions on the robustness of deep learning (DL)-based code generators since it would imply that developers using different wordings to describe the same code would obtain different recommendations. We asked Copilot to automatically generate 892 Java methods starting from their original Javadoc description. Then, we generated different semantically equivalent descriptions for each method both manually and automatically, and we analyzed the extent to which predictions generated by Copilot changed. Our results show that modifying the description results in different code recommendations in \textasciitilde 46\% of cases. Also, differences in the semantically equivalent descriptions might impact the correctness of the generated code \textasciitilde 28\%.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Software Engineering},
  file = {/home/carlos/Zotero/storage/HYGTSJJX/Mastropaolo et al. - 2023 - On the Robustness of Code Generation Techniques A.pdf}
}

@misc{max,
  type = {página web},
  title = {Cycling '74},
  url = {https://cycling74.com/products/max/}
}

@thesis{mcvickerAnalyticalApproachOpen1987,
  type = {Doctoral},
  title = {An Analytical Approach to Open, Cylindrical Organ-Pipe Scaling from a Historical Perspective with Specific Reference to the Scaling Practices of Selected Organ-Builders.},
  author = {McVicker, William Richard},
  date = {1987},
  institution = {{Durham University}},
  url = {http://etheses.dur.ac.uk/1551/},
  urldate = {2023-05-23},
  file = {/home/carlos/Zotero/storage/8ZTPDTKA/McVicker - 1987 - An analytical approach to open, cylindrical organ-.pdf;/home/carlos/Zotero/storage/MIQ7HFXY/1551.html}
}

@online{michaelisBroadDatasetAll2022,
  title = {A {{Broad Dataset}} Is {{All You Need}} for {{One-Shot Object Detection}}},
  author = {Michaelis, Claudio and Bethge, Matthias and Ecker, Alexander S.},
  date = {2022-10-29},
  eprint = {2011.04267},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2011.04267},
  url = {http://arxiv.org/abs/2011.04267},
  urldate = {2024-01-22},
  abstract = {Is it possible to detect arbitrary objects from a single example? A central problem of all existing attempts at one-shot object detection is the generalization gap: Object categories used during training are detected much more reliably than novel ones. We here show that this generalization gap can be nearly closed by increasing the number of object categories used during training. Doing so allows us to improve generalization from seen to unseen classes from 45\% to 89\% and improve the state-of-the-art on COCO by 5.4 \%AP50 (from 22.0 to 27.5). We verify that the effect is caused by the number of categories and not the number of training samples, and that it holds for different models, backbones and datasets. This result suggests that the key to strong few-shot detection models may not lie in sophisticated metric learning approaches, but instead simply in scaling the number of categories. We hope that our findings will help to better understand the challenges of few-shot learning and encourage future data annotation efforts to focus on wider datasets with a broader set of categories rather than gathering more samples per category.},
  pubstate = {preprint},
  version = {2},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/home/carlos/Zotero/storage/TTGXP52I/Michaelis et al. - 2022 - A Broad Dataset is All You Need for One-Shot Object Detection.pdf;/home/carlos/Zotero/storage/ZSWF3IMF/2011.html}
}

@article{miklosInteractionReedResonator2006,
  title = {Interaction of Reed and Resonator by Sound Generation in a Reed Organ Pipe},
  author = {Miklós, András and Angster, Judit and Pitsch, Stephan and Rossing, Thomas D.},
  date = {2006-05-01},
  journaltitle = {The Journal of the Acoustical Society of America},
  shortjournal = {The Journal of the Acoustical Society of America},
  volume = {119},
  number = {5},
  pages = {3121--3129},
  issn = {0001-4966},
  doi = {10.1121/1.2188372},
  url = {https://doi.org/10.1121/1.2188372},
  urldate = {2023-05-23},
  abstract = {Interaction of reed and resonator in reed organ pipes without and with the resonator has been investigated. The wave form of the sound generated without the resonator attached is a periodic train (with the frequency of reed vibration) of decaying high frequency oscillation. The frequency of this oscillation is independent of the frequency of the reed vibration; it corresponds roughly to the fundamental acoustic resonance of the shallot. Another rather surprising phenomenon was also observed: without the pipe resonator, the reed vibration frequency, and correspondingly the sound frequency is a continuous function of the reed vibrating length, but when the resonator is added “forbidden” frequency domains occur in the vicinity of the eigenfrequencies of the resonator, and the sound frequency jumps abruptly from below to above each resonance frequency of the resonator, when the reed is shortened. This effect can be explained by the coupling between two oscillating systems, the reed and the acoustic resonator. The presented investigations result in a better understanding of the acoustical and mechanical aspects of sound generation in reed pipes, which may allow organ builders and voicers to easier pipe design and more accurate voicing to obtain the desired sound.},
  file = {/home/carlos/Zotero/storage/RS93TGMK/Interaction-of-reed-and-resonator-by-sound.html}
}

@article{miklosReedVibrationLingual2003,
  title = {Reed Vibration in Lingual Organ Pipes without the Resonators},
  author = {Miklós, András and Angster, Judit and Pitsch, Stephan and Rossing, Thomas},
  date = {2003-03-01},
  journaltitle = {The Journal of the Acoustical Society of America},
  shortjournal = {The Journal of the Acoustical Society of America},
  volume = {113},
  pages = {1081--91},
  doi = {10.1121/1.1534101},
  abstract = {Vibrations of plucked and blown reeds of lingual organ pipes without the resonators have been investigated. Three rather surprising phenomena are observed: the frequency of the reed plucked by hand is shifted upwards for large-amplitude plucking, the blown frequency is significantly higher than the plucked one, and peaks halfway between the harmonics of the fundamental frequency appear in the spectrum of the reed velocity. The dependence of the plucked frequency on the length of the reed reveals that the vibrating length at small vibrations is 3 mm shorter than the apparent free length. The frequency shift for large-amplitude plucking is explained by the periodic change of the vibrating length during the oscillation. Reed vibrations of the blown pipe can be described by a physical model based on the assumption of air flow between the reed and the shallot. Aerodynamic effects may generate and sustain the oscillation of the reed without acoustic feedback. The appearance of subharmonics is explained by taking into account the periodic modulation of the stress in the reed material by the sound field. Therefore, a parametric instability appears in the differential equation of vibration, leading to the appearance of subharmonics.},
  file = {/home/carlos/Zotero/storage/VT6SFNJE/Miklós et al. - 2003 - Reed vibration in lingual organ pipes without the .pdf}
}

@book{minsky1969perceptrons,
  title = {Perceptrons: An Introduction to Computational Geometry},
  author = {Minsky, M. and Papert, S.},
  date = {1969},
  publisher = {{MIT Press}},
  url = {https://books.google.es/books?id=Ow1OAQAAIAAJ},
  isbn = {978-0-262-63022-1},
  lccn = {69014379}
}

@book{minskyPerceptronsIntroductionComputational2017,
  title = {Perceptrons: {{An Introduction}} to {{Computational Geometry}}},
  shorttitle = {Perceptrons},
  author = {Minsky, Marvin and Papert, Seymour A.},
  date = {2017-09-22},
  publisher = {{The MIT Press}},
  doi = {10.7551/mitpress/11301.001.0001},
  url = {https://direct.mit.edu/books/book/3132/PerceptronsAn-Introduction-to-Computational},
  urldate = {2023-12-21},
  abstract = {The first systematic study of parallelism in computation by two pioneers in the field.Reissue of the 1988 Expanded Edition with a new foreword by Léon BottouIn},
  isbn = {978-0-262-34393-0},
  langid = {english},
  file = {/home/carlos/Zotero/storage/VUWTY5QW/PerceptronsAn-Introduction-to-Computational.html}
}

@online{mishkinAllYouNeed2016,
  title = {All You Need Is a Good Init},
  author = {Mishkin, Dmytro and Matas, Jiri},
  date = {2016-02-19},
  eprint = {1511.06422},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1511.06422},
  url = {http://arxiv.org/abs/1511.06422},
  urldate = {2024-01-22},
  abstract = {Layer-sequential unit-variance (LSUV) initialization - a simple method for weight initialization for deep net learning - is proposed. The method consists of the two steps. First, pre-initialize weights of each convolution or inner-product layer with orthonormal matrices. Second, proceed from the first to the final layer, normalizing the variance of the output of each layer to be equal to one. Experiment with different activation functions (maxout, ReLU-family, tanh) show that the proposed initialization leads to learning of very deep nets that (i) produces networks with test accuracy better or equal to standard methods and (ii) is at least as fast as the complex schemes proposed specifically for very deep nets such as FitNets (Romero et al. (2015)) and Highway (Srivastava et al. (2015)). Performance is evaluated on GoogLeNet, CaffeNet, FitNets and Residual nets and the state-of-the-art, or very close to it, is achieved on the MNIST, CIFAR-10/100 and ImageNet datasets.},
  pubstate = {preprint},
  version = {7},
  keywords = {Computer Science - Machine Learning},
  file = {/home/carlos/Zotero/storage/Z8PT92DE/Mishkin y Matas - 2016 - All you need is a good init.pdf;/home/carlos/Zotero/storage/FE846CPB/1511.html}
}

@inreference{ModelacionLenguaje2024,
  title = {Modelación del lenguaje},
  booktitle = {Wikipedia, la enciclopedia libre},
  date = {2024-01-15T00:14:03Z},
  url = {https://es.wikipedia.org/w/index.php?title=Modelaci%C3%B3n_del_lenguaje&oldid=157157282},
  urldate = {2024-01-24},
  abstract = {Un modelo estadístico de lenguaje asigna una probabilidad a una secuencia de m palabras                         P         (                    w                        1                             ,         …         ,                    w                        m                             )                 \{\textbackslash displaystyle P(w\_\{1\},\textbackslash ldots ,w\_\{m\})\}    mediante una distribución de probabilidad. Contar con una forma de estimar la verosimilitud de diversas frases resulta sumamente útil en una variedad de aplicaciones dentro del procesamiento del lenguaje natural. Los modelos de lenguaje se emplean en el reconocimiento de voz, la traducción automática, el etiquetado de discurso, el análisis de texto, el reconocimiento de escritura, la recuperación de información y otras muchas aplicaciones.},
  langid = {spanish},
  annotation = {Page Version ID: 157157282},
  file = {/home/carlos/Zotero/storage/LTFQTHQH/Modelación_del_lenguaje.html}
}

@book{molinaColeccionesGMEPresente2018,
  title = {Las Colecciones Del {{GME}}: Presente, Pasado y Futuro},
  author = {Molina, Sylvia and Osona, Javier and Sanz Vázquez, Julio and family=Saz, given=Daniel, prefix=del, useprefix=true and Alcázar, Antonio J.},
  date = {2018},
  edition = {1ª},
  publisher = {{Ed. de la Universidad de Castilla–La Mancha}},
  location = {{Cuenca}}
}

@article{moradidakhelGitHubCopilotAI2023,
  title = {{{GitHub Copilot AI}} Pair Programmer: {{Asset}} or {{Liability}}?},
  shorttitle = {{{GitHub Copilot AI}} Pair Programmer},
  author = {Moradi Dakhel, Arghavan and Majdinasab, Vahid and Nikanjam, Amin and Khomh, Foutse and Desmarais, Michel C. and Jiang, Zhen Ming (Jack)},
  date = {2023-09-01},
  journaltitle = {Journal of Systems and Software},
  shortjournal = {Journal of Systems and Software},
  volume = {203},
  pages = {111734},
  issn = {0164-1212},
  doi = {10.1016/j.jss.2023.111734},
  url = {https://www.sciencedirect.com/science/article/pii/S0164121223001292},
  urldate = {2023-12-26},
  abstract = {Automatic program synthesis is a long-lasting dream in software engineering. Recently, a promising Deep Learning (DL) based solution, called Copilot, has been proposed by OpenAI and Microsoft as an industrial product. Although some studies evaluate the correctness of Copilot solutions and report its issues, more empirical evaluations are necessary to understand how developers can benefit from it effectively. In this paper, we study the capabilities of Copilot in two different programming tasks: (i) generating (and reproducing) correct and efficient solutions for fundamental algorithmic problems, and (ii) comparing Copilot’s proposed solutions with those of human programmers on a set of programming tasks. For the former, we assess the performance and functionality of Copilot in solving selected fundamental problems in computer science, like sorting and implementing data structures. In the latter, a dataset of programming problems with human-provided solutions is used. The results show that Copilot is capable of providing solutions for almost all fundamental algorithmic problems, however, some solutions are buggy and non-reproducible. Moreover, Copilot has some difficulties in combining multiple methods to generate a solution. Comparing Copilot to humans, our results show that the correct ratio of humans’ solutions is greater than Copilot’s suggestions, while the buggy solutions generated by Copilot require less effort to be repaired. Based on our findings, if Copilot is used by expert developers in software projects, it can become an asset since its suggestions could be comparable to humans’ contributions in terms of quality. However, Copilot can become a liability if it is used by novice developers who may fail to filter its buggy or non-optimal solutions due to a lack of expertise.},
  keywords = {Code completion,GitHub copilot,Language model,Testing},
  file = {/home/carlos/Zotero/storage/UZ645QAQ/Moradi Dakhel et al. - 2023 - GitHub Copilot AI pair programmer Asset or Liabil.pdf;/home/carlos/Zotero/storage/U3TB2FHT/S0164121223001292.html}
}

@article{MoreDifferent1972,
  title = {More {{Is Different}}},
  date = {1972},
  volume = {177},
  langid = {english},
  file = {/home/carlos/Zotero/storage/SUBB5CWU/1972 - More Is Different.pdf}
}

@article{mukherjeeOrcaProgressiveLearning2023,
  title = {Orca: {{Progressive Learning}} from {{Complex Explanation Traces}} of {{GPT-4}}},
  shorttitle = {Orca},
  author = {Mukherjee, Subhabrata (Subho) and Mitra, Arindam and Jawahar, Ganesh and Agarwal, Sahaj and Palangi, Hamid and Awadallah, Ahmed H.},
  date = {2023-06-01},
  url = {https://www.microsoft.com/en-us/research/publication/orca-progressive-learning-from-complex-explanation-traces-of-gpt-4/},
  urldate = {2023-06-25},
  abstract = {Recent research has focused on enhancing the capability of smaller models through imitation~learning, drawing on the outputs generated by large foundation models (LFMs). A number of issues impact the quality of these models, ranging from~limited imitation signals~from shallow LFM outputs; small scale homogeneous training data; and most notably a lack of rigorous evaluation resulting in […]},
  langid = {american},
  file = {/home/carlos/Zotero/storage/ANQ2XMEH/orca-progressive-learning-from-complex-explanation-traces-of-gpt-4.html}
}

@article{nielsenNeuralNetworksDeep2015,
  title = {Neural {{Networks}} and {{Deep Learning}}},
  author = {Nielsen, Michael A.},
  date = {2015},
  publisher = {{Determination Press}},
  url = {http://neuralnetworksanddeeplearning.com},
  urldate = {2023-05-24},
  langid = {english},
  file = {/home/carlos/Zotero/storage/TZXGVB5T/index.html}
}

@online{noeverTuringDeception2022,
  title = {The {{Turing Deception}}},
  author = {Noever, David and Ciolino, Matt},
  date = {2022-12-23},
  eprint = {2212.06721},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2212.06721},
  url = {http://arxiv.org/abs/2212.06721},
  urldate = {2024-01-27},
  abstract = {This research revisits the classic Turing test and compares recent large language models such as ChatGPT for their abilities to reproduce human-level comprehension and compelling text generation. Two task challenges -- summarization, and question answering -- prompt ChatGPT to produce original content (98-99\%) from a single text entry and also sequential questions originally posed by Turing in 1950. We score the original and generated content against the OpenAI GPT-2 Output Detector from 2019, and establish multiple cases where the generated content proves original and undetectable (98\%). The question of a machine fooling a human judge recedes in this work relative to the question of "how would one prove it?" The original contribution of the work presents a metric and simple grammatical set for understanding the writing mechanics of chatbots in evaluating their readability and statistical clarity, engagement, delivery, and overall quality. While Turing's original prose scores at least 14\% below the machine-generated output, the question of whether an algorithm displays hints of Turing's truly original thoughts (the "Lovelace 2.0" test) remains unanswered and potentially unanswerable for now.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/carlos/Zotero/storage/MTI49WUJ/Noever y Ciolino - 2022 - The Turing Deception.pdf;/home/carlos/Zotero/storage/JKLFGCTV/2212.html}
}

@thesis{nordgrenPROMPTENGINEERINGITS2023,
  title = {{{PROMPT ENGINEERING AND ITS USABILITY TO IMPROVE MODERN PSYCHOLOGY CHATBOTS}}},
  author = {Nordgren, Isak J and Svensson, L Gustaf E},
  date = {2023},
  abstract = {As advancements in chatbots and Large Language Models (LLMs) such as GPT-3.5 and GPT-4 continue, their applications in diverse fields, including psychology, expand. This study investigates the effectiveness of LLMs optimized through prompt engineering, aiming to enhance their performance in psychological applications. To this end, two distinct versions of a GPT-3.5-based chatbot were developed: a version similar to the base model, and a version equipped with a more extensive system prompt detailing expected behavior.},
  langid = {english},
  file = {/home/carlos/Zotero/storage/PXI4SHRK/Nordgren y Svensson - PROMPT ENGINEERING AND ITS USABILITY TO IMPROVE MODERN PSYCHOLOGY CHATBOTS.pdf}
}

@book{nyquist,
  type = {artículo en PDF},
  title = {Sampling Theory for Digital Audio},
  author = {Lavry, Dan},
  date = {2004},
  url = {http://lavryengineering.com/pdfs/lavry-sampling-theory.pdf},
  lastchecked = {el 10 de mayo de 2020}
}

@article{odyaSoundIntensityDistribution2017,
  title = {Sound {{Intensity Distribution Around Organ Pipe}}},
  author = {Odya, Piotr and Kotus, Józef and Szczodrak, Maciej and Kostek, Bozena},
  date = {2017-03-01},
  journaltitle = {Archives of Acoustics},
  shortjournal = {Archives of Acoustics},
  volume = {42},
  doi = {10.1515/aoa-2017-0002},
  abstract = {The aim of the paper was to compare acoustic field around the open and stopped organ pipes. The wooden organ pipe was located in the anechoic chamber and activated with a constant air flow, produced by an external air-compressor. Thus, a long-term steady state response was possible to obtain. Multi-channel acoustic vector sensor was used to measure the sound intensity distribution of radiated acoustic energy. Measurements have been carried out on a defined fixed grid of points. A specialized Cartesian robot allowed for a precise positioning of the acoustic probe. The resulted data were processed in order to obtain and visualize the sound intensity distribution around the pipe, taking into account the type of the organ pipe, frequency of the generated sound, the sound pressure level and the direction of acoustic energy propagation. For the open pipe, an additional sound source was identified at the top of the pipe. In this case, the streamlines in front of the pipe are propagated horizontally and in a greater distance than in a case of the stopped pipe, moreover they are directed downwards. For the stopped pipe, the streamlines of the acoustic flow were directed upwards. The results for both pipe types were compared and discussed in the paper.},
  file = {/home/carlos/Zotero/storage/KPDQJFNS/Odya et al. - 2017 - Sound Intensity Distribution Around Organ Pipe.pdf}
}

@online{openaiGPT4TechnicalReport2023,
  title = {{{GPT-4 Technical Report}}},
  author = {OpenAI},
  date = {2023-03-27},
  eprint = {2303.08774},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2303.08774},
  url = {http://arxiv.org/abs/2303.08774},
  urldate = {2023-09-27},
  abstract = {We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10\% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.},
  pubstate = {preprint},
  version = {3},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/carlos/Zotero/storage/LNICJHTX/OpenAI - 2023 - GPT-4 Technical Report.pdf;/home/carlos/Zotero/storage/3GV3BCSS/2303.html}
}

@misc{OpenSoundControl,
  type = {página web},
  title = {Open {{Sound Control}}},
  annotation = {Published: opensoundcontrol.org}
}

@misc{osc,
  type = {página web},
  title = {Open Sound Control},
  howpublished = {{$<$}a href="opensoundcontrol.org"{$>$}opensoundcontrol.org{$<$}/a{$>$}}
}

@online{OvertoneCollaborativeProgrammable,
  title = {Overtone - {{Collaborative Programmable Music}}},
  url = {https://overtone.github.io/},
  urldate = {2023-12-09},
  file = {/home/carlos/Zotero/storage/LXF2GLUX/overtone.github.io.html}
}

@online{PapersCodeAudioLM,
  title = {Papers with {{Code}} - {{AudioLM}}: A {{Language Modeling Approach}} to {{Audio Generation}}},
  shorttitle = {Papers with {{Code}} - {{AudioLM}}},
  url = {https://paperswithcode.com/paper/audiolm-a-language-modeling-approach-to-audio},
  urldate = {2024-01-04},
  abstract = {Implemented in 4 code libraries.},
  langid = {english},
  file = {/home/carlos/Zotero/storage/U33C57MP/audiolm-a-language-modeling-approach-to-audio.html}
}

@online{PapersCodeGPT4,
  title = {Papers with {{Code}} - {{GPT-4 Explained}}},
  url = {https://paperswithcode.com/method/gpt-4},
  urldate = {2023-09-27},
  abstract = {GPT-4 is a transformer based model pre-trained to predict the next token in a document.},
  langid = {english},
  file = {/home/carlos/Zotero/storage/B47UHZWU/gpt-4.html}
}

@online{PapersCodeMuseCoco,
  title = {Papers with {{Code}} - {{MuseCoco}}: {{Generating Symbolic Music}} from {{Text}}},
  shorttitle = {Papers with {{Code}} - {{MuseCoco}}},
  url = {https://paperswithcode.com/paper/musecoco-generating-symbolic-music-from-text},
  urldate = {2024-01-04},
  abstract = {Implemented in one code library.},
  langid = {english},
  file = {/home/carlos/Zotero/storage/WCM7YULJ/musecoco-generating-symbolic-music-from-text.html}
}

@online{PapersCodeRobustness,
  title = {Papers with {{Code}} - {{On}} the {{Robustness}} of {{Code Generation Techniques}}: {{An Empirical Study}} on {{GitHub Copilot}}},
  shorttitle = {Papers with {{Code}} - {{On}} the {{Robustness}} of {{Code Generation Techniques}}},
  url = {https://cs.paperswithcode.com/paper/on-the-robustness-of-code-generation},
  urldate = {2023-12-26},
  abstract = {Implemented in one code library.},
  langid = {english},
  file = {/home/carlos/Zotero/storage/T33YVX3N/on-the-robustness-of-code-generation.html}
}

@online{PapersCodeWavJourney,
  title = {Papers with {{Code}} - {{WavJourney}}: {{Compositional Audio Creation}} with {{Large Language Models}}},
  shorttitle = {Papers with {{Code}} - {{WavJourney}}},
  url = {https://paperswithcode.com/paper/wavjourney-compositional-audio-creation-with},
  urldate = {2024-01-04},
  abstract = {Implemented in one code library.},
  langid = {english},
  file = {/home/carlos/Zotero/storage/WIJE3S3G/wavjourney-compositional-audio-creation-with.html}
}

@article{paquierEffectWoodSound2016,
  title = {Effect of Wood on the Sound of Oboe as Simulated by the Chanter of a 16-Inch {{French}} Bagpipe},
  author = {Paquier, Mathieu and Hendrickx, Etienne and Jeannin, Raphaël},
  date = {2016-02-01},
  journaltitle = {Applied Acoustics},
  shortjournal = {Applied Acoustics},
  volume = {103},
  pages = {47--53},
  doi = {10.1016/j.apacoust.2015.10.008},
  abstract = {Many objective and subjective experiments on brass instruments, organs, flutes and clarinets have shown that the influence of material was weak. Yet, the influence of wood on the sound of oboes is still to be determined. In this study, short musical recordings of ten French 16″ bagpipes made of 5 different woods (African Ebony, Santos Rosewood, Boxwood, African Blackwood and Service Tree) were presented to subjects (specialist and naïve), who had to give their feedback on several criteria (global quality, warmth, aggressiveness, brightness, volume and attack precision). The choice of a bagpipe rather than a simple oboe enables to minimize the influence of the musician, as he is not directly in contact with the reed. An influence of the reed material was found, but no influence of the wood. In a second experiment, a discrimination task allowed to confirm that the differences between chanters were not principally due to the wood. Several physical parameters calculated from recorded signals could also not reveal any large differences between woods.},
  file = {/home/carlos/Zotero/storage/3C5Z48UX/Paquier et al. - 2016 - Effect of wood on the sound of oboe as simulated b.pdf}
}

@online{pengImpactAIDeveloper2023a,
  title = {The {{Impact}} of {{AI}} on {{Developer Productivity}}: {{Evidence}} from {{GitHub Copilot}}},
  shorttitle = {The {{Impact}} of {{AI}} on {{Developer Productivity}}},
  author = {Peng, Sida and Kalliamvakou, Eirini and Cihon, Peter and Demirer, Mert},
  date = {2023-02-13},
  eprint = {2302.06590},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2302.06590},
  urldate = {2023-12-27},
  abstract = {Generative AI tools hold promise to increase human productivity. This paper presents results from a controlled experiment with GitHub Copilot, an AI pair programmer. Recruited software developers were asked to implement an HTTP server in JavaScript as quickly as possible. The treatment group, with access to the AI pair programmer, completed the task 55.8\% faster than the control group. Observed heterogenous effects show promise for AI pair programmers to help people transition into software development careers.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Software Engineering},
  file = {/home/carlos/Zotero/storage/UEPW89PF/Peng et al. - 2023 - The Impact of AI on Developer Productivity Eviden.pdf}
}

@book{penroseNuevaMenteEmperador2015,
  title = {La nueva mente del emperador},
  author = {Penrose, Roger},
  date = {2015-07-02},
  eprint = {sLz3CQAAQBAJ},
  eprinttype = {googlebooks},
  publisher = {{Penguin Random House Grupo Editorial España}},
  abstract = {Un apasionante paseo por la matemática y la física, y por los hallazgos del pensamiento humano de la mano de Roger Penrose, Premio Nobel de Física 2020. Durante décadas, los defensores de la inteligencia artificial han mantenido que los ordenadores harán pronto todo lo que la mente humana puede hacer. En su favor, se puede utilizar, por ejemplo, el que ya hay máquinas que juegan al ajedrez como los grandes maestros. Ahora bien, ¿comprenden el juego como lo hacemos nosotros?En este libro, Roger Penrose, probablemente el especialista en la teoría general de la relatividad más prestigioso del mundo y una de las mentes analíticas más originales de la actualidad, sostiene que existen facetas del pensamiento humano que nunca serán emuladas por un ordenador. Para defender esa tesis, Penrose recurre a una amplia gama de conocimientos científicos, que van desde la máquina de Turing hasta la estructura del cerebro, pasando por el teorema de Gödel, los agujeros negros y los blancos, la radiación de Hawking, la entropía o la mecánica cuántica. Entre los numerosos estudios existentes dedicados a la relación entre la mente y el cuerpo, esta ambiciosa obra sobresale tanto por su lucidez y claridad como por su rigor y profundidad. Reseña:«Un libro audaz, brillante e innovador. Cuando Penrose habla, los científicos escuchan.»The New York Times Book Review},
  isbn = {978-84-663-3083-1},
  langid = {spanish},
  pagetotal = {870},
  keywords = {Computers / Artificial Intelligence / General,Science / Essays,Science / General,Science / Life Sciences / Neuroscience}
}

@article{perez-arroyoSintetizadorInstrumentoEra1984,
  title = {El Sintetizador: El Instrumento de La Era Visual},
  author = {Pérez-Arroyo, Rafael},
  date = {1984},
  journaltitle = {Ritmo},
  volume = {542},
  pages = {12--16}
}

@online{perezThreadsYaSupera2023,
  title = {Threads ya supera los 100 millones de usuarios. Ha aplastado el récord que tenía ChatGPT},
  author = {Pérez, Enrique},
  date = {2023-07-10T07:20:00Z},
  url = {https://www.xataka.com/aplicaciones/threads-supera-100-millones-usuarios-ha-aplastado-record-que-tenia-chatgpt},
  urldate = {2023-12-08},
  abstract = {La tecnología va a un ritmo vertiginoso. Threads, el rival de Twitter de Instagram, llegó oficialmente la semana pasada. Y aunque para usarlo en Europa hay...},
  langid = {spanish},
  organization = {{Xataka}},
  file = {/home/carlos/Zotero/storage/9CKSGAN7/threads-supera-100-millones-usuarios-ha-aplastado-record-que-tenia-chatgpt.html}
}

@online{ph.dTrainingTimeFoundation2023,
  title = {The Training Time of the Foundation Models (from Scratch)},
  author = {Ph.D, Michał Marcińczuk},
  date = {2023-11-17T07:43:49},
  url = {https://medium.com/codenlp/the-training-time-of-the-foundation-models-from-scratch-59bbce90cc87},
  urldate = {2024-01-21},
  abstract = {How many GPU hours does it take to train a large language model (LLM)?},
  langid = {english},
  organization = {{CodeNLP}},
  file = {/home/carlos/Zotero/storage/WE2QT4G9/the-training-time-of-the-foundation-models-from-scratch-59bbce90cc87.html}
}

@incollection{pierceBasicLinearAcoustics2007,
  title = {Basic {{Linear Acoustics}}},
  booktitle = {Springer {{Handbook}} of {{Acoustics}}},
  author = {Pierce, Alan},
  editor = {Rossing, Thomas D.},
  date = {2007},
  series = {Springer {{Handbooks}}},
  pages = {25--111},
  publisher = {{Springer}},
  location = {{New York, NY}},
  doi = {10.1007/978-0-387-30425-0_3},
  url = {https://doi.org/10.1007/978-0-387-30425-0_3},
  urldate = {2023-05-23},
  abstract = {This chapter deals with the physical and mathematical aspects of sound when the disturbances are, in some sense, small. Acoustics is usually concerned with small-amplitude phenomena, and consequently a~linear description is usually applicable. Disturbances are governed by the properties of the medium in which they occur, and the governing equations are the equations of continuum mechanics, which apply equally to gases, liquids, and solids. These include the mass, momentum, and energy equations, as well as thermodynamic principles. The viscosity and thermal conduction enter into the versions of these equations that apply to fluids. Fluids of typical great interest are air and sea water, and consequently this chapter includes a~summary of their relevant acoustic properties. The foundation is also laid for the consideration of acoustic waves in elastic solids, suspensions, bubbly liquids, and porous media.},
  isbn = {978-0-387-30425-0},
  langid = {english},
  keywords = {Acoustic Pressure,Complex Amplitude,Helmholtz Equation,Recursion Relation,Sound Speed}
}

@online{PrimerosMesesChat2023,
  title = {Primeros 6 meses del Chat GPT, ¿cuáles son sus logros y desafíos?},
  date = {2023-05-24T17:13:28+00:00},
  url = {https://www.noticiasradioreflejos.com.ar/2021/primeros-6-meses-del-chat-gpt-cuales-son-sus-logros-y-desafios/},
  urldate = {2023-12-08},
  abstract = {Buenos Aires, mayo de 2023 – Bruno Ruyú, profesor de la Maestría de Ciencias de Datos de la Universidad Austral, hace un repaso por los principales logros y desafíos del ChatGPT. “El ChatGPT logró alcanzar los 100 millones de usuarios en dos meses, un número impresionante. Mientras Instagram alcanzó este record en 30 meses, Spotify […]},
  langid = {spanish},
  organization = {{Noticias Radio Reflejos}},
  file = {/home/carlos/Zotero/storage/K7W3P7AF/primeros-6-meses-del-chat-gpt-cuales-son-sus-logros-y-desafios.html}
}

@online{PromptEngineeringGuide2023,
  title = {Prompt {{Engineering Guide}}},
  date = {2023-12-22},
  url = {https://www.promptingguide.ai/},
  urldate = {2024-01-05},
  abstract = {A Comprehensive Overview of Prompt Engineering},
  langid = {english},
  file = {/home/carlos/Zotero/storage/866LWP67/www.promptingguide.ai.html}
}

@online{QueConsistenModelos,
  title = {¿En qué consisten los modelos autorregresivos?: Explicación sobre los modelos autorregresivos: AWS},
  shorttitle = {¿En qué consisten los modelos autorregresivos?},
  url = {https://aws.amazon.com/es/what-is/autoregressive-models/},
  urldate = {2024-01-26},
  abstract = {En qué consisten los modelos autorregresivos, de qué manera y por qué las empresas recurren a estos y cómo se utilizan con AWS.},
  langid = {spanish},
  organization = {{Amazon Web Services, Inc.}},
  file = {/home/carlos/Zotero/storage/6AHZ6W4R/autoregressive-models.html}
}

@online{QueEsAjuste,
  title = {¿Qué es el ajuste de hiperparámetros? - Explicación de los métodos de ajuste de hiperparámetros - AWS},
  shorttitle = {¿Qué es el ajuste de hiperparámetros?},
  url = {https://aws.amazon.com/es/what-is/hyperparameter-tuning/},
  urldate = {2024-01-26},
  abstract = {Qué es el ajuste de hiperparámetros, cómo y por qué lo utiliza las empresas, y cómo se utiliza con AWS.},
  langid = {spanish},
  organization = {{Amazon Web Services, Inc.}},
  file = {/home/carlos/Zotero/storage/XYHKEV34/hyperparameter-tuning.html}
}

@article{radfordLanguageModelsAre2019a,
  title = {Language {{Models}} Are {{Unsupervised Multitask Learners}}},
  author = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  date = {2019},
  abstract = {Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset - matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.},
  langid = {english},
  file = {/home/carlos/Zotero/storage/F5MP43DF/Radford et al. - Language Models are Unsupervised Multitask Learner.pdf}
}

@online{radovanovicEmergingArchitecturesLLM2023,
  title = {Emerging {{Architectures}} for {{LLM Applications}}},
  author = {Radovanovic, Rajko, Matt Bornstein},
  date = {2023-06-20T19:23:48+00:00},
  url = {https://a16z.com/2023/06/20/emerging-architectures-for-llm-applications/},
  urldate = {2023-06-27},
  abstract = {A reference architecture for the LLM app stack. It shows the most common systems, tools, and design patterns used by AI startups and tech companies.},
  langid = {american},
  organization = {{Andreessen Horowitz}},
  file = {/home/carlos/Zotero/storage/PAWYWIEW/emerging-architectures-for-llm-applications.html}
}

@online{ramsauerHopfieldNetworksAll2021,
  title = {Hopfield {{Networks}} Is {{All You Need}}},
  author = {Ramsauer, Hubert and Schäfl, Bernhard and Lehner, Johannes and Seidl, Philipp and Widrich, Michael and Adler, Thomas and Gruber, Lukas and Holzleitner, Markus and Pavlović, Milena and Sandve, Geir Kjetil and Greiff, Victor and Kreil, David and Kopp, Michael and Klambauer, Günter and Brandstetter, Johannes and Hochreiter, Sepp},
  date = {2021-04-28},
  eprint = {2008.02217},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2008.02217},
  url = {http://arxiv.org/abs/2008.02217},
  urldate = {2024-01-22},
  abstract = {We introduce a modern Hopfield network with continuous states and a corresponding update rule. The new Hopfield network can store exponentially (with the dimension of the associative space) many patterns, retrieves the pattern with one update, and has exponentially small retrieval errors. It has three types of energy minima (fixed points of the update): (1) global fixed point averaging over all patterns, (2) metastable states averaging over a subset of patterns, and (3) fixed points which store a single pattern. The new update rule is equivalent to the attention mechanism used in transformers. This equivalence enables a characterization of the heads of transformer models. These heads perform in the first layers preferably global averaging and in higher layers partial averaging via metastable states. The new modern Hopfield network can be integrated into deep learning architectures as layers to allow the storage of and access to raw input data, intermediate results, or learned prototypes. These Hopfield layers enable new ways of deep learning, beyond fully-connected, convolutional, or recurrent networks, and provide pooling, memory, association, and attention mechanisms. We demonstrate the broad applicability of the Hopfield layers across various domains. Hopfield layers improved state-of-the-art on three out of four considered multiple instance learning problems as well as on immune repertoire classification with several hundreds of thousands of instances. On the UCI benchmark collections of small classification tasks, where deep learning methods typically struggle, Hopfield layers yielded a new state-of-the-art when compared to different machine learning methods. Finally, Hopfield layers achieved state-of-the-art on two drug design datasets. The implementation is available at: https://github.com/ml-jku/hopfield-layers},
  pubstate = {preprint},
  version = {3},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  file = {/home/carlos/Zotero/storage/36MASUK3/Ramsauer et al. - 2021 - Hopfield Networks is All You Need.pdf;/home/carlos/Zotero/storage/BGMBA4V5/2008.html}
}

@online{reederNewLanguageModel2023,
  title = {The {{New Language Model Stack}}},
  author = {Reeder, Michelle Fradin {and} Lauren},
  date = {2023-06-14T15:55:06+00:00},
  url = {https://www.sequoiacap.com/article/llm-stack-perspective/},
  urldate = {2023-06-27},
  abstract = {How companies are bringing AI applications to life},
  langid = {american},
  organization = {{Sequoia Capital}},
  file = {/home/carlos/Zotero/storage/QMBM8NIY/llm-stack-perspective.html}
}

@online{RegressionVsClassification2021,
  title = {Regression vs {{Classification}}, {{Explained}} - {{Sharp Sight}}},
  date = {2021-04-21T20:00:49-05:00},
  url = {https://www.sharpsightlabs.com/blog/regression-vs-classification/},
  urldate = {2024-01-26},
  abstract = {This article explains the difference between regression vs classification in machine learning. For ML tutorials, sign up for our email list.},
  langid = {american},
  file = {/home/carlos/Zotero/storage/286HSH4E/regression-vs-classification.html}
}

@online{RegressionVsClassification2021a,
  title = {Regression vs. {{Classification}} in {{Machine Learning}}: {{What}}'s the {{Difference}}?},
  shorttitle = {Regression vs. {{Classification}} in {{Machine Learning}}},
  date = {2021-10-06T07:39:30-07:00},
  url = {https://www.springboard.com/blog/data-science/regression-vs-classification/},
  urldate = {2024-01-26},
  abstract = {Comparing regression vs classification in machine learning can sometimes confuse even the most seasoned data scientists. This can eventually make it difficult},
  langid = {english},
  organization = {{Springboard Blog}},
  file = {/home/carlos/Zotero/storage/7CPDH77Z/regression-vs-classification.html}
}

@online{RevistaBitsCiencia,
  title = {Revista Bits de Ciencia N° 21 - 2021},
  url = {https://revistasdex.uchile.cl/files/full/BitsdeCiencia_(21)_2021/index.html},
  urldate = {2023-10-30},
  langid = {spanish},
  file = {/home/carlos/Zotero/storage/6QXLYRRD/index.html}
}

@article{ritmo_542,
  title = {El Sintetizador: El Instrumento de La Era Visual},
  author = {Pérez-Arroyo, Rafael},
  date = {1984},
  journaltitle = {Ritmo},
  volume = {542},
  pages = {12--16}
}

@book{roadsComputerMusicTutorial1996,
  title = {The {{Computer Music Tutorial}}},
  author = {Roads, Curtis and Strawn, John and Abbott, Curtis and Gordon, John and Philip, Greenspun},
  date = {1996},
  publisher = {{The MIT Press}},
  location = {{Cambride}}
}

@article{rosenblattPerceptronProbabilisticModel1958,
  title = {The Perceptron: {{A}} Probabilistic Model for Information Storage and Organization in the Brain.},
  shorttitle = {The Perceptron},
  author = {Rosenblatt, F.},
  date = {1958},
  journaltitle = {Psychological Review},
  shortjournal = {Psychological Review},
  volume = {65},
  number = {6},
  pages = {386--408},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/h0042519},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0042519},
  urldate = {2023-12-21},
  abstract = {The first of these questions is in the province of sensory physiology, and is the only one for which appreciable understanding has been achieved. This article will be concerned primarily with the second and third questions, which are still subject to a vast amount of speculation, and where the few relevant facts currently supplied by neurophysiology have not yet been integrated into an acceptable theory. With regard to the second question, two alternative positions have been maintained. The first suggests that storage of sensory information is in the form of coded representations or images, with some sort of one-to-one mapping between the sensory stimulus},
  langid = {english},
  file = {/home/carlos/Zotero/storage/9Z6ZPSWA/Rosenblatt - 1958 - The perceptron A probabilistic model for informat.pdf}
}

@incollection{rossingBriefHistoryAcoustics2007,
  title = {A {{Brief History}} of {{Acoustics}}},
  booktitle = {Springer {{Handbook}} of {{Acoustics}}},
  author = {Rossing, Thomas},
  editor = {Rossing, Thomas D.},
  date = {2007},
  series = {Springer {{Handbooks}}},
  pages = {9--24},
  publisher = {{Springer}},
  location = {{New York, NY}},
  doi = {10.1007/978-0-387-30425-0_2},
  url = {https://doi.org/10.1007/978-0-387-30425-0_2},
  urldate = {2023-05-23},
  abstract = {Although there are certainly some good historical treatments of acoustics in the literature, it still seems appropriate to begin a~handbook of acousticshistoryacoustics with a~brief history of the subject. We begin by mentioning some important experiments that took place before the 19th century. Acoustics in the 19th century is characterized by describing the work of seven outstanding acousticians: Tyndall, von Helmholtz, Rayleigh, Stokes, Bell, Edison, and Koenig. Of course this sampling omits the mention of many other outstanding investigators.},
  isbn = {978-0-387-30425-0},
  langid = {english},
  keywords = {Acoustical Society,Basilar Membrane,Physical Acoustics,Rayleigh Wave,Surface Acoustic Wave}
}

@incollection{rossingIntroductionAcoustics2007,
  title = {Introduction to {{Acoustics}}},
  booktitle = {Springer {{Handbook}} of {{Acoustics}}},
  author = {Rossing, Thomas},
  editor = {Rossing, Thomas D.},
  date = {2007},
  series = {Springer {{Handbooks}}},
  pages = {1--6},
  publisher = {{Springer}},
  location = {{New York, NY}},
  doi = {10.1007/978-0-387-30425-0_1},
  url = {https://doi.org/10.1007/978-0-387-30425-0_1},
  urldate = {2023-05-23},
  abstract = {This brief introduction may help to persuade the reader that acoustics covers a~wide range of interesting topics. It is impossible to cover all these topics in a~single handbook, but we have attempted to include a~sampling of hot topics that represent current acoustical research, both fundamental and applied.},
  isbn = {978-0-387-30425-0},
  langid = {english},
  keywords = {Outer Hair Cell,Physical Acoustics,Sound Source,Sound Wave,Vocal Tract}
}

@book{rothmanTransformersNaturalLanguage2021,
  title = {Transformers for {{Natural Language Processing}}: {{Build}} Innovative Deep Neural Network Architectures for {{NLP}} with {{Python}}, {{PyTorch}}, {{TensorFlow}}, {{BERT}}, {{RoBERTa}}, and More},
  shorttitle = {Transformers for {{Natural Language Processing}}},
  author = {Rothman, Denis},
  date = {2021},
  publisher = {{Packt Publishing}},
  location = {{Birmingham}},
  isbn = {978-1-80056-579-1},
  langid = {english},
  pagetotal = {384}
}

@article{roziereCodeLlamaOpen,
  title = {Code {{Llama}}: {{Open Foundation Models}} for {{Code}}},
  author = {Rozière, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Ellen, Xiaoqing and Adi, Yossi and Liu, Jingyu and Remez, Tal and Rapin, Jérémy and Kozhevnikov, Artyom and Evtimov, Ivan and Bitton, Joanna and Bhatt, Manish and Ferrer, Cristian Canton and Grattafiori, Aaron and Xiong, Wenhan and Défossez, Alexandre and Copet, Jade and Azhar, Faisal and Touvron, Hugo and Martin, Louis and Usunier, Nicolas and Scialom, Thomas and Synnaeve, Gabriel},
  langid = {english},
  file = {/home/carlos/Zotero/storage/VAXFL78X/Rozière et al. - Code Llama Open Foundation Models for Code.pdf}
}

@article{ruczSimulationOrganPipe2010,
  title = {Simulation of Organ Pipe Transfer Function by Means of Various Numerical Techniques},
  author = {Rucz, P. and Angster, J. and Augusztinovicz, F. and Fiala, P. and Miklós, A. and Ortiz, N.},
  date = {2010},
  url = {https://publica.fraunhofer.de/handle/publica/367692},
  urldate = {2023-05-23},
  abstract = {Designing and manufacturing processes of organ pipes are still based on traditional prototyping methods and applying step-by-step tuning and voicing adjustments. To speed up this rather time and resource consuming procedure, a modeling approach is being developed. To be able to simulate complex physical phenomena of the sound generation process, a number of pipe models have already been set up by several researchers and scientists. In general, these models treat the pipe resonator as a simple one-dimensional system, described by approximative analytical formulas. Contrary to this, the present paper examines numerical acoustical models for the pipe resonator. The performance and accuracy of three different simulation technique is tested, involving the usage of self-developed and commercial software packages. Real prototype pipes are modeled by the boundary element, coupled finite / boundary element and finite / infinite element methods. The results are compared to each other and measurement data. Possibilities of expanding the model by non-acoustical parts is also examined.},
  langid = {english},
  file = {/home/carlos/Zotero/storage/TTDBH8FV/details.html}
}

@article{ruczSoundDesignChimney2013,
  title = {Sound Design of Chimney Pipes by Optimization of Their Resonators},
  author = {Rucz, Péter and Trommer, Thomas and Angster, Judit and Miklós, András and Augusztinovicz, Fülöp},
  date = {2013-01-03},
  journaltitle = {The Journal of the Acoustical Society of America},
  shortjournal = {The Journal of the Acoustical Society of America},
  volume = {133},
  number = {1},
  pages = {529--537},
  issn = {0001-4966},
  doi = {10.1121/1.4770236},
  url = {https://doi.org/10.1121/1.4770236},
  urldate = {2023-05-23},
  abstract = {An optimization method, based on an acoustic waveguide model of chimney and resonator, was developed and tested by laboratory measurements of experimental chimney pipes. The dimensions of the chimney pipes are modified by the optimization algorithm until the specified fundamental frequency is achieved, and a predetermined harmonic partial overlaps with an eigenfrequency of the pipe. The experimental pipes were dimensioned by the optimization method for four different scenarios and were built by an organ builder. The measurements show excellent agreement between the measured sound spectra and calculated input admittances. The developed optimization method can be used for sound design of chimney pipes.},
  file = {/home/carlos/Zotero/storage/4VUQWKWD/Sound-design-of-chimney-pipes-by-optimization-of.html}
}

@online{RunTextGeneration2022,
  title = {Run Text Generation with {{Bloom}} and {{GPT}} Models on {{Amazon SageMaker JumpStart}} | {{AWS Machine Learning Blog}}},
  date = {2022-11-07T10:07:13-08:00},
  url = {https://aws.amazon.com/blogs/machine-learning/run-text-generation-with-gpt-and-bloom-models-on-amazon-sagemaker-jumpstart/},
  urldate = {2023-10-31},
  langid = {american},
  file = {/home/carlos/Zotero/storage/FTBUAU2Q/run-text-generation-with-gpt-and-bloom-models-on-amazon-sagemaker-jumpstart.html}
}

@book{RussellStuartJ2021AI:A,
  title = {Artificial Intelligence : {{A}} Modern Approach},
  author = {Russell, Stuart J},
  date = {2021},
  edition = {4th Edition.; Global edition.},
  publisher = {{Pearson}},
  location = {{Harlow}},
  isbn = {978-0-13-461099-3},
  langid = {english},
  keywords = {Inteligencia artificial,Inteligencia artificial Robótica,Transferencia del conocimiento}
}

@online{schaefferAreEmergentAbilities2023,
  title = {Are {{Emergent Abilities}} of {{Large Language Models}} a {{Mirage}}?},
  author = {Schaeffer, Rylan and Miranda, Brando and Koyejo, Sanmi},
  date = {2023-05-22},
  eprint = {2304.15004},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2304.15004},
  urldate = {2023-10-23},
  abstract = {Recent work claims that large language models display emergent abilities, abilities not present in smaller-scale models that are present in larger-scale models. What makes emergent abilities intriguing is two-fold: their sharpness, transitioning seemingly instantaneously from not present to present, and their unpredictability, appearing at seemingly unforeseeable model scales. Here, we present an alternative explanation for emergent abilities: that for a particular task and model family, when analyzing fixed model outputs, emergent abilities appear due the researcher’s choice of metric rather than due to fundamental changes in model behavior with scale. Specifically, nonlinear or discontinuous metrics produce apparent emergent abilities, whereas linear or continuous metrics produce smooth, continuous, predictable changes in model performance. We present our alternative explanation in a simple mathematical model, then test it in three complementary ways: we (1) make, test and confirm three predictions on the effect of metric choice using the InstructGPT/GPT-3 family on tasks with claimed emergent abilities, (2) make, test and confirm two predictions about metric choices in a metaanalysis of emergent abilities on BIG-Bench; and (3) show how to choose metrics to produce never-before-seen seemingly emergent abilities in multiple vision tasks across diverse deep networks. Via all three analyses, we provide evidence that alleged emergent abilities evaporate with different metrics or with better statistics, and may not be a fundamental property of scaling AI models.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/home/carlos/Zotero/storage/IKAF8WT5/Schaeffer et al. - 2023 - Are Emergent Abilities of Large Language Models a .pdf}
}

@book{searleMentesCerebrosCiencia1985,
  title = {Mentes, cerebros y ciencia},
  author = {Searle, John R.},
  date = {1985-12},
  eprint = {jfFUVl03PYUC},
  eprinttype = {googlebooks},
  publisher = {{Cátedra}},
  abstract = {Mientras que el sentido comun nos presenta como seres racionales, conscientes y libres, la ciencia nos informa que el universo en el que operamos, y que constituimos, es un agregado de particulas inconscienles. Que sabemos del cerebro, punto de union entre nuestra mente y el mundo fisico? Muy poco. En los ultimos tiempos se abre paso una atrevida analogia que relaciona el cerebro con un ordenador digital. Algunos cientificos postulan que las maquinas pueden --o podran -- pensar. Resolvera la inteligencia Artificial los problemas planteados por la relacion mente/cerebro?},
  isbn = {978-84-376-0569-2},
  langid = {spanish},
  pagetotal = {118}
}

@online{selAlgorithmThoughtsEnhancing2023,
  title = {Algorithm of {{Thoughts}}: {{Enhancing Exploration}} of {{Ideas}} in {{Large Language Models}}},
  shorttitle = {Algorithm of {{Thoughts}}},
  author = {Sel, Bilgehan and Al-Tawaha, Ahmad and Khattar, Vanshaj and Wang, Lu and Jia, Ruoxi and Jin, Ming},
  date = {2023-08-20},
  eprint = {2308.10379},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2308.10379},
  url = {http://arxiv.org/abs/2308.10379},
  urldate = {2023-09-27},
  abstract = {Current literature, aiming to surpass the "Chain-of-Thought" approach, often resorts to an external modus operandi involving halting, modifying, and then resuming the generation process to boost Large Language Models' (LLMs) reasoning capacities. This mode escalates the number of query requests, leading to increased costs, memory, and computational overheads. Addressing this, we propose the Algorithm of Thoughts -- a novel strategy that propels LLMs through algorithmic reasoning pathways, pioneering a new mode of in-context learning. By employing algorithmic examples, we exploit the innate recurrence dynamics of LLMs, expanding their idea exploration with merely one or a few queries. Our technique outperforms earlier single-query methods and stands on par with a recent multi-query strategy that employs an extensive tree search algorithm. Intriguingly, our results suggest that instructing an LLM using an algorithm can lead to performance surpassing that of the algorithm itself, hinting at LLM's inherent ability to weave its intuition into optimized searches. We probe into the underpinnings of our method's efficacy and its nuances in application.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/carlos/Zotero/storage/RUC6VMXG/Sel et al. - 2023 - Algorithm of Thoughts Enhancing Exploration of Id.pdf;/home/carlos/Zotero/storage/DMUQY952/2308.html}
}

@online{seydeBangBangControlAll2021,
  title = {Is {{Bang-Bang Control All You Need}}? {{Solving Continuous Control}} with {{Bernoulli Policies}}},
  shorttitle = {Is {{Bang-Bang Control All You Need}}?},
  author = {Seyde, Tim and Gilitschenski, Igor and Schwarting, Wilko and Stellato, Bartolomeo and Riedmiller, Martin and Wulfmeier, Markus and Rus, Daniela},
  date = {2021-11-03},
  eprint = {2111.02552},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2111.02552},
  url = {http://arxiv.org/abs/2111.02552},
  urldate = {2024-01-22},
  abstract = {Reinforcement learning (RL) for continuous control typically employs distributions whose support covers the entire action space. In this work, we investigate the colloquially known phenomenon that trained agents often prefer actions at the boundaries of that space. We draw theoretical connections to the emergence of bang-bang behavior in optimal control, and provide extensive empirical evaluation across a variety of recent RL algorithms. We replace the normal Gaussian by a Bernoulli distribution that solely considers the extremes along each action dimension - a bang-bang controller. Surprisingly, this achieves state-of-the-art performance on several continuous control benchmarks - in contrast to robotic hardware, where energy and maintenance cost affect controller choices. Since exploration, learning,and the final solution are entangled in RL, we provide additional imitation learning experiments to reduce the impact of exploration on our analysis. Finally, we show that our observations generalize to environments that aim to model real-world challenges and evaluate factors to mitigate the emergence of bang-bang solutions. Our findings emphasize challenges for benchmarking continuous control algorithms, particularly in light of potential real-world applications.},
  pubstate = {preprint},
  version = {1},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Robotics},
  file = {/home/carlos/Zotero/storage/CKZ7I9RM/Seyde et al. - 2021 - Is Bang-Bang Control All You Need Solving Continuous Control with Bernoulli Policies.pdf;/home/carlos/Zotero/storage/UQUDFT7H/2111.html}
}

@article{shannon1951prediction,
  title = {Prediction and Entropy of Printed English},
  author = {Shannon, Claude Elwood},
  date = {1951-01},
  journaltitle = {Bell System Technical Journal},
  volume = {30},
  pages = {50--64},
  url = {http://languagelog.ldc.upenn.edu/myl/Shannon1950.pdf},
  added-at = {2013-02-27T08:26:04.000+0100},
  interhash = {daabc21c7f6e71f6e78a10c8d3492927},
  intrahash = {2e79cf0f6022645a632b13e081b0b035},
  keywords = {communication english entropy information prediction shannon toread},
  timestamp = {2014-07-28T15:57:31.000+0200}
}

@article{shannonPredictionEntropyPrinted1951,
  title = {Prediction and {{Entropy}} of {{Printed English}}},
  author = {Shannon, C. E.},
  date = {1951-01},
  journaltitle = {Bell System Technical Journal},
  volume = {30},
  number = {1},
  pages = {50--64},
  issn = {00058580},
  doi = {10.1002/j.1538-7305.1951.tb01366.x},
  url = {https://ieeexplore.ieee.org/document/6773263},
  urldate = {2023-05-24},
  abstract = {A new method of estimating the entropy and redundancy of a language is described. This method exploits the knowledge of the language statistics possessed by those who speak the language, and depends on experimental results in prediction of the next letter when the preceding text is known. Results of experiments in prediction are given, and some properties of an ideal predictor are developed.},
  langid = {english}
}

@online{shevlaneModelEvaluationExtreme2023,
  title = {Model Evaluation for Extreme Risks},
  author = {Shevlane, Toby and Farquhar, Sebastian and Garfinkel, Ben and Phuong, Mary and Whittlestone, Jess and Leung, Jade and Kokotajlo, Daniel and Marchal, Nahema and Anderljung, Markus and Kolt, Noam and Ho, Lewis and Siddarth, Divya and Avin, Shahar and Hawkins, Will and Kim, Been and Gabriel, Iason and Bolina, Vijay and Clark, Jack and Bengio, Yoshua and Christiano, Paul and Dafoe, Allan},
  date = {2023-05-24},
  eprint = {2305.15324},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2305.15324},
  urldate = {2023-06-27},
  abstract = {Current approaches to building general-purpose AI systems tend to produce systems with both beneficial and harmful capabilities. Further progress in AI development could lead to capabilities that pose extreme risks, such as offensive cyber capabilities or strong manipulation skills. We explain why model evaluation is critical for addressing extreme risks. Developers must be able to identify dangerous capabilities (through "dangerous capability evaluations") and the propensity of models to apply their capabilities for harm (through "alignment evaluations"). These evaluations will become critical for keeping policymakers and other stakeholders informed, and for making responsible decisions about model training, deployment, and security.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,K.4.1},
  file = {/home/carlos/Zotero/storage/BDHEV472/Shevlane et al. - 2023 - Model evaluation for extreme risks.pdf}
}

@online{StableAudioFast,
  title = {Stable {{Audio}}: {{Fast Timing-Conditioned Latent Audio Diffusion}}},
  shorttitle = {Stable {{Audio}}},
  url = {https://stability.ai/research/stable-audio-efficient-timing-latent-diffusion},
  urldate = {2023-09-27},
  abstract = {Stable Audio represents the cutting-edge audio generation research by Stability AI’s generative audio research lab, Harmonai. We continue to improve our model architectures, datasets, and training procedures to improve output quality, controllability, inference speed, and output length.},
  langid = {british},
  organization = {{Stability AI}},
  file = {/home/carlos/Zotero/storage/HE8PHSK2/stable-audio-efficient-timing-latent-diffusion.html}
}

@article{stafuraSoundFreqencySpectrum2017,
  title = {Sound Freqency Spectrum of a Wood Organ Pipe after the Application of a Second Glue Layer on the Inner Walls},
  author = {Štafura, Andrej and Nagy, Š},
  date = {2017-01-01},
  journaltitle = {Akustika},
  shortjournal = {Akustika},
  volume = {28},
  pages = {90--96},
  abstract = {The key issue in the case of historic pipe organs is the preservation of the instrument sound authenticity. The submitted study deals with the research into the influence of a second glue layer on the sound frequency spectrum of a wood organ pipe. The aim of the present experiment is to simulate the application of certain restoration techniques, when a glue layer is applied on the inner wall of a wood organ pipe. The research has confirmed influence on the sound frequency spectrum and thus also the influence on the final sound performance of the pipe. In one of the studied cases, a significant decrease in the third harmonic component, having a significant impact on the final sound performance of the wood pipes, was recorded. In the case of other three specimens, such significant decrease was not recorded. This result leads to a discussion on the application of certain restoration techniques using glue layers on the pipe wall surfaces. Further study of this issue can help preserve the musical and aesthetical quality of historic instruments and thus the musical cultural heritage.},
  file = {/home/carlos/Zotero/storage/27T9FGQC/Štafura y Nagy - 2017 - Sound freqency spectrum of a wood organ pipe after.pdf}
}

@online{StrudelREPL,
  title = {Strudel {{REPL}}},
  url = {https://strudel.cc/},
  urldate = {2023-12-09},
  file = {/home/carlos/Zotero/storage/6HPXIMRG/strudel.cc.html}
}

@online{SunoAI,
  title = {Suno {{AI}}},
  url = {https://www.suno.ai/},
  urldate = {2023-12-26},
  abstract = {We are building a future where anyone can make great music. No instrument needed, just imagination. From your mind to music.},
  langid = {english},
  file = {/home/carlos/Zotero/storage/6922LJJL/www.suno.ai.html}
}

@misc{SuperCollider,
  type = {página web},
  title = {{{SuperCollider}}},
  url = {https://supercollider.github.io/}
}

@misc{supercollider,
  type = {página web},
  title = {{{SuperCollider}}},
  url = {https://supercollider.github.io/}
}

@book{Supper,
  title = {Música Electrónica y Música Con Ordenador. {{Historia}}, Estética, Métodos, Sistemas},
  author = {Supper, Martin},
  date = {2012},
  publisher = {{Alianza Música}},
  location = {{Madrid}}
}

@book{supperMusicaElectronicaMusica2012,
  title = {Música Electrónica y Música Con Ordenador. {{Historia}}, Estética, Métodos, Sistemas},
  author = {Supper, Martin},
  date = {2012},
  publisher = {{Alianza Música}},
  location = {{Madrid}}
}

@report{Synthi_Australia,
  title = {{{SYNTHI}} 100 {{MUSIC SYNTHESIZER}}},
  date = {2016},
  institution = {{Engineers Australia Engineering Heritage Victoria}},
  url = {https://portal.engineersaustralia.org.au 	/system/files/engineering-heritage-australia/nomination-title/Synthi%20100.Nomination.V7.27%20May%202016_0.pdf},
  lastchecked = {el 25 de abril de 2020}
}

@book{Synthi_users_manual,
  title = {Synthi Users Manual {{EMS}}},
  date = {1970},
  publisher = {{Electronic Music Studios}},
  location = {{Londres}},
  url = {https://whitefiles.org/rwz/zxe/1970_ems_synthi_users_manual.pdf},
  lastchecked = {el 25 de abril de 2020}
}

@book{Synthi100_brochure,
  type = {folleto},
  title = {The Synthi 100},
  date = {1971}
}

@book{Synthi1001971,
  type = {folleto},
  title = {The {{Synthi}} 100},
  date = {1971}
}

@report{SYNTHI100MUSIC2016,
  title = {{{SYNTHI}} 100 {{MUSIC SYNTHESIZER}}},
  date = {2016},
  institution = {{Engineers Australia Engineering Heritage Victoria}},
  url = {https://portal.engineersaustralia.org.au 	/system/files/engineering-heritage-australia/nomination-title/Synthi%20100.Nomination.V7.27%20May%202016_0.pdf}
}

@book{SynthiAKS_brochure,
  type = {folleto},
  title = {The Synthi Educational Handbook},
  author = {Grogono, Peter},
  date = {1972},
  publisher = {{Electronic Music Studios of American Inc}}
}

@book{SynthiUsersManual,
  type = {folleto},
  title = {Synthi {{Users Manual}}},
  publisher = {{Electronic Music Studios of American Inc}},
  url = {https://whitefiles.org/rwz/zxe/1970\_ems\_synthi\_users\_manual.pdf}
}

@book{SynthiUsersManual1970,
  title = {Synthi {{Users Manual EMS}}},
  date = {1970},
  publisher = {{Electronic Music Studios}},
  location = {{Londres}},
  url = {https://whitefiles.org/rwz/zxe/1970\_ems\_synthi\_users\_manual.pdf}
}

@book{SynthiVCS3_brochure,
  type = {folleto},
  title = {Synthi Users Manual},
  publisher = {{Electronic Music Studios of American Inc}},
  url = {https://whitefiles.org/rwz/zxe/1970_ems_synthi_users_manual.pdf}
}

@article{tateishiRoleFootChamber2019,
  title = {Role of the Foot Chamber in the Sounding Mechanism of a Flue Organ Pipe},
  author = {Tateishi, Shuhei and Iwagami, Sho and Tsutsumi, Genki and Kobayashi, Taizo and Takami, Toshiya and Takahashi, Kin'ya},
  date = {2019},
  journaltitle = {Acoustical Science and Technology},
  volume = {40},
  number = {1},
  pages = {29--39},
  doi = {10.1250/ast.40.29},
  abstract = {Two-demensional (2D) models of a flue organ pipe are studied with compressible fluid simulation, specifically compressible Large Eddy Simulation, focusing on the influence of the geometry of the flue and the foot on the jet motion and acoustic oscillation in the pipe. When the foot geometry is fixed, the models having a flue with chamfers show good performances in stabilizing the acoustic oscillation in the steady state. Furthermore, we find that the foot chamber works as a Helmholtz resonator. If the frequency of the acoustic oscillation in the pipe is higher than the resonance frequency of the Helmholtz resonator by almost the full-width at half-maximum, anti-phase synchronization between the acoustic oscillation in the pipe and that in the foot chamber occurs. In this case, the acoustic oscillation in the pipe grows rapidly in the attack transient and is stabilized in the steady state.},
  keywords = {Helmholtz resonator,Organ foot,Organ pipe},
  file = {/home/carlos/Zotero/storage/VGAQUQ9A/Tateishi et al. - 2019 - Role of the foot chamber in the sounding mechanism.pdf;/home/carlos/Zotero/storage/9WYS6MFK/_article.html}
}

@online{teamChucKStronglyTimedMusic,
  title = {{{ChucK}}: {{A Strongly-Timed Music Programming Language}}},
  shorttitle = {{{ChucK}}},
  author = {Team, ChucK},
  url = {https://ccrma.stanford.edu/software/chuck/},
  urldate = {2023-12-09},
  abstract = {ChucK is a strongly-timed programming language for interactive sound synthesis and music creation.},
  langid = {english},
  file = {/home/carlos/Zotero/storage/Q7Y4LBTF/chuck.stanford.edu.html}
}

@online{TestTuringHola,
  title = {4.1.1 {{El Test}} de {{Turing}} | {{Hola}}, ¿necesitas Ayuda?},
  url = {https://edea.juntadeandalucia.es/bancorecursos/file/d1bb5f09-682f-4e93-a799-e90b1c3364ed/2/COM_3ESO_REA_01_V02.zip/411_el_test_de_turing.html},
  urldate = {2024-01-27},
  file = {/home/carlos/Zotero/storage/D9EYC4EE/411_el_test_de_turing.html}
}

@online{TextGenerationStrategies,
  title = {Text Generation Strategies},
  url = {https://huggingface.co/docs/transformers/main/en/generation_strategies},
  urldate = {2023-10-31},
  abstract = {We’re on a journey to advance and democratize artificial intelligence through open source and open science.},
  file = {/home/carlos/Zotero/storage/4ENA6UIN/generation_strategies.html}
}

@book{the_synthesizer,
  title = {The {{Synthesizer}}. {{A}} Comprehensive Guide to Understanding, Programming, Playing, and Recording the Ultimate Electronic Music Instrument},
  author = {Vail, Mark},
  date = {2014},
  publisher = {{Oxford University Press}},
  location = {{New York}}
}

@online{tianFinetuningLanguageModels2023,
  title = {Fine-Tuning {{Language Models}} for {{Factuality}}},
  author = {Tian, Katherine and Mitchell, Eric and Yao, Huaxiu and Manning, Christopher D. and Finn, Chelsea},
  date = {2023-11-14},
  eprint = {2311.08401},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2311.08401},
  url = {http://arxiv.org/abs/2311.08401},
  urldate = {2024-01-25},
  abstract = {The fluency and creativity of large pre-trained language models (LLMs) have led to their widespread use, sometimes even as a replacement for traditional search engines. Yet language models are prone to making convincing but factually inaccurate claims, often referred to as 'hallucinations.' These errors can inadvertently spread misinformation or harmfully perpetuate misconceptions. Further, manual fact-checking of model responses is a time-consuming process, making human factuality labels expensive to acquire. In this work, we fine-tune language models to be more factual, without human labeling and targeting more open-ended generation settings than past work. We leverage two key recent innovations in NLP to do so. First, several recent works have proposed methods for judging the factuality of open-ended text by measuring consistency with an external knowledge base or simply a large model's confidence scores. Second, the direct preference optimization algorithm enables straightforward fine-tuning of language models on objectives other than supervised imitation, using a preference ranking over possible model responses. We show that learning from automatically generated factuality preference rankings, generated either through existing retrieval systems or our novel retrieval-free approach, significantly improves the factuality (percent of generated claims that are correct) of Llama-2 on held-out topics compared with RLHF or decoding strategies targeted at factuality. At 7B scale, compared to Llama-2-chat, we observe 58\% and 40\% reduction in factual error rate when generating biographies and answering medical questions, respectively.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/carlos/Zotero/storage/G7PVTXL8/Tian et al. - 2023 - Fine-tuning Language Models for Factuality.pdf;/home/carlos/Zotero/storage/CJWHU2CJ/2311.html}
}

@book{torresivinalsPythonDeepLearning2020,
  title = {Python {{Deep Learning}}. {{Introducción}} Práctica Con {{Keras}} y {{TensorFlow}} 2},
  author = {Torres i Viñals, Jordi},
  date = {2020},
  edition = {1ª},
  publisher = {{Marcombo}},
  isbn = {978-84-267-2921-7}
}

@misc{TouchOSC,
  type = {página web},
  title = {{{TouchOSC}}},
  url = {https://hexler.net/products/touchosc}
}

@misc{touchosc_web,
  type = {página web},
  title = {{{TouchOSC}}},
  url = {https://hexler.net/products/touchosc}
}

@book{TuningTimbreSpectrum2005,
  title = {Tuning, {{Timbre}}, {{Spectrum}}, {{Scale}}},
  date = {2005},
  publisher = {{Springer-Verlag}},
  location = {{London}},
  doi = {10.1007/b138848},
  url = {http://link.springer.com/10.1007/b138848},
  urldate = {2023-05-23},
  isbn = {978-1-85233-797-1},
  langid = {english},
  keywords = {electronic music,instruments,Interpretation,music theory,musical scales,psychoacoustics,signal processing design,structure},
  file = {/home/carlos/Zotero/storage/YT34FDHU/2005 - Tuning, Timbre, Spectrum, Scale.pdf}
}

@online{UnderstandingLearningDemonstrations,
  title = {An {{Understanding}} of {{Learning}} from {{Demonstrations}} for {{Neural Text Generation}} · {{The ICLR Blog Track}}},
  url = {https://iclr-blog-track.github.io/2022/03/25/text-gen-via-lfd/},
  urldate = {2024-01-26},
  file = {/home/carlos/Zotero/storage/ZP65IJW5/text-gen-via-lfd.html}
}

@online{UNEENISO33821,
  title = {{{UNE-EN ISO}} 3382-1:2010 {{Acústica}}. {{Medición}} de Parámetros Acústi...},
  url = {https://www.une.org/encuentra-tu-norma/busca-tu-norma/norma/?Tipo=N&c=N0044829},
  urldate = {2023-05-23},
  file = {/home/carlos/Zotero/storage/XBNIB2Y6/norma.html}
}

@book{vailSynthesizerComprehensiveGuide2014,
  title = {The {{Synthesizer}}. {{A}} Comprehensive Guide to Understanding, Programming, Playing, and Recording the Ultimate Electronic Music Instrument},
  author = {Vail, Mark},
  date = {2014},
  publisher = {{Oxford University Press}},
  location = {{New York}}
}

@article{vandeperreMeasurementSoundFlow2023,
  title = {Measurement of Sound and Flow Fields in an Organ Pipe Using a Scanning Laser {{Doppler}} Vibrometer},
  author = {Van de Perre, Greet and Nila, Alex and Vanlanduit, S.},
  date = {2023-05-23},
  abstract = {Sound production in organ pipes is a complex matter involving interactions between flow fields and sound waves. Until now, this mechanism has not entirely been understood. In this paper, the complex interaction between the flow and the sound field in the instrument is investigated by using a scanning laser vibrometer. The measurement results are compared with measurements of two more traditional optical techniques (PIV and Schlieren photography) and with microphone sound measurements.}
}

@online{vaswaniAttentionAllYou2017,
  title = {Attention {{Is All You Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  date = {2017-12-05},
  eprint = {1706.03762},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1706.03762},
  url = {http://arxiv.org/abs/1706.03762},
  urldate = {2023-05-23},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/carlos/Zotero/storage/ZUQMSYXF/Vaswani et al. - 2017 - Attention Is All You Need.pdf;/home/carlos/Zotero/storage/E7YRG247/1706.html}
}

@article{vergeJetFormationJet1994,
  title = {Jet Formation and Jet Velocity Fluctuations in a Flue Organ Pipe},
  author = {Verge, M. P. and Fabre, B. and Mahu, W. E. A. and Hirschberg, A. and family=Hassel, given=R. R., prefix=van, useprefix=true and Wijnands, A. P. J. and family=Vries, given=J. J., prefix=de, useprefix=true and Hogendoorn, C. J.},
  date = {1994-02-01},
  journaltitle = {The Journal of the Acoustical Society of America},
  shortjournal = {The Journal of the Acoustical Society of America},
  volume = {95},
  number = {2},
  pages = {1119--1132},
  issn = {0001-4966},
  doi = {10.1121/1.408460},
  url = {https://doi.org/10.1121/1.408460},
  urldate = {2023-05-23},
  abstract = {Flow visualization of the initial transient in a small recorderlike flue organ pipe is presented and the various stages of the jet formation are related to measurements of the acoustic response of the pipe. An initial acoustic signal, due to the unsteady volume flow of the jet, appears before the forming jet reaches the labium. This signal can easily be modeled using a low‐frequency approximation. The initial trajectory of the jet makes a curve towards the exterior of the pipe. Under certain conditions, the jet may even, at first, miss the labium. This effect is related to the steepness of the pressure rise in the foot of the pipe. The initial impact of the jet with the labium appears to be a crucial factor in the triggering of the transient. Moving the labium towards the exterior of the pipe, using a steep pressure rise or putting ears around the mouth increase the chance that the jet will hit the labium. This initial impact is followed by an impulsive vortex shedding at the labium and subsequently a high‐frequency varicoselike oscillation is observed on the jet. This oscillation is also observed without labium. After about three periods of the fundamental mode of the pipe, turbulence appears therefore destroying these coherent structures. Whereas the time dependency of the jet velocity dominates the first stage of the starting transient, the jet velocity fluctuations during steady‐state result in a non‐negligible damping. This loss mechanism is, for the fundamental mode of our experimental organ pipe, of the same order of magnitude as the radiation or visco‐thermal damping.},
  file = {/home/carlos/Zotero/storage/7FVKL4YV/Verge et al. - 1994 - Jet formation and jet velocity fluctuations in a f.pdf;/home/carlos/Zotero/storage/E6ATHNJF/Jet-formation-and-jet-velocity-fluctuations-in-a.html}
}

@misc{vst_mejores,
  type = {página web},
  title = {The 200 Best Free {{VST}} Plugins Ever},
  url = {https://blog.landr.com/best-free-vst-plugins/}
}

@article{wang2021promising,
  title = {A Promising and Challenging Approach: {{Radiologists}}’ Perspective on Deep Learning and Artificial Intelligence for Fighting {{COVID-19}}},
  author = {Wang, Tianming and Chen, Zhu and Shang, Quanliang and Ma, Cong and Chen, Xiangyu and Xiao, Enhua},
  date = {2021},
  journaltitle = {Diagnostics},
  volume = {11},
  number = {10},
  pages = {1924},
  publisher = {{Multidisciplinary Digital Publishing Institute}}
}

@online{wangAllYouNeed2019,
  title = {All {{You Need Is Boundary}}: {{Toward Arbitrary-Shaped Text Spotting}}},
  shorttitle = {All {{You Need Is Boundary}}},
  author = {Wang, Hao and Lu, Pu and Zhang, Hui and Yang, Mingkun and Bai, Xiang and Xu, Yongchao and He, Mengchao and Wang, Yongpan and Liu, Wenyu},
  date = {2019-11-21},
  eprint = {1911.09550},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1911.09550},
  url = {http://arxiv.org/abs/1911.09550},
  urldate = {2024-01-22},
  abstract = {Recently, end-to-end text spotting that aims to detect and recognize text from cluttered images simultaneously has received particularly growing interest in computer vision. Different from the existing approaches that formulate text detection as bounding box extraction or instance segmentation, we localize a set of points on the boundary of each text instance. With the representation of such boundary points, we establish a simple yet effective scheme for end-to-end text spotting, which can read the text of arbitrary shapes. Experiments on three challenging datasets, including ICDAR2015, TotalText and COCO-Text demonstrate that the proposed method consistently surpasses the state-of-the-art in both scene text detection and end-to-end text recognition tasks.},
  pubstate = {preprint},
  version = {1},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/carlos/Zotero/storage/7KT9R5CE/Wang et al. - 2019 - All You Need Is Boundary Toward Arbitrary-Shaped Text Spotting.pdf;/home/carlos/Zotero/storage/5SXPIZ7P/1911.html}
}

@online{wangCostEffectiveHyperparameterOptimization2023,
  title = {Cost-{{Effective Hyperparameter Optimization}} for {{Large Language Model Generation Inference}}},
  author = {Wang, Chi and Liu, Susan Xueqing and Awadallah, Ahmed H.},
  date = {2023-08-08},
  eprint = {2303.04673},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2303.04673},
  urldate = {2023-11-07},
  abstract = {Large Language Models (LLMs) have sparked significant interest in their generative capabilities, leading to the development of various commercial applications. The high cost of using the models drives application builders to maximize the value of generation under a limited inference budget. This paper presents a study of optimizing inference hyperparameters such as the number of responses, temperature and max tokens, which significantly affects the utility/cost of text generation. We design a framework named EcoOptiGen which leverages economical hyperparameter optimization and cost-based pruning. Experiments with the GPT-3.5/GPT-4 models on a variety of tasks verify its effectiveness. EcoOptiGen is implemented in the ‘autogen’ package of the FLAML library: https: //aka.ms/autogen.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/carlos/Zotero/storage/25YJQ69L/Wang et al. - 2023 - Cost-Effective Hyperparameter Optimization for Lar.pdf}
}

@online{wangHowFarCan2023,
  title = {How {{Far Can Camels Go}}? {{Exploring}} the {{State}} of {{Instruction Tuning}} on {{Open Resources}}},
  shorttitle = {How {{Far Can Camels Go}}?},
  author = {Wang, Yizhong and Ivison, Hamish and Dasigi, Pradeep and Hessel, Jack and Khot, Tushar and Chandu, Khyathi Raghavi and Wadden, David and MacMillan, Kelsey and Smith, Noah A. and Beltagy, Iz and Hajishirzi, Hannaneh},
  date = {2023-06-07},
  eprint = {2306.04751},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2306.04751},
  url = {http://arxiv.org/abs/2306.04751},
  urldate = {2023-06-25},
  abstract = {In this work we explore recent advances in instruction-tuning language models on a range of open instruction-following datasets. Despite recent claims that open models can be on par with state-of-the-art proprietary models, these claims are often accompanied by limited evaluation, making it difficult to compare models across the board and determine the utility of various resources. We provide a large set of instruction-tuned models from 6.7B to 65B parameters in size, trained on 12 instruction datasets ranging from manually curated (e.g., OpenAssistant) to synthetic and distilled (e.g., Alpaca) and systematically evaluate them on their factual knowledge, reasoning, multilinguality, coding, and open-ended instruction following abilities through a collection of automatic, model-based, and human-based metrics. We further introduce T\textbackslash "ulu, our best performing instruction-tuned model suite finetuned on a combination of high-quality open resources. Our experiments show that different instruction-tuning datasets can uncover or enhance specific skills, while no single dataset (or combination) provides the best performance across all evaluations. Interestingly, we find that model and human preference-based evaluations fail to reflect differences in model capabilities exposed by benchmark-based evaluations, suggesting the need for the type of systemic evaluation performed in this work. Our evaluations show that the best model in any given evaluation reaches on average 83\% of ChatGPT performance, and 68\% of GPT-4 performance, suggesting that further investment in building better base models and instruction-tuning data is required to close the gap. We release our instruction-tuned models, including a fully finetuned 65B T\textbackslash "ulu, along with our code, data, and evaluation framework at https://github.com/allenai/open-instruct to facilitate future research.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/home/carlos/Zotero/storage/N7BKL9IN/Wang et al. - 2023 - How Far Can Camels Go Exploring the State of Inst.pdf;/home/carlos/Zotero/storage/VTFI54HT/2306.html}
}

@article{wangHyperparameterOptimizationAlgorithm2022,
  title = {A {{Hyperparameter Optimization Algorithm}} for the {{LSTM Temperature Prediction Model}} in {{Data Center}}},
  author = {Wang, Simin and Ma, Chunmiao and Xu, Yixuan and Wang, Jinyu and Wu, Weiguo},
  date = {2022-12-12},
  journaltitle = {Scientific Programming},
  volume = {2022},
  pages = {e6519909},
  publisher = {{Hindawi}},
  issn = {1058-9244},
  doi = {10.1155/2022/6519909},
  url = {https://www.hindawi.com/journals/sp/2022/6519909/},
  urldate = {2023-11-07},
  abstract = {As the main tool to realize data mining and efficient knowledge acquisition in the era of big data, machine learning is widely used in data center energy-saving research. The temperature prediction model based on machine learning predicts the state of the data center according to the upcoming tasks. It can adjust the refrigeration equipment in advance to avoid temperature regulation lag and set the air conditioning temperature according to the actual demand to avoid excessive refrigeration. Task scheduling and migration algorithm based on temperature prediction can effectively avoid hot spots. However, the choice of hyperparameter of machine learning model has a great impact on its performance. In this study, a hyperparameter optimization algorithm based on MLP is proposed. On the basis of trying certain hyperparameters, the MLP model is used to predict the value of all hyperparameters’ space, and then, a certain number of high-quality hyperparameters are selected to train the model repeatedly. In each iteration, the amount of training data decreases gradually, while the accuracy of the model improves rapidly, and finally, the appropriate hyperparameter are obtained. We use the idea of mutation in the genetic algorithm to improve the probability of high-quality solutions and the loss function weighting method to select the solution with the best stability. Experiments are carried out on two representative machine learning models, LSTM and Random Forest, and compared with the standard Gaussian Bayes and Random Search method. The results show that the method proposed in this study can obtain high-precision and high-stability hyperparameter through one run and can greatly improve the operation efficiency. This algorithm is not only effective for LSTM but also suitable for other machine learning models.},
  langid = {english},
  file = {/home/carlos/Zotero/storage/CSFU4NGN/Wang et al. - 2022 - A Hyperparameter Optimization Algorithm for the LS.pdf}
}

@online{wangSelfConsistencyImprovesChain2023,
  title = {Self-{{Consistency Improves Chain}} of {{Thought Reasoning}} in {{Language Models}}},
  author = {Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  date = {2023-03-07},
  eprint = {2203.11171},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2203.11171},
  url = {http://arxiv.org/abs/2203.11171},
  urldate = {2024-01-20},
  abstract = {Chain-of-thought prompting combined with pre-trained large language models has achieved encouraging results on complex reasoning tasks. In this paper, we propose a new decoding strategy, self-consistency, to replace the naive greedy decoding used in chain-of-thought prompting. It first samples a diverse set of reasoning paths instead of only taking the greedy one, and then selects the most consistent answer by marginalizing out the sampled reasoning paths. Self-consistency leverages the intuition that a complex reasoning problem typically admits multiple different ways of thinking leading to its unique correct answer. Our extensive empirical evaluation shows that self-consistency boosts the performance of chain-of-thought prompting with a striking margin on a range of popular arithmetic and commonsense reasoning benchmarks, including GSM8K (+17.9\%), SVAMP (+11.0\%), AQuA (+12.2\%), StrategyQA (+6.4\%) and ARC-challenge (+3.9\%).},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/carlos/Zotero/storage/937N86FR/Wang et al. - 2023 - Self-Consistency Improves Chain of Thought Reasoning in Language Models.pdf;/home/carlos/Zotero/storage/DV8TJ9QK/2203.html}
}

@article{wegrzynProblemPlacingOrgan2019,
  title = {Problem of Placing the Organ Pipes on the Windchest},
  author = {Węgrzyn, Damian and Wrzeciono, Piotr},
  date = {2019-01-01},
  journaltitle = {Vibrations in Physical Systems},
  shortjournal = {Vibrations in Physical Systems},
  volume = {30},
  pages = {2019121},
  abstract = {This paper presents research showing the problem occurring in the construction of a pipe organ, related to the placement of the organ pipes on the windchest. The close location of the organ pipes to each other influences the parameters of the sound generated by the pipes. It causes an intonation problem, namely the detuning of the organ pipes if they are located too close to each other on the windchest. The presented measurements show the influence of a distance between pipes of various types on basic sound parameters, such as frequency or volume level. The research carried out shows that in extreme cases the detuning reaches a temperate halftone. This has undoubtedly an impact on the tuning of organ pipes, especially in the case of a table organ or pipe organ built in a small space. In the future, the outcomes of the presented research can be applied in the windchest design.},
  file = {/home/carlos/Zotero/storage/L9R7Y3PX/Węgrzyn y Wrzeciono - 2019 - Problem of placing the organ pipes on the windches.pdf}
}

@online{weiChainofThoughtPromptingElicits2023,
  title = {Chain-of-{{Thought Prompting Elicits Reasoning}} in {{Large Language Models}}},
  author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
  date = {2023-01-10},
  eprint = {2201.11903},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2201.11903},
  urldate = {2023-10-23},
  abstract = {We explore how generating a chain of thought—a series of intermediate reasoning steps—significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain-ofthought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain-of-thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a PaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/carlos/Zotero/storage/AZPLR9LR/Wei et al. - 2023 - Chain-of-Thought Prompting Elicits Reasoning in La.pdf}
}

@online{weiEmergentAbilitiesLarge2022,
  title = {Emergent {{Abilities}} of {{Large Language Models}}},
  author = {Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and Chi, Ed H. and Hashimoto, Tatsunori and Vinyals, Oriol and Liang, Percy and Dean, Jeff and Fedus, William},
  date = {2022-10-26},
  eprint = {2206.07682},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2206.07682},
  url = {http://arxiv.org/abs/2206.07682},
  urldate = {2023-06-27},
  abstract = {Scaling up language models has been shown to predictably improve performance and sample efficiency on a wide range of downstream tasks. This paper instead discusses an unpredictable phenomenon that we refer to as emergent abilities of large language models. We consider an ability to be emergent if it is not present in smaller models but is present in larger models. Thus, emergent abilities cannot be predicted simply by extrapolating the performance of smaller models. The existence of such emergence implies that additional scaling could further expand the range of capabilities of language models.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language},
  file = {/home/carlos/Zotero/storage/C3F58HUQ/Wei et al. - 2022 - Emergent Abilities of Large Language Models.pdf;/home/carlos/Zotero/storage/SK77QAMT/2206.html}
}

@online{WhatRetrievalAugmented,
  title = {What is Retrieval Augmented Generation?},
  url = {https://www.linkedin.com/pulse/what-retrieval-augmented-generation-grow-right},
  urldate = {2024-01-05},
  abstract = {Retrieval Augmented Generation (RAG) is an approach that combines the power of large-scale neural language models with external retrieval or search mechanisms. Here's a breakdown of RAG in a semi-formal, business tone: Core Concept: At the heart of RAG is the idea of leveraging external knowledge so},
  langid = {spanish},
  file = {/home/carlos/Zotero/storage/A9NJFVUJ/what-retrieval-augmented-generation-grow-right.html}
}

@online{WhatRetrievalaugmentedGeneration2021,
  title = {What Is Retrieval-Augmented Generation?},
  date = {2021-02-09},
  url = {https://research.ibm.com/blog/retrieval-augmented-generation-RAG},
  urldate = {2023-11-07},
  abstract = {RAG is an AI framework for retrieving facts to ground LLMs on the most accurate information and to give users insight into AI’s decisionmaking process.},
  langid = {american},
  organization = {{IBM Research Blog}},
  file = {/home/carlos/Zotero/storage/S4AMA7JD/retrieval-augmented-generation-RAG.html}
}

@book{WhyYouHear2012,
  title = {Why {{You Hear What You Hear}}},
  year = {Sun, 12/09/2012 - 12:00},
  url = {https://press.princeton.edu/books/hardcover/9780691148595/why-you-hear-what-you-hear},
  urldate = {2023-05-23},
  abstract = {A groundbreaking textbook that explores the phenomena and physics of music and sound},
  isbn = {978-0-691-14859-5},
  langid = {english},
  file = {/home/carlos/Zotero/storage/8IEIVBMV/why-you-hear-what-you-hear.html}
}

@book{wilsonSuperColliderBook2011a,
  title = {The {{SuperCollider Book}}},
  author = {Wilson, Scott and Cottle, David and Collins, Nick},
  date = {2011-03},
  publisher = {{The MIT Press}},
  abstract = {SuperCollider is one of the most important domain-specific audio programming languages, with potential applications that include real-time interaction, installations, electroacoustic pieces, generative music, and audiovisuals. The SuperCollider Book is the essential reference to this powerful and flexible language, offering students and professionals a collection of tutorials, essays, and projects. With contributions from top academics, artists, and technologists that cover topics at levels from the introductory to the specialized, it will be a valuable sourcebook both for beginners and for advanced users. SuperCollider, first developed by James McCartney, is an accessible blend of Smalltalk, C, and further ideas from a number of programming languages. Free, open-source, cross-platform, and with a diverse and supportive developer community, it is often the first programming language sound artists and computer musicians learn. The SuperCollider Book is the long-awaited guide to the design, syntax, and use of the SuperCollider language. The first chapters offer an introduction to the basics, including a friendly tutorial for absolute beginners, providing the reader with skills that can serve as a foundation for further learning. Later chapters cover more advanced topics and particular topics in computer music, including programming, sonification, spatialization, microsound, GUIs, machine listening, alternative tunings, and non-real-time synthesis; practical applications and philosophical insigh"s from the composer's and artist's perspectives; and "under the hood," developer's-eye views of SuperCollider's inner workings. A Web site accompanying the book offers code, links to the application itself and its source code, and a variety of third-party extras, extensions, libraries, and examples.},
  isbn = {978-0-262-23269-2},
  pagetotal = {680}
}

@online{xieAllYouNeed2017,
  title = {All {{You Need}} Is {{Beyond}} a {{Good Init}}: {{Exploring Better Solution}} for {{Training Extremely Deep Convolutional Neural Networks}} with {{Orthonormality}} and {{Modulation}}},
  shorttitle = {All {{You Need}} Is {{Beyond}} a {{Good Init}}},
  author = {Xie, Di and Xiong, Jiang and Pu, Shiliang},
  date = {2017-04-09},
  eprint = {1703.01827},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1703.01827},
  url = {http://arxiv.org/abs/1703.01827},
  urldate = {2024-01-22},
  abstract = {Deep neural network is difficult to train and this predicament becomes worse as the depth increases. The essence of this problem exists in the magnitude of backpropagated errors that will result in gradient vanishing or exploding phenomenon. We show that a variant of regularizer which utilizes orthonormality among different filter banks can alleviate this problem. Moreover, we design a backward error modulation mechanism based on the quasi-isometry assumption between two consecutive parametric layers. Equipped with these two ingredients, we propose several novel optimization solutions that can be utilized for training a specific-structured (repetitively triple modules of Conv-BNReLU) extremely deep convolutional neural network (CNN) WITHOUT any shortcuts/ identity mappings from scratch. Experiments show that our proposed solutions can achieve distinct improvements for a 44-layer and a 110-layer plain networks on both the CIFAR-10 and ImageNet datasets. Moreover, we can successfully train plain CNNs to match the performance of the residual counterparts. Besides, we propose new principles for designing network structure from the insights evoked by orthonormality. Combined with residual structure, we achieve comparative performance on the ImageNet dataset.},
  pubstate = {preprint},
  version = {3},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {/home/carlos/Zotero/storage/AXI3SGH8/Xie et al. - 2017 - All You Need is Beyond a Good Init Exploring Better Solution for Training Extremely Deep Convolutio.pdf;/home/carlos/Zotero/storage/CZIYPAEK/1703.html}
}

@online{yangLargeLanguageModels2023,
  title = {Large {{Language Models}} as {{Optimizers}}},
  author = {Yang, Chengrun and Wang, Xuezhi and Lu, Yifeng and Liu, Hanxiao and Le, Quoc V. and Zhou, Denny and Chen, Xinyun},
  date = {2023-09-06},
  eprint = {2309.03409},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2309.03409},
  url = {http://arxiv.org/abs/2309.03409},
  urldate = {2023-10-30},
  abstract = {Optimization is ubiquitous. While derivative-based algorithms have been powerful tools for various problems, the absence of gradient imposes challenges on many real-world applications. In this work, we propose Optimization by PROmpting (OPRO), a simple and effective approach to leverage large language models (LLMs) as optimizers, where the optimization task is described in natural language. In each optimization step, the LLM generates new solutions from the prompt that contains previously generated solutions with their values, then the new solutions are evaluated and added to the prompt for the next optimization step. We first showcase OPRO on linear regression and traveling salesman problems, then move on to prompt optimization where the goal is to find instructions that maximize the task accuracy. With a variety of LLMs, we demonstrate that the best prompts optimized by OPRO outperform human-designed prompts by up to 8\% on GSM8K, and by up to 50\% on Big-Bench Hard tasks.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/carlos/Zotero/storage/SLLUN5RF/Yang et al. - 2023 - Large Language Models as Optimizers.pdf;/home/carlos/Zotero/storage/HAGLRUNJ/2309.html}
}

@article{yoshikawaFeedbackExcitationMechanism1980,
  title = {Feedback Excitation Mechanism in Organ Pipes},
  author = {Yoshikawa, Shigeru and Saneyoshi, Jun'ichi},
  date = {1980-01-01},
  journaltitle = {Journal of the Acoustical Society of Japan (E)},
  shortjournal = {Journal of the Acoustical Society of Japan (E)},
  volume = {1},
  pages = {175--191},
  doi = {10.1250/ast.1.175},
  abstract = {A feedback theory on the organ pipe sounding mechanism was established for small amplitude oscillations. Lateral displacement of the jet at the edge is amplified to produce the driving current, part of which is fed back to the jet. The self-sustained oscillation is realized if amplification and feedback functions combine to unity in the feedback loop. Numerical calculation clarified that (1) phase shift due to the lip-to-edge transit time of the jet has physical significance, and its range for sound production extends roughly between π/2 and 3π/2, (2) feedback oscillation must be maintained by the decrease of phase shift with ascending frequency, (3) “octave jump” occurs and the phase shift is doubled for such high speeds as exceed the allowable limit, and (4) oscillations take place at the antiresonance of the current-driven parallel system. Experimental results on four models made by authors encourage our feedback excitation theory.},
  file = {/home/carlos/Zotero/storage/4I87HJQY/Yoshikawa y Saneyoshi - 1980 - Feedback excitation mechanism in organ pipes.pdf}
}

@online{zengMusicBERTSymbolicMusic2021,
  title = {{{MusicBERT}}: {{Symbolic Music Understanding}} with {{Large-Scale Pre-Training}}},
  shorttitle = {{{MusicBERT}}},
  author = {Zeng, Mingliang and Tan, Xu and Wang, Rui and Ju, Zeqian and Qin, Tao and Liu, Tie-Yan},
  date = {2021-06-10},
  eprint = {2106.05630},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  doi = {10.48550/arXiv.2106.05630},
  url = {http://arxiv.org/abs/2106.05630},
  urldate = {2023-05-27},
  abstract = {Symbolic music understanding, which refers to the understanding of music from the symbolic data (e.g., MIDI format, but not audio), covers many music applications such as genre classification, emotion classification, and music pieces matching. While good music representations are beneficial for these applications, the lack of training data hinders representation learning. Inspired by the success of pre-training models in natural language processing, in this paper, we develop MusicBERT, a large-scale pre-trained model for music understanding. To this end, we construct a large-scale symbolic music corpus that contains more than 1 million music songs. Since symbolic music contains more structural (e.g., bar, position) and diverse information (e.g., tempo, instrument, and pitch), simply adopting the pre-training techniques from NLP to symbolic music only brings marginal gains. Therefore, we design several mechanisms, including OctupleMIDI encoding and bar-level masking strategy, to enhance pre-training with symbolic music data. Experiments demonstrate the advantages of MusicBERT on four music understanding tasks, including melody completion, accompaniment suggestion, genre classification, and style classification. Ablation studies also verify the effectiveness of our designs of OctupleMIDI encoding and bar-level masking strategy in MusicBERT.},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Information Retrieval,Computer Science - Multimedia,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/home/carlos/Zotero/storage/JL4NSPDK/Zeng et al. - 2021 - MusicBERT Symbolic Music Understanding with Large.pdf;/home/carlos/Zotero/storage/VIRCCY7D/2106.html}
}

@unpublished{zhang2021dive,
  title = {Dive into Deep Learning},
  author = {Zhang, Aston and Lipton, Zachary C. and Li, Mu and Smola, Alexander J.},
  date = {2021},
  eprint = {2106.11342},
  eprinttype = {arxiv}
}

@online{zhouLeasttoMostPromptingEnables2023,
  title = {Least-to-{{Most Prompting Enables Complex Reasoning}} in {{Large Language Models}}},
  author = {Zhou, Denny and Schärli, Nathanael and Hou, Le and Wei, Jason and Scales, Nathan and Wang, Xuezhi and Schuurmans, Dale and Cui, Claire and Bousquet, Olivier and Le, Quoc and Chi, Ed},
  date = {2023-04-16},
  eprint = {2205.10625},
  eprinttype = {arxiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2205.10625},
  url = {http://arxiv.org/abs/2205.10625},
  urldate = {2023-06-25},
  abstract = {Chain-of-thought prompting has demonstrated remarkable performance on various natural language reasoning tasks. However, it tends to perform poorly on tasks which requires solving problems harder than the exemplars shown in the prompts. To overcome this challenge of easy-to-hard generalization, we propose a novel prompting strategy, least-to-most prompting. The key idea in this strategy is to break down a complex problem into a series of simpler subproblems and then solve them in sequence. Solving each subproblem is facilitated by the answers to previously solved subproblems. Our experimental results on tasks related to symbolic manipulation, compositional generalization, and math reasoning reveal that least-to-most prompting is capable of generalizing to more difficult problems than those seen in the prompts. A notable finding is that when the GPT-3 code-davinci-002 model is used with least-to-most prompting, it can solve the compositional generalization benchmark SCAN in any split (including length split) with an accuracy of at least 99\% using just 14 exemplars, compared to only 16\% accuracy with chain-of-thought prompting. This is particularly noteworthy because neural-symbolic models in the literature that specialize in solving SCAN are trained on the entire training set containing over 15,000 examples. We have included prompts for all the tasks in the Appendix.},
  pubstate = {preprint},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/home/carlos/Zotero/storage/7MQPZXWI/Zhou et al. - 2023 - Least-to-Most Prompting Enables Complex Reasoning .pdf;/home/carlos/Zotero/storage/S48WGUZE/2205.html}
}

@online{zhuangComprehensiveSurveyTransfer2020,
  title = {A {{Comprehensive Survey}} on {{Transfer Learning}}},
  author = {Zhuang, Fuzhen and Qi, Zhiyuan and Duan, Keyu and Xi, Dongbo and Zhu, Yongchun and Zhu, Hengshu and Xiong, Hui and He, Qing},
  date = {2020-06-23},
  eprint = {1911.02685},
  eprinttype = {arxiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.1911.02685},
  url = {http://arxiv.org/abs/1911.02685},
  urldate = {2024-01-25},
  abstract = {Transfer learning aims at improving the performance of target learners on target domains by transferring the knowledge contained in different but related source domains. In this way, the dependence on a large number of target domain data can be reduced for constructing target learners. Due to the wide application prospects, transfer learning has become a popular and promising area in machine learning. Although there are already some valuable and impressive surveys on transfer learning, these surveys introduce approaches in a relatively isolated way and lack the recent advances in transfer learning. Due to the rapid expansion of the transfer learning area, it is both necessary and challenging to comprehensively review the relevant studies. This survey attempts to connect and systematize the existing transfer learning researches, as well as to summarize and interpret the mechanisms and the strategies of transfer learning in a comprehensive way, which may help readers have a better understanding of the current research status and ideas. Unlike previous surveys, this survey paper reviews more than forty representative transfer learning approaches, especially homogeneous transfer learning approaches, from the perspectives of data and model. The applications of transfer learning are also briefly introduced. In order to show the performance of different transfer learning models, over twenty representative transfer learning models are used for experiments. The models are performed on three different datasets, i.e., Amazon Reviews, Reuters-21578, and Office-31. And the experimental results demonstrate the importance of selecting appropriate transfer learning models for different applications in practice.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/carlos/Zotero/storage/N58MIQLS/Zhuang et al. - 2020 - A Comprehensive Survey on Transfer Learning.pdf;/home/carlos/Zotero/storage/23KDLTRQ/1911.html}
}

@article{zraraPORTFOLIOOPTIMIZATIONUSING2021,
  title = {{{PORTFOLIO OPTIMIZATION USING DEEP LEARNING FOR THE MOROCCAN MARKET}}},
  author = {Zrara, Lamiaa},
  date = {2021-01-01},
  file = {/home/carlos/Zotero/storage/KRZQ9EEH/Zrara - 2021 - PORTFOLIO OPTIMIZATION USING DEEP LEARNING FOR THE.pdf}
}
