\section{Códigos de materiales sonoros escritos en SuperCollider}
\label{sec:materiales_supercollider}





\begin{minipage}[t]{1\textwidth}
    \centering
    \setstretch{1}
    \begin{lstlisting}[style=SuperCollider-IDE, basicstyle=\footnotesize\ttfamily, numbers=none]
(
{
    var n=6, freqs = LFNoise1.kr(n.linrand).range(500, 12000);
    Splay.ar(
    RLPF.ar(
        Dust.ar(freqs * 0.004) * 50,
        freqs,
        LFNoise1.kr(0.1, 0.5).range(0.05, 0.15)
    )
    )
}.play;
)                                          
    \end{lstlisting}
    \captionqranexo{Código generado por GPT-4 en interacción iterativa en modo chatbot.}{https://drive.google.com/file/d/1HiO2IxfSWXGoKilgamJVrFxUIuv8JDau/view?usp=drive_link}{audio}
    \vspace{1cm}
\end{minipage}


















% \begin{minipage}[t]{1\textwidth}
%     \centering
%     \setstretch{1}
%     \begin{lstlisting}[style=SuperCollider-IDE, basicstyle=\footnotesize\ttfamily, numbers=none]
% (
% // Primera capa: Ritmo percusivo
% Ndef(\a,
%     \setsrc -> Pbind(\source,
%         Pseq([
%             { WhiteNoise.ar() * EnvGen.kr(Env.perc, doneAction:2) * 0.1 },
%             { Impulse.ar(4 + [0,1]) * 0.1 },
%         ], inf),
%         \dur, Prand([0.25, 0.5, 0.75], inf)
%     )
% ).play;

% // Segunda capa: Melodía
% Ndef(\b,
%     \setsrc -> Pbind(\source,
%         Pseq([
%             { SinOsc.ar([440, 442]) * 0.2 },
%             { Saw.ar([330, 332]) * 0.1 },
%         ], inf),
%         \dur, Prand([1, 1.5, 2], inf)
%     )
% ).play;

% // Tercera capa: Textura armónica
% Ndef(\c,
%     \setsrc -> Pbind(\source,
%         Pseq([
%             { Pulse.ar([110, 112]) * 0.1 },
%             { LFTri.ar(LFNoise1.kr(1).range(200,300) + 1 * 180 + [0,1], 0.04) * 0.2 },
%         ], inf),
%         \dur, Prand([2, 3, 4], inf)
%     )
% ).play;
% )     
%     \end{lstlisting}
%     \captionqranexo{Código generado por GPT-4 en interacción iterativa en modo chatbot.}{https://drive.google.com/file/d/1SupaIpEUR43V-FRca22N-qzyFh7cUNE_/view?usp=drive_link}{audio}
%     \vspace{1cm}
% \end{minipage}







\begin{minipage}[t]{1\textwidth}
    \centering
    \setstretch{1}
    \begin{lstlisting}[style=SuperCollider-IDE, basicstyle=\footnotesize\ttfamily, numbers=none]
(
SynthDef(\acidBold, {
    arg out, freq = 1000, gate = 1, pan = 1, cut = 4000, rez = 0.8, amp = 1, lfoFreq = 0.25;
    var lfo, source;
    lfo = SinOsc.kr(lfoFreq).range(800, 2000);  // LFO para modulación de frecuencia
    source = Pulse.ar(freq + lfo, 0.05);
    Out.ar(out,
        Pan2.ar(
            RLPF.ar(
                source,
            cut * LFNoise1.kr(1).range(0.8,1.2),  // Modulación de cut
            rez + LFNoise1.kr(0.5).range(-0.1, 0.1)),  // Modulación de resonancia
        pan) * EnvGen.kr(Env.perc(0.01, 0.3), gate, amp, doneAction: Done.freeSelf);
    )
}).add;
)

(
Pbind(\instrument, \acidBold, \dur, Pseq([0.25, 0.5, 0.75], inf), \root, -12,
    \degree, Pseq([0, 3, 6, 9, 12, 15, 18, 21], inf),  // Grados modificados
    \pan, Pfunc({1.0.rand2}),
    \cut, Pxrand([1000, 500, 2000, 300], inf),
    \rez, Pfunc({0.7.rand +0.3}), \amp, 0.3).play;
)

(
Pdef(\buckyballBold, Pbind(\instrument, \acidBold, \dur, Pseq([0.06, 0.07, 0.02, 0.01], inf), \root, [-24, -17],
    \degree, Pseq([2, 3, 20, 7, 1, 11, [5, 17], 30], inf)+22, \pan, Pfunc({[1.0.rand2, 1.0.rand2]}),
    \cut, Pxrand([1000, 500, 2000, 300], inf), \rez, Pfunc({0.7.rand +0.3}), \amp, [0.15, 0.22])).play;
)

(
Pdef(\buckyballBold, Pbind(\instrument, \acidBold, \dur, Pseq([0.25, 0.5, 0.75], inf), \root, [-24, -17],
    \degree, Pseq([0b, 3b, 5b, 7b, 9b, 11b, 5b, 0b], inf), \pan, Pfunc({1.0.rand2}),
    \cut, Pxrand([1000, 500, 2000, 300], inf), \rez, Pfunc({0.7.rand +0.3}), \amp, 0.3)).play;
)

(
Pdef(\randomRhythm, Pbind(
    \instrument, \acidBold,
    \dur, Pwhite(0.03, 0.05, inf),  // Duraciones aleatorias entre 0.1 y 1.0 segundos
    \degree, Pseq([0, 10, 4, 2, 7, 9, 11]-24, inf),
    \pan, Pwhite(-1, 1, inf),  // Pan aleatorio
    \cut, Prand([500, 1000, 1500, 2000], inf),
    \rez, Pwhite(0.3, 0.8, inf),  // Resonancia aleatoria
    \amp, Pwhite(0.1, 0.5, inf)  // Amplitud aleatoria
)).play;
)
    \end{lstlisting}
    \captionqranexo{Código generado por GPT-4 en interacción iterativa en modo chatbot.}{https://drive.google.com/file/d/1X4WcBr9YL1dWsEmjk7b7FP2YuMqHQdAS/view?usp=drive_link}{audio}
    \vspace{1cm}
\end{minipage}








\begin{minipage}[t]{1\textwidth}
    \centering
    \setstretch{1}
    \begin{lstlisting}[style=SuperCollider-IDE, basicstyle=\footnotesize\ttfamily, numbers=none]
// 1. Definimos el SynthDef con modulación de frecuencia.
(
SynthDef(\fmModulator, { |out = 0, freq = 440, modDepth = 100, modFreq = 5, pan = 0, dur = 1|
    // Generador de modulación
    var modulator = SinOsc.ar(modFreq) * modDepth;

    // Oscilador principal con frecuencia modulada
    var signal = SinOsc.ar(freq *1 + modulator) * 0.5;

    // Envoltura para dar principio y fin al sonido
    var env = EnvGen.kr(Env.perc(0.01, dur*3 - 0.01), doneAction: 2);

    // Multiplicamos la señal por la envoltura
    signal = signal * env;

    // Aplicamos paneo
    signal = Pan2.ar(signal, pan);

    // Aplicamos reverb
    signal = FreeVerb.ar(signal, 0.2, 0.6, 0.5); // Puedes ajustar estos parámetros para cambiar la reverb

    // Enviamos la señal al canal de salida
    Out.ar(out, signal);
}).add;
)

// 2. Usamos Pbind para secuenciar eventos de nuestro SynthDef con paneo.
(
Pbind(
    \instrument, \fmModulator,  // Usamos el SynthDef definido anteriormente
    \freq, Pwhite(0.0, 1).linexp(0, 1, 100, 600),    // Frecuencias aleatorias entre 300 y 600 Hz
    \modDepth, Pwhite(50, 150), // Profundidad de modulación variable
    \modFreq, Pwhite(30, 200.0),    // Frecuencia de modulación variable
    \pan, Pwhite(-1.0, 1),        // Paneo aleatorio
    \dur, Pwhite(0.5, 9),                   // Duración de cada nota
    \legato, 3
).play;
)           
    \end{lstlisting}
    \captionqranexo{Código generado por GPT-4 en interacción iterativa en modo chatbot.}{https://drive.google.com/file/d/132HzMURSflmYGemI5vU0H-imPtLatYhZ/view?usp=drive_link}{audio}
    \vspace{1cm}
\end{minipage}








\begin{minipage}[t]{1\textwidth}
    \centering
    \setstretch{1}
    \begin{lstlisting}[style=SuperCollider-IDE, basicstyle=\footnotesize\ttfamily, numbers=none]
(
{
    var x, y, z, a, b, c, d, e, f, g, h, mix;

    // Tomando la idea de osciladores sinusoidales y distorsión
    x = SinOsc.ar((Decay.ar(Impulse.ar([4,4.005]), 1e3*MouseX.kr(0, 1).abs)*50), MouseY.kr(0, 1)).distort;

    // Incorporando la idea de modulación de frecuencia y filtrado
    y = BPF.ar(Saw.ar([40,40.001]), LFNoise0.kr(128)+1*4e3+146, LFNoise1.kr(1)+1*5e-2+0.01).tanh;

    // Utilizando un delay con modulación
    z = DelayC.ar(LPF.ar(LFNoise0.ar(8)**2 + x.tanh.round(0.05), 6e3), 1, LFNoise0.ar(8!2).range(1e-4, 0.02));

    // Juega con la modulación de un filtro
    a = BHiPass.ar(LFNoise1.ar(8)**3, y.midicps, y/2e3, 67-y);

    // Incorporando elementos de pitch shifting
    b = PitchShift.ar(Saw.ar(Demand.kr(Impulse.kr(4), 0, Drand(([-12, -7, 0, 7, 12]+33).midicps, inf)), Decay.kr(Impulse.kr(4), 3)), 7, 2);

    // Creando una secuencia de ritmo
    c = Impulse.ar(8)*LFNoise1.ar(2);

    // Añadiendo un poco de reverb y limitador para controlar la dinámica
    d = Limiter.ar(GVerb.ar(BPF.ar(c, [400, 800], 1/9, 50).tanh, 100, 10), 0.9);

    // Mezclando las señales juntas
    mix = Mix.new([x, y, z, a, b, c, d]);

    // Aplicando un poco de panoramización y envío al output
    Out.ar(0, Splay.ar(mix));
}.play;
)        
    \end{lstlisting}
    \captionqranexo{Código generado por GPT-4 en interacción iterativa en modo chatbot.}{https://drive.google.com/file/d/1ldkyeQG6HQc2tpbfl_KYAR8wH_DPX7An/view?usp=drive_link}{audio}
    \vspace{1cm}
\end{minipage}
























% \begin{minipage}[t]{1\textwidth}
%     \centering
%     \setstretch{1}
%     \begin{lstlisting}[style=SuperCollider-IDE, basicstyle=\footnotesize\ttfamily, numbers=none]
% // Grabada textura 3 en path: '/home/carlos/.local/share/SuperCollider/Recordings/SC_240105_171941.wav'

% s.boot; // Arrancar el servidor

% // Textura 1: Espacialidad y Drones
% (
% {
%     var freq, amp, pan, drones;

%     // Base frecuencial
%     freq = MouseX.kr(50, 300, warp:'exponential');

%     // Creación de 5 drones con desafinaciones leves
%     drones = 5.collect {
%         SinOsc.ar(freq + Rand(-10, 10), 0, 0.1)
%     }.sum;

%     pan = MouseY.kr(-1, 1); // Panoramización con el ratón en eje Y
%     Pan2.ar(drones, pan);
% }.play;
% )

% // Textura 2: Granulación
% (
% {
%     var grainSize, grainPos, grains;

%     grainSize = MouseX.kr(0.01, 0.5); // Tamaño del grano con el ratón en eje X
%     grainPos = MouseY.kr(0, 1); // Posición de inicio del grano con el ratón en eje Y

%     // Granos basados en ruido blanco
%     grains = GrainSin.ar(2, WhiteNoise.ar(0.5), grainSize, grainPos, 0.1, 1);
%     grains;
% }.play;
% )

% // Textura 3: Ruido Modulado
% (
% {
%     var freq, q, mixedNoise, filteredNoise;

%     freq = MouseX.kr(50, 5000, warp:'exponential'); // Frecuencia de filtro con el ratón en eje X
%     q = MouseY.kr(0.1, 20, warp:'exponential'); // Resonancia (Q) del filtro con el ratón en eje Y

%     // Combinación de ruidos
%     mixedNoise = Mix([WhiteNoise.ar(0.3!2), PinkNoise.ar(0.3!2), BrownNoise.ar(0.3!2)]);

%     // Filtrado resonante
%     filteredNoise = RLPF.ar(mixedNoise, freq, q);
%     filteredNoise;
% }.play;
% )                       
%     \end{lstlisting}
%     \captionqranexo{Zero-shot en una petición de creación sonora generado por GPT-4 en interacción iterativa en modo chatbot.}{https://drive.google.com/file/d/13AMMKehJHzlI8CQUqCqoWMHZ9AI2YgcS/view?usp=drive_link}{audio}
%     \vspace{1cm}
% \end{minipage}




















\begin{minipage}[t]{1\textwidth}
    \centering
    \setstretch{1}
    \begin{lstlisting}[style=SuperCollider-IDE, basicstyle=\footnotesize\ttfamily, numbers=none]
(
SynthDef(\customNTubeSound, {
    var source, filteredNoise, output, pannedOutput;

    // Generamos un sonido que se asemeje a la respiración utilizando PinkNoise, SinOsc y la técnica NTube.ar
    source = PinkNoise.ar * SinOsc.ar(0.1);
    filteredNoise = NTube.ar(
        source,
        [0.97, 1.0, 1.0, 1.0, 1.0, 0.97], // Loss factors
        [0.5, MouseY.kr(-1.0, 1.0), 0.2, -0.4], // Junction reflection coefficients
        [0.01, 0.02, 0.01, 0.005, 0.05] * MouseX.kr(0.001, 1.0, 'exponential') // Delay lengths
    ) * 0.1;

    // Panoramización
    pannedOutput = Pan2.ar(filteredNoise, 0);//SinOsc.kr(0.1).range(-1, 1));

    // Aplicamos un limitador
    output = Limiter.ar(pannedOutput, 0.99, 0.01);
    output = output.min(1.0).max(-1.0);

    Out.ar([0, 1], output);
}).add;
)

// Reproducimos el sonido
x = Synth(\customNTubeSound);

(
SynthDef(\customAmbientSound, {
    var source, nTubeProcessed, modulatedFilter, output, stereoOutput;

    // Generamos un noise basado en PinkNoise pero modulado con una SinOsc de baja frecuencia para darle movimiento
    source = PinkNoise.ar(0.5) * SinOsc.kr(0.1).range(0.5, 1.5);

    // Utilizamos NTube para darle un carácter tubular y resonante al noise
    nTubeProcessed = NTube.ar(
        source,
        [0.95, 0.98, 1.0, 1.0, 0.98, 0.95], // Loss factors
        LFNoise1.kr(0.1).range(0.1, 0.9), // Junction reflection coefficients variando con el tiempo
        LFNoise2.kr(0.05).range(0.01, 0.05) // Delay lengths variando aleatoriamente
    ) * 0.3;

    // Añadimos un filtro paso banda que se mueva con el tiempo
    modulatedFilter = BPF.ar(
        nTubeProcessed,
        freq: LFNoise2.kr(0.2).range(300, 2000),
        rq: 0.5
    );

    // Aplicamos un delay estéreo con modulación tipo ping-pong
    stereoOutput = CombC.ar(modulatedFilter, 2.0, LFNoise2.kr(0.1).range(0.05, 0.5), 0.5);
    stereoOutput = DelayN.ar(stereoOutput, 0.2, SinOsc.kr(0.3).range(0.01, 0.1));

    Out.ar([0, 1], stereoOutput);
}).add;
)

// Reproducimos el sonido
y = Synth(\customAmbientSound);                
    \end{lstlisting}
    \captionqranexo{Código generado por GPT-4 en interacción iterativa en modo chatbot.}{https://drive.google.com/file/d/1Sa3tfPBDp4kpmI3ZFB3Tyg-9_ZELdJN5/view?usp=drive_link}{audio}
    \vspace{1cm}
\end{minipage}





\begin{minipage}[t]{1\textwidth}
    \centering
    \setstretch{1}
    \begin{lstlisting}[style=SuperCollider-IDE, basicstyle=\footnotesize\ttfamily, numbers=none]
(
SynthDef(\fmSynthNoReverb, {
    arg freq=440, mDepth=100, mFreq=5, dur=1, amp=0.5, pan=0;
    var modulator, carrier, env, signal;

    env = EnvGen.kr(Env.perc(0.01, dur, 1, -1), doneAction: 2);

    modulator = SinOsc.ar(mFreq) * mDepth;
    carrier = SinOsc.ar(freq + modulator);
    signal = carrier + (SinOsc.ar(freq * 2 + modulator * 0.5) * 0.5);
    signal = signal * env * amp;

    // Aplicar panorámica
    signal = Pan2.ar(signal, pan);

    // Enviar a un bus de audio en lugar de la salida principal
    Out.ar(\bus.kr(0), signal);
}).add;
)

(
SynthDef(\reverbSynth, {
    arg bus, mix=0.2, room=0.8;
    var inSignal;

    inSignal = In.ar(bus, 2);
    inSignal = FreeVerb.ar(inSignal, mix: mix, room: room);

    // Devolver el sonido procesado al bus principal
    Out.ar(0, inSignal);
}).add;
)

// Configurar el bus
~reverbBus = Bus.audio(s, 2);

// Iniciar el Synth de reverberación
~reverbSynth = Synth(\reverbSynth, ['bus': ~reverbBus]);

// Pbind
(
Pbind(
    \instrument, \fmSynthNoReverb,
    \freq, Pwhite(300, 600, inf),
    \mDepth, Pwhite(50, 500, inf),
    \mFreq, Pseq([Pwhite(2, 10, 1), Pwhite(100, 1000, 1)], inf),
    \dur, Pwhite(0.2, 1, inf),
    \amp, Pwhite(0.3, 0.7, inf),
    \pan, Pwhite(-1, 1, inf),  // Valores entre -1 (izquierda) y 1 (derecha)
    \bus, ~reverbBus   // Enviar al bus de reverberación
).play;
)                                
    \end{lstlisting}
    \captionqranexo{Código generado por GPT-4 en interacción iterativa en modo chatbot.}{https://drive.google.com/file/d/1q9GnGktEwciSSn-IKLPLegHU6lmSdD3Z/view?usp=drive_link}{audio}
    \vspace{1cm}
\end{minipage}





















\begin{minipage}[t]{1\textwidth}
    \centering
    \setstretch{1}
    \begin{lstlisting}[style=SuperCollider-IDE, basicstyle=\footnotesize\ttfamily, numbers=none]
(
// Inicialización de la orquestación
s.waitForBoot {
    var introDur = 10, desarrolloDur = 20, interactivoDur = 15, climaxDur = 15, cierreDur = 5;
    var totalDur = introDur + desarrolloDur + interactivoDur + climaxDur + cierreDur;
    var timeline;

    timeline = Routine {
        // Introducción con gabor e imp
        Synth(\gabor, [freq: 440, pan: 0, width: 0.3, sustain: introDur]);
        Synth(\imp, [freq: 440, speed: 1, begin: 0, end: 1, pan: 0, accelerate: 0.5, offset: 0, sustain: introDur]);
        (introDur).wait;

        // Desarrollo con psin y pmsin
        Synth(\psin, [freq: 440, speed: 1, begin: 0, end: 1, pan: 0, accelerate: 0.5, offset: 0, modfreq: 40, sustain: desarrolloDur]);
        Synth(\pmsin, [freq: 440, speed: 1, begin: 0, end: 1, pan: 0, accelerate: 0.5, offset: 0, sustain: desarrolloDur]);
        (desarrolloDur).wait;

        // Interacción en vivo con in e in1
        Synth(\in, [soundin: 0, pan: 0, inputFadeTime: 0.03, sustain: interactivoDur]);
        Synth(\in1, [soundin: 0, pan: 0, inputFadeTime: 0.03, sustain: interactivoDur]);
        (interactivoDur).wait;

        // Climax con una mezcla de synths
        // Aquí puedes añadir más Synths según tu preferencia
        (climaxDur).wait;

        // Cierre con gabor y dirac
        Synth(\gabor, [freq: 440, pan: 0, width: 0.3, sustain: cierreDur]);
        Synth(\dirac, [pan: 0, sustain: cierreDur]);
        (cierreDur).wait;
    };

    timeline.play;
};
)                                     
    \end{lstlisting}
    \captionqranexo{Código generado por GPT-4 en interacción iterativa en modo chatbot.}{https://drive.google.com/file/d/1UiNHmMKCaxsTX2qasP3xH8HRpCmminf4/view?usp=drive_link}{audio}
    \vspace{1cm}
\end{minipage}



















\begin{minipage}[t]{1\textwidth}
    \centering
    \setstretch{1}
    \begin{lstlisting}[style=SuperCollider-IDE, basicstyle=\footnotesize\ttfamily, numbers=none]
(
SynthDef(\paulstretchPoly, { |out = 0, bufnum, envBufnum, pan = 0, stretch = 8, window = 0.25, amp = 1, rate = 1|
    // Los detalles internos de la SynthDef se mantienen iguales que en la versión monofónica
    var trigPeriod, sig, chain, trig, pos, fftSize;
    fftSize = 2**floor(log2(window*SampleRate.ir));
    trigPeriod = fftSize/SampleRate.ir;
    trig = Impulse.ar(1/trigPeriod);
    pos = Demand.ar(trig, 0, demandUGens: Dseries(0, trigPeriod/stretch));
    sig = [GrainBuf.ar(1, trig, trigPeriod, bufnum, rate, pos, envbufnum: envBufnum),
        GrainBuf.ar(1, trig, trigPeriod, bufnum, rate, pos + (trigPeriod/(2*stretch)), envbufnum: envBufnum)]*amp;
    sig = sig.collect({ |item, i|
        chain = FFT(LocalBuf(fftSize), item, hop: 1.0, wintype: -1);
        chain = PV_Diffuser(chain, 1 - trig);
        item = IFFT(chain, wintype: -1);
    });
    sig = sig*PlayBuf.ar(1, envBufnum, 1/(trigPeriod), loop:1);
    sig[1] = DelayC.ar(sig[1], trigPeriod/2, trigPeriod/2);
    Out.ar(out, Pan2.ar(Mix.new(sig), pan));
}).add;

s.waitForBoot({
    var numSynths = 8; // Número de instancias de Synth que quieres crear
    var envBuf, envSignal, buffer, synths;

    // Carga del buffer con el archivo de sonido
    buffer = Buffer.read(s, Platform.resourceDir +/+ "sounds/a11wlk01.wav");

    // Creación y carga del buffer de envolvente
    envBuf = Buffer.alloc(s, s.sampleRate, 1);
    envSignal = Signal.newClear(s.sampleRate).waveFill({|x| (1 - x.pow(2)).pow(1.25)}, -1.0, 1.0);
    envBuf.loadCollection(envSignal);
    s.sync();

    // Creación de múltiples instancias de Synth con diferentes parámetros
    synths = Array.fill(numSynths, { |i|
        var delayTime = i.rand; // Tiempo de espera antes de iniciar la instancia
        var rateValue = [0.125, 0.25, 0.5, -0.125, -0.25, -0.5].choose; // Velocidades de reproducción, incluidas negativas
        var stretchValue = (8.rand + 0.5).round(0.01); // Valores de estiramiento
        var panValue = [-1, 1].choose; // Posición estéreo
        var windowValue = [0.1, 0.2, 0.3, 0.4].choose; // Valor aleatorio para el tamaño de la ventana

        // Se utiliza 'fork' para permitir tiempos de inicio escalonados
        fork({
            delayTime.wait; // Espera antes de empezar
            Synth(\paulstretchPoly, [
                \bufnum, buffer.bufnum,
                \envBufnum, envBuf.bufnum,
                \pan, panValue,
                \stretch, stretchValue,
                \rate, rateValue,
                \amp, 0.3.rand + 0.2, // Volumen aleatorio dentro de un rango
                \window, windowValue // Tamaño de ventana aleatorio
            ]);
        });
    });
});
)                                 
    \end{lstlisting}
    \captionqranexo{Código generado por GPT-4 en interacción iterativa en modo chatbot.}{https://drive.google.com/file/d/1GkSF9Gu_NZ56M_Ue9GQptnhDMOwTAsXt/view?usp=drive_link}{audio}
    \vspace{1cm}
\end{minipage}





















%  https://platform.openai.com/playground?assistant=asst_jRoEFqfb7RegBABBvS7qEi1i&thread=thread_sNm8fDfcwZu3GU4APA6g3SXp

\begin{minipage}[t]{1\textwidth}
    \centering
    \setstretch{1}
\begin{lstlisting}[style=SuperCollider-IDE, basicstyle=\footnotesize\ttfamily, numbers=none]
// Definimos un bus de audio para la reverberación
~reverbBus = Bus.audio(s, 2);
// SynthDef de reverberación
(
SynthDef(\reverbEffect, { |outBus = 0|
    var sig = In.ar(~reverbBus, 2);
    sig = JPverb.ar(sig[0] + sig[1], t60: 3, size: 0.9, damp: 0.2, earlyDiff: 0.7);
    ReplaceOut.ar(outBus, sig);
}).add;
// SynthDefs para gránulos con correcciones de FM y adiciones para variación
SynthDef(\grainSynth, { |outBus, freq = 440, dur = 0.1, pan = 0, amp = 0.1, type = 0|
    var sig, env, mod;
    env = EnvGen.ar(Env.perc(0.01, dur, amp), doneAction: 2);
    // Tipo de grano: varía desde FM a pulse a noise
    mod = Select.ar(type,
        [
            SinOsc.ar(freq + SinOsc.ar(Rand(1.0, 100.0)).range(-200, 200)) * env, // FM
            Pulse.ar(freq, 0.5) * env,                                            // Pulse
            WhiteNoise.ar() * env * LFNoise1.kr(5).range(0,1)                    // Noise
        ]
    );
    Out.ar(outBus, Pan2.ar(mod, pan));
}).add;
)
// Creamos la instancia del efecto de reverberación
~reverb = Synth(\reverbEffect, [\outBus, 0]);
// Función para variar la densidad temporal de los granos y tipo de grano
(
~density = { |minTime = 0.05, maxTime = 0.2, typeMin = 0, typeMax = 2|
    Pbind(
        \instrument, \grainSynth,
        \freq, Pexprand(200.0, 2000.0, inf),
        \dur, Pwhite(minTime, maxTime, inf),
        \pan, Pwhite(-1, 1, inf),
        \amp, Pwhite(0.01, 0.1, inf),
        \type, Pwhite(typeMin, typeMax, inf),
        \outBus, ~reverbBus
    ).play;
};
)
// Iniciar con densidad inicial y tipos de grano
~grainPattern = ~density.value(0.05, 0.1, 0, 0);
// Modificar la densidad y el tipo de grano cada 10 segundos
(
~changeDensity = {
    inf.do {
        ~grainPattern.stop;
        ~grainPattern = ~density.value(
            0.05.rand2(0.2), // minTime
            (0.2.rand2(0.5)).abs, // maxTime
            0, // typeMin
            2 // typeMax
        );
        10.wait;
    };
}.fork;
)
// Parar el cambio de densidad y el patrón de grano
(
~stopPatterns = {
    ~changeDensity.stop;
    ~grainPattern.stop;
};
)
~changeDensity.stop;
~grainPattern.stop;
~reverb.free;
// Ejecutar ~changeDensity para iniciar el cambio automático en la densidad y tipo de grano
~changeDensity;
~stopPatterns;
    \end{lstlisting}
    \captionqranexo{Código generado por GPT-4 en interacción iterativa utilizando la técnica de \gls{rag} en un \emph{Assistant} de OpenAI.}{https://drive.google.com/file/d/1jjeCwswr61iFNpDIwKCPNkDIWAQWuPUe/view?usp=drive_link}{audio}
    \vspace{1cm}
\end{minipage}

















% // Patch obtenido con SuperCollider Assistant
% // 09/11/2023
% // https://platform.openai.com/playground?thread=thread_5Sqry82fvt0tclH4mX0yDIln
\begin{minipage}[t]{1\textwidth}
    \centering
    \setstretch{1}
    \begin{lstlisting}[style=SuperCollider-IDE, basicstyle=\footnotesize\ttfamily, numbers=none]
(
s.boot;

// Definir un sintetizador más suave para el sonido del viento y las hojas
SynthDef(\softFoliage, {
    arg out=0, amp=0.1, pan=0;
    var sound, filterFreq;

    // Crear un ruido rosado que tiene una calidad más suave que el ruido blanco
    sound = PinkNoise.ar(amp);

    // Modular la frecuencia del filtro para simular el movimiento del viento en las hojas
    filterFreq = LFNoise1.kr(Rand(0.1, 0.5)).exprange(300, 2000);
    sound = LPF.ar(sound, filterFreq);

    // Utilizar una envolvente suave para modelar el sonido con más naturalidad
    sound = sound * EnvGen.kr(Env.linen(5, 10, 5, 0.1), doneAction: 2);

    Out.ar(out, Pan2.ar(sound, pan));
}).add;

// Definir el synth para los pájaros como se hizo inicialmente
SynthDef(\birds, {
    arg out=0, amp=0.05, pan=0;
    var z;
    z = SinOsc.ar(2200 + (SinOsc.kr([5, 6]) * 100)).abs - 0.97;
    z = HPF.ar(z * amp, 1000);
    z = z * EnvGen.ar(Env.perc(0.1, Rand(2, 3)), doneAction: 2);
    Out.ar(out, Pan2.ar(z, pan));
}).add;

// Inicializar el patrón para generar el sonido del viento
Pbind(
    \instrument, \softFoliage,
    \dur, Pwhite(8, 12),  // Duración más larga para un sonido continuo
    \amp, 0.2,
    \pan, Pwhite(-1, 1)
).play;

// Inicializar el patrón para los pájaros
Pbind(
    \instrument, \birds,
    \dur, Pexprand(0.1, 1),
    \amp, 0.05,
    \pan, Pwhite(-1, 1)
).play;
)                                    
    \end{lstlisting}
    \captionqranexo{Código generado por GPT-4 en interacción iterativa utilizando la técnica de \gls{rag} en un \emph{Assistant} de OpenAI.}{https://drive.google.com/file/d/1Fum93BKo5o37dtEk5lR1NACCJjd63fd_/view?usp=drive_link}{audio}
    \vspace{1cm}
\end{minipage}
















% // Interesante!
% // https://platform.openai.com/playground?assistant=asst_jRoEFqfb7RegBABBvS7qEi1i&mode=assistant&thread=thread_W0hsopVAd3SiA1yT4zzNbB97
% // SC Assitant
\begin{minipage}[t]{1\textwidth}
    \centering
    \setstretch{1}
    \begin{lstlisting}[style=SuperCollider-IDE, basicstyle=\footnotesize\ttfamily, numbers=none]
(
s.waitForBoot {
    var numChannels = 2; // Estéreo

    s.options.numOutputBusChannels = numChannels;
    s.options.numInputBusChannels = numChannels;
    s.boot;

    SynthDef("grainTexture", {
        arg out=0, dur=2, rate=1, pan=0;
        var env, grain, freq;

        freq = LFNoise1.kr(0.5).exprange(200, 1200);

        grain = GrainSin.ar(
            numChannels: numChannels,
            trigger: Impulse.kr(10),
            dur: LFNoise2.kr(0.5).range(dur * 0.5, dur),
            pan: LFNoise2.kr(0.1).range(-1, 1),
            freq: freq,
            maxGrains: 50
        ) * 0.1;

        env = EnvGen.kr(Env.perc(0.01, 1), doneAction: 2);

        Out.ar(out, grain * env);
    }).add;

    Routine({
        inf.do {
            Synth("grainTexture", [
                \dur, rrand(0.1, 0.5),
                \rate, rrand(0.5, 2),
                \pan, rrand(-1, 1)
            ]);

            (rrand(0.1, 0.5)).wait;
        }
    }).play;
};
)                                      
    \end{lstlisting}
    \captionqranexo{Código generado por GPT-4 en interacción iterativa utilizando la técnica de \gls{rag} en un \emph{Assistant} de OpenAI.}{https://drive.google.com/file/d/142-tpf4Ib15tNYVuA9wl1iaKgpHimr14/view?usp=drive_link}{audio}
    \vspace{1cm}
\end{minipage}













% // https://platform.openai.com/playground?assistant=asst_vC9nmZAe8RcBA2s0kFM4roFj&mode=assistant&thread=thread_i1XHLNH57r1duSZU5x7nWn5h
% // 11/11/2023
% // Assistant v2
\begin{minipage}[t]{1\textwidth}
    \centering
    \setstretch{1}
    \begin{lstlisting}[style=SuperCollider-IDE, basicstyle=\footnotesize\ttfamily, numbers=none]
(
SynthDef.new(\birds, {
    var env, freq, sig, modFreq, pan;
    modFreq = LFNoise1.kr(rrand(0.5, 2)).range(5, 15);
    env = Env.perc(0.01, 0.1, 0.1).kr(doneAction: 2);
    freq = LFDNoise3.kr(modFreq).exprange(4000, 8000);
    sig = SinOsc.ar(freq) * env;
    pan = LFNoise2.kr(0.5).range(-1, 1);
    Out.ar(0, Pan2.ar(sig, pan));
}).add;

SynthDef.new(\wind, {
    var sig, filt, env, ampMod;
    ampMod = LFNoise1.kr(0.2).range(0.2, 0.7);
    env = Env.linen(2, 10, 2, 1).kr(doneAction: 2);
    sig = WhiteNoise.ar(ampMod);
    filt = BPF.ar(sig, LFNoise1.kr(rrand(0.05, 0.1)).range(150, 250), 0.1) * 0.25;
    Out.ar(0, Pan2.ar(filt * env, LFNoise2.kr(rrand(0.3, 0.5)).range(-1, 1)));
}).add;

SynthDef.new(\leaves, {
    var sig, mod, env;
    env = Env.linen(0.1, 8, 0.1, 0.3).kr(doneAction: 2);
    sig = Dust2.ar(LFNoise2.kr(1).range(50, 400));
    mod = LFNoise1.kr(4).range(0, 0.5);
    Out.ar(0, Pan2.ar(sig * mod * env, LFNoise1.kr(rrand(0.4, 0.6)).range(-1, 1)));
}).add;

SynthDef.new(\insects, {
    var sig, env;
    env = Env.linen(2, 12, 2, 0.1).kr(doneAction: 2);
    sig = Mix.fill(2, {
        LFPulse.ar(rrand(40, 120), 0, LFNoise2.kr(1).range(0.1, 0.5)) * 0.05
    });
    Out.ar(0, Pan2.ar(sig * env, LFNoise1.kr(0.5).range(-1, 1)));
}).add;

Pbind(
    \instrument, \birds,
    \dur, Pfunc({ rrand(0.1, 0.8) }),
    \amp, Pfunc({ rrand(0.3, 0.6) })
).play;

Pbind(
    \instrument, \wind,
    \dur, 1,
    \amp, Pfunc({ rrand(0.2, 0.4) })
).play;

Pbind(
    \instrument, \leaves,
    \dur, Pwrand([0.1, 0.2, 0.5], [0.5, 0.3, 0.2], inf),
    \amp, Pfunc({ rrand(0.1, 0.4) })
).play;

Pbind(
    \instrument, \insects,
    \dur, Pwrand([0.3, 0.7, 1], [0.5, 0.3, 0.2], inf),
    \amp, Pfunc({ rrand(0.05, 0.2) })
).play;
)                                       
    \end{lstlisting}
    \captionqranexo{Código generado por GPT-4 en interacción iterativa utilizando la técnica de \gls{rag} en un \emph{Assistant} de OpenAI.}{https://drive.google.com/file/d/1y0Sx5pSpi8qQtWNtgCgHDnuHxiALruuU/view?usp=drive_link}{audio}
    \vspace{1cm}
\end{minipage}


% \begin{minipage}[t]{1\textwidth}
%     \centering
%     \setstretch{1}
%     \begin{lstlisting}[style=SuperCollider-IDE, basicstyle=\footnotesize\ttfamily, numbers=none]
% // https://chat.openai.com/share/340c2959-bea8-49b9-bf09-4a9a8c3b68f6
% // Acaba con un par de códigos interesantes. Hay que interactuar bastante.

% // grabado (codigo del final) en path: '/home/carlos/.local/share/SuperCollider/Recordings/SC_240106_184528.wav'



% // Ejemplo 1: Secuencia melódica con eco
% {CombN.ar(SinOsc.ar([100, 101].midiratio * 60).sum * 0.2, 0.4, 0.4, 3)}.play;

% // Ejemplo 2: Percusión sintética con filtrado y resonancia
% {RLPF.ar(Dust.ar(15) * 50, MouseX.kr(200, 12000), 0.1)}.play;

% // Ejemplo 3: Sintetizador de bajos con modulación de frecuencia
% {SinOsc.ar([SinOsc.kr(2, 0, 10, 55), SinOsc.kr(2, 0, 10, 110)], 0, 0.4)}.play;

% // Ejemplo 4: Paisaje sonoro con ruido modulado y espacialización
% {FreeVerb.ar(HPF.ar(WhiteNoise.ar([0.05, 0.05]), MouseX.kr(100, 5000)), 0.5, 0.7)}.play;

% // Ejemplo 5: Secuencias de acordes con un patrón arpegiado
% (
% {
%     var freqs = [60, 64, 67].midicps;
%     var trigs = Dust.kr([2, 3, 4]);
%     Splay.ar(
%         LPF.ar(
%             SinOscFB.ar(freqs * [1, 1.01], 0, Decay.kr(trigs, 0.2)),
%             5000
%         )
%     )
% }.play;
% )


% {Splay.ar(RLPF.ar(Dust.ar(3!6) * 50, LFNoise1.kr(2!6).range(200, 12000), 0.1),1)}.play;

% {n=6;Splay.ar(RLPF.ar(Dust.ar({|i| i.rand2}!n) * 50, LFNoise1.kr({|i| i.linexp(0,5,0.5,5)}!n).range(200, 12000), 0.1),1)}.play;


% //******* Código interesante
% (
% {
%     var n=6, freqs = LFNoise1.kr(n.linrand).range(200, 12000);
%     Splay.ar(
%     RLPF.ar(
%         Dust.ar(freqs * 0.004) * 50,
%         freqs,
%         LFNoise1.kr(0.1, 0.5).range(0.05, 0.15)
%     )
%     )
% }.play;
% )


% //******* Código interesante
% {n=6;Splay.ar(RLPF.ar(Dust.ar(Array.fill(n,{2.0.rand})+0.01)*50,LFNoise1.kr(Array.fill(n,{2.0.rand})  ).exprange(200,12000),0.1))}.play;                                      
%     \end{lstlisting}
%     \captionqranexo{Zero-shot en una petición de creación sonora generado por GPT-4 en interacción iterativa en modo chatbot.}{https://drive.google.com/file/d/13AMMKehJHzlI8CQUqCqoWMHZ9AI2YgcS/view?usp=drive_link}{audio}
%     \vspace{1cm}
% \end{minipage}
